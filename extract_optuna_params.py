"""
Optuna ìµœì í™” í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°„ë‹¨ ì¶”ì¶œê¸°
=====================================

final_modelsì—ì„œ Optunaë¡œ ìµœì í™”ëœ í•µì‹¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë§Œ 
ê°„ë‹¨í•˜ê²Œ ì¶”ì¶œí•˜ì—¬ ì •ë¦¬í•©ë‹ˆë‹¤.
"""

import joblib
import json
import pandas as pd
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')


def extract_optuna_params(model_path):
    """Optunaë¡œ ìµœì í™”ëœ í•µì‹¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë§Œ ì¶”ì¶œ"""
    try:
        model = joblib.load(model_path)
        
        # ì•™ìƒë¸” ëª¨ë¸ì€ ì œì™¸
        if hasattr(model, 'models') and hasattr(model, 'weights'):
            return {'model_type': 'ensemble', 'params': 'ensemble_model'}
        
        model_type = str(type(model).__name__).lower()
        
        # Logistic Regression
        if 'logistic' in model_type:
            return {
                'model_type': 'logistic_regression',
                'params': {
                    'C': round(model.C, 4),
                    'penalty': model.penalty,
                    'solver': model.solver,
                    'max_iter': model.max_iter
                }
            }
        
        # Random Forest
        elif 'forest' in model_type:
            return {
                'model_type': 'random_forest',
                'params': {
                    'n_estimators': model.n_estimators,
                    'max_depth': model.max_depth,
                    'min_samples_split': model.min_samples_split,
                    'min_samples_leaf': model.min_samples_leaf,
                    'max_features': round(model.max_features, 3) if isinstance(model.max_features, float) else model.max_features
                }
            }
        
        # XGBoost
        elif 'xgb' in model_type:
            return {
                'model_type': 'xgboost',
                'params': {
                    'n_estimators': model.n_estimators,
                    'max_depth': model.max_depth,
                    'learning_rate': round(model.learning_rate, 4),
                    'subsample': round(model.subsample, 3),
                    'colsample_bytree': round(model.colsample_bytree, 3),
                    'reg_alpha': round(model.reg_alpha, 2),
                    'reg_lambda': round(model.reg_lambda, 2),
                    'scale_pos_weight': round(model.scale_pos_weight, 1) if model.scale_pos_weight else None
                }
            }
        
        else:
            return {'model_type': 'unknown', 'params': {}}
            
    except Exception as e:
        return {'model_type': 'error', 'params': str(e)}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ Optuna ìµœì í™” í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°„ë‹¨ ì¶”ì¶œ")
    
    models_dir = Path("/Users/jojongho/KDT/P2_Default-invest/final_models")
    model_files = list(models_dir.glob("*.joblib"))
    
    # ê²°ê³¼ ì €ì¥
    optuna_params = {}
    
    print("\nğŸ“‹ ëª¨ë¸ë³„ ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
    print("="*60)
    
    for model_file in sorted(model_files):
        # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
        filename = model_file.stem
        if "__" in filename:
            data_type, model_name = filename.split("__", 1)
            model_name = model_name.replace("_model", "")
        else:
            data_type = "unknown"
            model_name = filename.replace("_model", "")
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        result = extract_optuna_params(model_file)
        
        # í‚¤ ìƒì„±
        model_key = f"{data_type}__{model_name}"
        optuna_params[model_key] = {
            'data_type': data_type,
            'model_name': model_name,
            'model_type': result['model_type'],
            'optimized_params': result['params']
        }
        
        # ì¶œë ¥
        print(f"\nğŸ”¹ {model_key}")
        print(f"   íƒ€ì…: {result['model_type']}")
        
        if isinstance(result['params'], dict):
            for param, value in result['params'].items():
                print(f"   {param}: {value}")
        else:
            print(f"   {result['params']}")
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    output_file = "optuna_hyperparameters_simple.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(optuna_params, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {output_file}")
    
    # ëª¨ë¸ íƒ€ì…ë³„ ìš”ì•½
    print(f"\nğŸ“Š ëª¨ë¸ íƒ€ì…ë³„ ê°œìˆ˜:")
    type_counts = {}
    for info in optuna_params.values():
        model_type = info['model_type']
        type_counts[model_type] = type_counts.get(model_type, 0) + 1
    
    for model_type, count in type_counts.items():
        print(f"   {model_type}: {count}ê°œ")
    
    # CSVë¡œë„ ì €ì¥ (ë” ë³´ê¸° ì‰½ê²Œ)
    rows = []
    for key, info in optuna_params.items():
        row = {
            'Model_Key': key,
            'Data_Type': info['data_type'],
            'Model_Name': info['model_name'],
            'Model_Type': info['model_type']
        }
        
        if isinstance(info['optimized_params'], dict):
            row.update(info['optimized_params'])
        
        rows.append(row)
    
    df = pd.DataFrame(rows)
    csv_file = "optuna_hyperparameters_simple.csv"
    df.to_csv(csv_file, index=False, encoding='utf-8-sig')
    print(f"âœ… CSV ì €ì¥ ì™„ë£Œ: {csv_file}")
    
    return optuna_params


if __name__ == "__main__":
    main()