"""
ì•™ìƒë¸” ëª¨ë¸ êµ¬í˜„
ë‹¤ì–‘í•œ ê¸°ë³¸ ëª¨ë¸ë“¤ì„ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ
"""

import pandas as pd
import numpy as np
import json
import warnings
from datetime import datetime
from pathlib import Path
import joblib
from sklearn.metrics import (
    roc_auc_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, roc_curve, auc,
    precision_recall_curve, average_precision_score, balanced_accuracy_score
)
from sklearn.model_selection import StratifiedKFold, cross_val_score
import matplotlib.pyplot as plt
import seaborn as sns

warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic' if plt.matplotlib.get_backend() != 'Agg' else 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class EnsembleModel:
    """
    ë‹¤ì–‘í•œ ê¸°ë³¸ ëª¨ë¸ë“¤ì„ ê²°í•©í•œ ì•™ìƒë¸” ëª¨ë¸
    """
    
    def __init__(self, config, base_models=None):
        """
        ì•™ìƒë¸” ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            config (dict): ì•™ìƒë¸” ì„¤ì •
            base_models (dict): ê¸°ë³¸ ëª¨ë¸ë“¤ {model_name: model_object}
        """
        self.config = config
        self.base_models = base_models or {}
        self.ensemble_config = config.get('ensemble', {})
        self.method = self.ensemble_config.get('method', 'weighted_average')
        self.weights = self.ensemble_config.get('weights', {})
        self.auto_weight = self.ensemble_config.get('auto_weight', False)
        
        # ê²°ê³¼ ì €ì¥
        self.predictions = {}
        self.final_prediction = None
        self.performance_metrics = {}
        
        print(f"ğŸ­ ì•™ìƒë¸” ëª¨ë¸ ì´ˆê¸°í™”")
        print(f"ğŸ“Š ë°©ë²•: {self.method}")
        print(f"âš–ï¸ ê°€ì¤‘ì¹˜: {self.weights}")
        print(f"ğŸ¤– ìë™ ê°€ì¤‘ì¹˜: {self.auto_weight}")
    
    def add_model(self, model_name, model, weight=None):
        """
        ê¸°ë³¸ ëª¨ë¸ ì¶”ê°€
        
        Args:
            model_name (str): ëª¨ë¸ ì´ë¦„
            model: í›ˆë ¨ëœ ëª¨ë¸ ê°ì²´
            weight (float): ê°€ì¤‘ì¹˜ (ì„ íƒì‚¬í•­)
        """
        self.base_models[model_name] = model
        if weight is not None:
            self.weights[model_name] = weight
        
        print(f"âœ… ëª¨ë¸ ì¶”ê°€: {model_name} (ê°€ì¤‘ì¹˜: {weight})")
    
    def predict_proba_individual(self, X):
        """
        ê° ê¸°ë³¸ ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°
        
        Args:
            X: ì…ë ¥ íŠ¹ì„±
            
        Returns:
            dict: {model_name: prediction_probabilities}
        """
        predictions = {}
        expected_length = len(X)
        
        for model_name, model in self.base_models.items():
            try:
                # ì˜ˆì¸¡ í™•ë¥  ê³„ì‚° (í´ë˜ìŠ¤ 1ì˜ í™•ë¥ ë§Œ ì‚¬ìš©)
                pred_proba = model.predict_proba(X)[:, 1]
                
                # ì˜ˆì¸¡ ê²°ê³¼ í¬ê¸° í™•ì¸
                if len(pred_proba) != expected_length:
                    print(f"âš ï¸ {model_name} ì˜ˆì¸¡ í¬ê¸° ë¶ˆì¼ì¹˜: ì˜ˆìƒ={expected_length}, ì‹¤ì œ={len(pred_proba)}")
                    # í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›€
                    pred_proba = np.full(expected_length, 0.5)
                
                predictions[model_name] = pred_proba
                print(f"âœ… {model_name} ì˜ˆì¸¡ ì™„ë£Œ: {len(pred_proba)}ê°œ ìƒ˜í”Œ")
                
            except Exception as e:
                print(f"âš ï¸ {model_name} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ê²½ìš° 0.5ë¡œ ì±„ì›€ (ì¤‘ë¦½ì  ì˜ˆì¸¡)
                predictions[model_name] = np.full(expected_length, 0.5)
                print(f"âœ… {model_name} ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´: {expected_length}ê°œ ìƒ˜í”Œ")
        
        return predictions
    
    def calculate_auto_weights(self, X_valid, y_valid):
        """
        ê²€ì¦ ë°ì´í„° ê¸°ë°˜ ìë™ ê°€ì¤‘ì¹˜ ê³„ì‚°
        
        Args:
            X_valid: ê²€ì¦ íŠ¹ì„±
            y_valid: ê²€ì¦ ë¼ë²¨
            
        Returns:
            dict: ìµœì  ê°€ì¤‘ì¹˜
        """
        print("\nğŸ¤– ìë™ ê°€ì¤‘ì¹˜ ê³„ì‚°")
        print("="*50)
        
        # ê° ëª¨ë¸ì˜ ê²€ì¦ ì„±ëŠ¥ ê³„ì‚°
        individual_predictions = self.predict_proba_individual(X_valid)
        model_scores = {}
        
        for model_name, pred_proba in individual_predictions.items():
            try:
                # F1 score ê¸°ë°˜ ì„±ëŠ¥ í‰ê°€
                pred_binary = (pred_proba >= 0.5).astype(int)
                f1 = f1_score(y_valid, pred_binary, zero_division=0)
                auc = roc_auc_score(y_valid, pred_proba)
                
                # ë³µí•© ì ìˆ˜ (F1ê³¼ AUCì˜ ì¡°í™”í‰ê· )
                if f1 > 0 and auc > 0:
                    composite_score = 2 * (f1 * auc) / (f1 + auc)
                else:
                    composite_score = 0
                
                model_scores[model_name] = composite_score
                print(f"{model_name}: F1={f1:.4f}, AUC={auc:.4f}, ë³µí•©={composite_score:.4f}")
                
            except Exception as e:
                print(f"âš ï¸ {model_name} ì„±ëŠ¥ ê³„ì‚° ì‹¤íŒ¨: {e}")
                model_scores[model_name] = 0
        
        # ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚° (ì†Œí”„íŠ¸ë§¥ìŠ¤)
        scores = np.array(list(model_scores.values()))
        if scores.sum() > 0:
            # ì†Œí”„íŠ¸ë§¥ìŠ¤ë¡œ ê°€ì¤‘ì¹˜ ì •ê·œí™”
            exp_scores = np.exp(scores - np.max(scores))
            weights_array = exp_scores / exp_scores.sum()
            
            auto_weights = dict(zip(model_scores.keys(), weights_array))
        else:
            # ëª¨ë“  ì„±ëŠ¥ì´ 0ì¸ ê²½ìš° ê· ë“± ê°€ì¤‘ì¹˜
            auto_weights = {name: 1.0/len(model_scores) for name in model_scores.keys()}
        
        print(f"\nğŸ¯ ìë™ ê³„ì‚°ëœ ê°€ì¤‘ì¹˜:")
        for name, weight in auto_weights.items():
            print(f"  {name}: {weight:.4f}")
        
        return auto_weights
    
    def ensemble_predict_proba(self, X, X_valid=None, y_valid=None):
        """
        ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰
        
        Args:
            X: ì˜ˆì¸¡í•  ë°ì´í„°
            X_valid: ê²€ì¦ ë°ì´í„° (ìë™ ê°€ì¤‘ì¹˜ìš©)
            y_valid: ê²€ì¦ ë¼ë²¨ (ìë™ ê°€ì¤‘ì¹˜ìš©)
            
        Returns:
            np.array: ì•™ìƒë¸” ì˜ˆì¸¡ í™•ë¥ 
        """
        print(f"\nğŸ­ ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰ ({self.method})")
        print("="*50)
        
        # ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡
        individual_predictions = self.predict_proba_individual(X)
        self.predictions = individual_predictions
        
        if len(individual_predictions) == 0:
            raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìë™ ê°€ì¤‘ì¹˜ ê³„ì‚°
        if self.auto_weight and X_valid is not None and y_valid is not None:
            auto_weights = self.calculate_auto_weights(X_valid, y_valid)
            # ê¸°ì¡´ ê°€ì¤‘ì¹˜ì™€ ìë™ ê°€ì¤‘ì¹˜ ê²°í•©
            final_weights = auto_weights
        else:
            final_weights = self.weights.copy()
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        if final_weights:
            # ì„¤ì •ëœ ëª¨ë¸ë§Œ ì‚¬ìš©
            available_models = set(individual_predictions.keys())
            final_weights = {k: v for k, v in final_weights.items() if k in available_models}
            
            if final_weights:
                total_weight = sum(final_weights.values())
                final_weights = {k: v/total_weight for k, v in final_weights.items()}
            else:
                # ê°€ì¤‘ì¹˜ê°€ ì—†ìœ¼ë©´ ê· ë“± ê°€ì¤‘ì¹˜
                final_weights = {name: 1.0/len(individual_predictions) 
                               for name in individual_predictions.keys()}
        else:
            # ê°€ì¤‘ì¹˜ê°€ ì—†ìœ¼ë©´ ê· ë“± ê°€ì¤‘ì¹˜
            final_weights = {name: 1.0/len(individual_predictions) 
                           for name in individual_predictions.keys()}
        
        print(f"ğŸ¯ ìµœì¢… ê°€ì¤‘ì¹˜:")
        for name, weight in final_weights.items():
            print(f"  {name}: {weight:.4f}")
        
        # ì•™ìƒë¸” ë°©ë²•ì— ë”°ë¥¸ ì˜ˆì¸¡
        if self.method == 'weighted_average':
            ensemble_pred = self._weighted_average(individual_predictions, final_weights)
        elif self.method == 'voting':
            ensemble_pred = self._majority_voting(individual_predictions, final_weights)
        elif self.method == 'stacking':
            ensemble_pred = self._stacking_prediction(individual_predictions, X)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•™ìƒë¸” ë°©ë²•: {self.method}")
        
        self.final_prediction = ensemble_pred
        return ensemble_pred
    
    def _weighted_average(self, predictions, weights):
        """ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”"""
        if not predictions:
            raise ValueError("ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì²« ë²ˆì§¸ ì˜ˆì¸¡ ê²°ê³¼ì˜ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
        first_pred = next(iter(predictions.values()))
        expected_length = len(first_pred)
        ensemble_pred = np.zeros(expected_length)
        
        print(f"ğŸ” ê°€ì¤‘ í‰ê·  ê³„ì‚°: ì˜ˆìƒ ê¸¸ì´={expected_length}")
        
        for model_name, pred in predictions.items():
            weight = weights.get(model_name, 0)
            
            # ì˜ˆì¸¡ ê²°ê³¼ í¬ê¸° í™•ì¸
            if len(pred) != expected_length:
                print(f"âš ï¸ {model_name} ì˜ˆì¸¡ í¬ê¸° ë¶ˆì¼ì¹˜: ì˜ˆìƒ={expected_length}, ì‹¤ì œ={len(pred)}")
                # í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´
                pred = np.full(expected_length, 0.5)
            
            ensemble_pred += weight * pred
            print(f"  {model_name}: ê°€ì¤‘ì¹˜={weight:.4f}, ì˜ˆì¸¡ê¸¸ì´={len(pred)}")
        
        print(f"âœ… ê°€ì¤‘ í‰ê·  ì™„ë£Œ: ê²°ê³¼ ê¸¸ì´={len(ensemble_pred)}")
        return ensemble_pred
    
    def _majority_voting(self, predictions, weights):
        """ê°€ì¤‘ ë‹¤ìˆ˜ê²° íˆ¬í‘œ"""
        ensemble_pred = np.zeros(len(next(iter(predictions.values()))))
        
        for model_name, pred in predictions.items():
            weight = weights.get(model_name, 0)
            # 0.5 ê¸°ì¤€ìœ¼ë¡œ ì´ì§„ ë¶„ë¥˜ í›„ ê°€ì¤‘ì¹˜ ì ìš©
            binary_pred = (pred >= 0.5).astype(float)
            ensemble_pred += weight * binary_pred
        
        return ensemble_pred
    
    def _stacking_prediction(self, predictions, X):
        """ìŠ¤íƒœí‚¹ ì•™ìƒë¸” (ê°„ë‹¨í•œ ì„ í˜• ê²°í•©)"""
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì„ í˜• ê²°í•©ìœ¼ë¡œ êµ¬í˜„
        # ì‹¤ì œë¡œëŠ” ë©”íƒ€ ëª¨ë¸ì„ í›ˆë ¨í•´ì•¼ í•¨
        return self._weighted_average(predictions, self.weights)
    
    def evaluate_ensemble(self, X, y, threshold=0.5):
        """
        ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        
        Args:
            X: í…ŒìŠ¤íŠ¸ íŠ¹ì„±
            y: í…ŒìŠ¤íŠ¸ ë¼ë²¨
            threshold: ë¶„ë¥˜ ì„ê³„ê°’
            
        Returns:
            dict: ì„±ëŠ¥ ë©”íŠ¸ë¦­
        """
        print(f"\nğŸ“Š ì•™ìƒë¸” ëª¨ë¸ í‰ê°€ (threshold={threshold})")
        print("="*50)
        
        # í•­ìƒ ìƒˆë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ (ë°ì´í„° í¬ê¸° ë¶ˆì¼ì¹˜ ë°©ì§€)
        ensemble_proba = self.ensemble_predict_proba(X)
        
        # ë°ì´í„° í¬ê¸° í™•ì¸
        print(f"ğŸ” ë°ì´í„° í¬ê¸° í™•ì¸: X={len(X)}, y={len(y)}, ensemble_proba={len(ensemble_proba)}")
        
        # í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ì˜¤ë¥˜ ë°œìƒ
        if len(ensemble_proba) != len(y):
            raise ValueError(f"ì˜ˆì¸¡ ê²°ê³¼ì™€ ë¼ë²¨ì˜ í¬ê¸°ê°€ ë‹¤ë¦…ë‹ˆë‹¤: ì˜ˆì¸¡={len(ensemble_proba)}, ë¼ë²¨={len(y)}")
        
        # ì´ì§„ ì˜ˆì¸¡
        ensemble_pred = (ensemble_proba >= threshold).astype(int)
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = {
            'auc': roc_auc_score(y, ensemble_proba),
            'precision': precision_score(y, ensemble_pred, zero_division=0),
            'recall': recall_score(y, ensemble_pred, zero_division=0),
            'f1': f1_score(y, ensemble_pred, zero_division=0),
            'balanced_accuracy': balanced_accuracy_score(y, ensemble_pred),
            'average_precision': average_precision_score(y, ensemble_proba)
        }
        
        self.performance_metrics = metrics
        
        print(f"ğŸ¯ ì•™ìƒë¸” ì„±ëŠ¥:")
        for metric, value in metrics.items():
            print(f"  {metric.upper()}: {value:.4f}")
        
        return metrics
    
    def find_optimal_threshold(self, X_valid, y_valid, metric='f1'):
        """
        ìµœì  ì„ê³„ê°’ ì°¾ê¸°
        
        Args:
            X_valid: ê²€ì¦ íŠ¹ì„±
            y_valid: ê²€ì¦ ë¼ë²¨
            metric: ìµœì í™”í•  ë©”íŠ¸ë¦­
            
        Returns:
            tuple: (ìµœì  ì„ê³„ê°’, ì„±ëŠ¥ ë©”íŠ¸ë¦­)
        """
        print(f"\nğŸ¯ ì•™ìƒë¸” ìµœì  Threshold íƒìƒ‰ ({metric})")
        print("="*50)
        
        # ì•™ìƒë¸” ì˜ˆì¸¡ í™•ë¥ 
        ensemble_proba = self.ensemble_predict_proba(X_valid)
        
        # ë‹¤ì–‘í•œ ì„ê³„ê°’ì—ì„œ ì„±ëŠ¥ ê³„ì‚°
        thresholds = np.arange(0.05, 0.95, 0.05)
        threshold_results = []
        
        for threshold in thresholds:
            pred = (ensemble_proba >= threshold).astype(int)
            
            if len(np.unique(pred)) == 1:
                continue
            
            try:
                metrics = {
                    'threshold': threshold,
                    'precision': precision_score(y_valid, pred, zero_division=0),
                    'recall': recall_score(y_valid, pred, zero_division=0),
                    'f1': f1_score(y_valid, pred, zero_division=0),
                    'balanced_accuracy': balanced_accuracy_score(y_valid, pred)
                }
                threshold_results.append(metrics)
            except:
                continue
        
        if not threshold_results:
            print("âš ï¸ ìµœì  threshold ì°¾ê¸° ì‹¤íŒ¨, ê¸°ë³¸ê°’ 0.5 ì‚¬ìš©")
            return 0.5, {}
        
        # ìµœì  ì„ê³„ê°’ ì„ íƒ
        threshold_df = pd.DataFrame(threshold_results)
        best_idx = threshold_df[metric].idxmax()
        optimal_threshold = threshold_df.loc[best_idx, 'threshold']
        best_metrics = threshold_df.loc[best_idx].to_dict()
        
        print(f"âœ… ìµœì  Threshold: {optimal_threshold:.3f}")
        print(f"ğŸ“Š ìµœì  ì„±ëŠ¥:")
        for m, v in best_metrics.items():
            if m != 'threshold':
                print(f"  {m.upper()}: {v:.4f}")
        
        return optimal_threshold, best_metrics
    
    def save_model(self, filepath):
        """ì•™ìƒë¸” ëª¨ë¸ ì €ì¥"""
        ensemble_data = {
            'config': self.config,
            'method': self.method,
            'weights': self.weights,
            'auto_weight': self.auto_weight,
            'performance_metrics': self.performance_metrics,
            'model_names': list(self.base_models.keys())
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(ensemble_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ì•™ìƒë¸” ëª¨ë¸ ì €ì¥: {filepath}")
    
    def create_ensemble_report(self, output_dir):
        """ì•™ìƒë¸” ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ê°œë³„ ëª¨ë¸ vs ì•™ìƒë¸” ë¹„êµ ì‹œê°í™”
        if self.predictions and self.final_prediction is not None:
            self._plot_model_comparison(output_dir)
        
        # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì‹œê°í™”
        if self.weights:
            self._plot_weights(output_dir)
    
    def _plot_model_comparison(self, output_dir):
        """ê°œë³„ ëª¨ë¸ vs ì•™ìƒë¸” ì˜ˆì¸¡ ë¹„êµ"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ê°œë³„ ëª¨ë¸ vs ì•™ìƒë¸” ì˜ˆì¸¡ ë¹„êµ', fontsize=16, fontweight='bold')
        
        # ì˜ˆì¸¡ ë¶„í¬ ë¹„êµ
        ax = axes[0, 0]
        for model_name, pred in self.predictions.items():
            ax.hist(pred, alpha=0.6, bins=30, label=model_name, density=True)
        ax.hist(self.final_prediction, alpha=0.8, bins=30, label='Ensemble', 
                density=True, color='red', linewidth=2, histtype='step')
        ax.set_xlabel('ì˜ˆì¸¡ í™•ë¥ ')
        ax.set_ylabel('ë°€ë„')
        ax.set_title('ì˜ˆì¸¡ í™•ë¥  ë¶„í¬')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # ì˜ˆì¸¡ ìƒê´€ê´€ê³„
        ax = axes[0, 1]
        model_names = list(self.predictions.keys())
        if len(model_names) >= 2:
            x_pred = self.predictions[model_names[0]]
            y_pred = self.predictions[model_names[1]]
            ax.scatter(x_pred, y_pred, alpha=0.6, s=20)
            ax.plot([0, 1], [0, 1], 'r--', alpha=0.8)
            ax.set_xlabel(f'{model_names[0]} ì˜ˆì¸¡')
            ax.set_ylabel(f'{model_names[1]} ì˜ˆì¸¡')
            ax.set_title('ëª¨ë¸ ê°„ ì˜ˆì¸¡ ìƒê´€ê´€ê³„')
            ax.grid(True, alpha=0.3)
        
        # ì•™ìƒë¸” vs ê°œë³„ ëª¨ë¸
        ax = axes[1, 0]
        for model_name, pred in self.predictions.items():
            ax.scatter(pred, self.final_prediction, alpha=0.6, s=20, label=model_name)
        ax.plot([0, 1], [0, 1], 'r--', alpha=0.8)
        ax.set_xlabel('ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡')
        ax.set_ylabel('ì•™ìƒë¸” ì˜ˆì¸¡')
        ax.set_title('ì•™ìƒë¸” vs ê°œë³„ ëª¨ë¸')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # ê°€ì¤‘ì¹˜ ë§‰ëŒ€ ê·¸ë˜í”„
        ax = axes[1, 1]
        if self.weights:
            names = list(self.weights.keys())
            weights = list(self.weights.values())
            bars = ax.bar(names, weights, alpha=0.7, color='skyblue')
            ax.set_ylabel('ê°€ì¤‘ì¹˜')
            ax.set_title('ì•™ìƒë¸” ê°€ì¤‘ì¹˜')
            ax.tick_params(axis='x', rotation=45)
            
            # ê°€ì¤‘ì¹˜ ê°’ í‘œì‹œ
            for bar, weight in zip(bars, weights):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                       f'{weight:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig(output_dir / 'ensemble_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ… ì•™ìƒë¸” ë¶„ì„ ì €ì¥: ensemble_analysis.png")
    
    def _plot_weights(self, output_dir):
        """ê°€ì¤‘ì¹˜ ì‹œê°í™”"""
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        
        names = list(self.weights.keys())
        weights = list(self.weights.values())
        
        # íŒŒì´ ì°¨íŠ¸
        colors = plt.cm.Set3(np.linspace(0, 1, len(names)))
        wedges, texts, autotexts = ax.pie(weights, labels=names, autopct='%1.2f%%',
                                         colors=colors, startangle=90)
        
        ax.set_title('ì•™ìƒë¸” ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¶„í¬', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(output_dir / 'ensemble_weights.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ… ê°€ì¤‘ì¹˜ ë¶„í¬ ì €ì¥: ensemble_weights.png")


def create_ensemble_from_results(results_dict, config):
    """
    ì‹¤í–‰ ê²°ê³¼ì—ì„œ ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
    
    Args:
        results_dict (dict): ëª¨ë¸ ì‹¤í–‰ ê²°ê³¼
        config (dict): ì•™ìƒë¸” ì„¤ì •
        
    Returns:
        EnsembleModel: ìƒì„±ëœ ì•™ìƒë¸” ëª¨ë¸
    """
    ensemble = EnsembleModel(config)
    
    # ê¸°ë³¸ ëª¨ë¸ë“¤ì„ ì•™ìƒë¸”ì— ì¶”ê°€
    ensemble_config = config.get('ensemble', {})
    enabled_models = ensemble_config.get('models', [])
    
    for model_key, model_obj in results_dict.items():
        if any(enabled_model in model_key for enabled_model in enabled_models):
            ensemble.add_model(model_key, model_obj)
    
    return ensemble 