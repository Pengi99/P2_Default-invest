"""
XGBoost ëª¨ë¸ - Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° K-fold CV
"""

import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import (
    roc_auc_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, roc_curve, auc
)
import optuna
from optuna.samplers import TPESampler
import joblib
from typing import Dict, Any
import os

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic' if plt.matplotlib.get_backend() != 'Agg' else 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class XGBoostOptimizer:
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.best_model = None
        self.best_params = None
        self.best_score = None
        self.study = None
        self.cv_results = {}
        
    def objective(self, trial, X_train, y_train, cv_folds=5):
        """Optuna ëª©ì  í•¨ìˆ˜"""
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„
        params = {
            'objective': 'binary:logistic',
            'eval_metric': 'auc',
            'booster': 'gbtree',
            'random_state': self.random_state,
            'verbosity': 0,
            
            # í•™ìŠµë¥  ë° ë¶€ìŠ¤íŒ… ê´€ë ¨
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            
            # íŠ¸ë¦¬ êµ¬ì¡° ê´€ë ¨
            'max_depth': trial.suggest_int('max_depth', 3, 10),
            'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),
            
            # ì •ê·œí™” ê´€ë ¨
            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),
            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),
            
            # ìƒ˜í”Œë§ ê´€ë ¨
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0),
            
            # ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬
            'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 10)
        }
        
        # ëª¨ë¸ ìƒì„±
        model = XGBClassifier(**params)
        
        # Stratified K-fold Cross Validation
        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=self.random_state)
        
        # AUC ì ìˆ˜ ê³„ì‚°
        auc_scores = cross_val_score(
            model, X_train, y_train, 
            cv=skf, scoring='roc_auc', n_jobs=-1
        )
        
        return auc_scores.mean()
    
    def optimize(self, X_train, y_train, n_trials=100, cv_folds=5):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”"""
        print("ğŸš€ XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘")
        print("="*60)
        
        # Optuna study ìƒì„±
        sampler = TPESampler(seed=self.random_state)
        self.study = optuna.create_study(
            direction='maximize',
            sampler=sampler,
            study_name='xgboost_optimization'
        )
        
        # ìµœì í™” ì‹¤í–‰
        self.study.optimize(
            lambda trial: self.objective(trial, X_train, y_train, cv_folds),
            n_trials=n_trials,
            show_progress_bar=True
        )
        
        # ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥
        self.best_params = self.study.best_params
        self.best_score = self.study.best_value
        
        print(f"âœ… ìµœì í™” ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœì  AUC: {self.best_score:.4f}")
        print(f"ğŸ¯ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
        for key, value in self.best_params.items():
            print(f"   {key}: {value}")
        
        return self.best_params, self.best_score
    
    def train_best_model(self, X_train: pd.DataFrame, y_train: pd.Series, 
                        X_val: pd.DataFrame, y_val: pd.Series, 
                        best_params: Dict[str, Any]) -> XGBClassifier:
        """Train the best model with optimized parameters."""
        print("ğŸ¯ ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í›ˆë ¨")
        print(f"   íŒŒë¼ë¯¸í„°: {best_params}")
        
        # ìµœì  ëª¨ë¸ í›ˆë ¨
        model = XGBClassifier(**best_params)
        
        # Early stoppingì„ ìœ„í•œ evaluation set
        eval_set = [(X_train, y_train), (X_val, y_val)]
        
        model.fit(
            X_train, y_train,
            eval_set=eval_set,
            verbose=False
        )
        
        print("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        return model
    
    def evaluate_test(self, X_test: pd.DataFrame, y_test: pd.Series, model: XGBClassifier = None) -> Dict[str, float]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€"""
        if model is None:
            model = self.best_model
            
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1]
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        metrics = {
            'auc': roc_auc_score(y_test, y_proba),
            'precision': precision_score(y_test, y_pred),
            'recall': recall_score(y_test, y_pred),
            'f1': f1_score(y_test, y_pred)
        }
        
        print(f"ğŸ¯ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ëŠ¥:")
        print(f"   AUC: {metrics['auc']:.4f}")
        print(f"   Precision: {metrics['precision']:.4f}")
        print(f"   Recall: {metrics['recall']:.4f}")
        print(f"   F1-Score: {metrics['f1']:.4f}")
        
        return metrics
    
    def plot_results(self, X_test, y_test, feature_names, save_path='outputs/visualizations/'):
        """ê²°ê³¼ ì‹œê°í™”"""
        print("\nğŸ“Š ê²°ê³¼ ì‹œê°í™” ìƒì„±")
        print("="*60)
        
        # ì˜ˆì¸¡ ê²°ê³¼
        y_test_pred = self.best_model.predict(X_test)
        y_test_proba = self.best_model.predict_proba(X_test)[:, 1]
        
        # ì‹œê°í™” ì„¤ì •
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('XGBoost ëª¨ë¸ ê²°ê³¼', fontsize=16, fontweight='bold')
        
        # 1. ROC ê³¡ì„ 
        fpr, tpr, _ = roc_curve(y_test, y_test_proba)
        roc_auc = auc(fpr, tpr)
        
        axes[0, 0].plot(fpr, tpr, color='darkorange', lw=2, 
                       label=f'ROC curve (AUC = {roc_auc:.4f})')
        axes[0, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        axes[0, 0].set_xlim([0.0, 1.0])
        axes[0, 0].set_ylim([0.0, 1.05])
        axes[0, 0].set_xlabel('False Positive Rate')
        axes[0, 0].set_ylabel('True Positive Rate')
        axes[0, 0].set_title('ROC ê³¡ì„ ')
        axes[0, 0].legend(loc="lower right")
        axes[0, 0].grid(True)
        
        # 2. í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y_test, y_test_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1])
        axes[0, 1].set_title('í˜¼ë™ í–‰ë ¬')
        axes[0, 1].set_xlabel('ì˜ˆì¸¡ê°’')
        axes[0, 1].set_ylabel('ì‹¤ì œê°’')
        
        # 3. íŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ)
        importances = self.best_model.feature_importances_
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importances
        }).sort_values(by='importance', ascending=False).head(10)
        
        axes[1, 0].barh(importance_df['feature'], importance_df['importance'], color='purple')
        axes[1, 0].set_title('íŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ)')
        axes[1, 0].set_xlabel('ì¤‘ìš”ë„')
        
        # 4. ìµœì í™” íˆìŠ¤í† ë¦¬
        if hasattr(self.study, 'trials'):
            trial_values = [trial.value for trial in self.study.trials if trial.value is not None]
            axes[1, 1].plot(trial_values, 'b-', alpha=0.7)
            axes[1, 1].axhline(y=max(trial_values), color='r', linestyle='--', 
                              label=f'Best: {max(trial_values):.4f}')
            axes[1, 1].set_title('ìµœì í™” íˆìŠ¤í† ë¦¬')
            axes[1, 1].set_xlabel('Trial')
            axes[1, 1].set_ylabel('AUC Score')
            axes[1, 1].legend()
            axes[1, 1].grid(True)
        
        plt.tight_layout()
        
        # ì €ì¥
        os.makedirs(save_path, exist_ok=True)
        plt.savefig(f'{save_path}/xgboost_results.png', dpi=300, bbox_inches='tight')
        print(f"âœ… ì‹œê°í™” ì €ì¥: {save_path}/xgboost_results.png")
        
        plt.show()
    
    def plot_learning_curves(self, save_path='outputs/visualizations/'):
        """í•™ìŠµ ê³¡ì„  ì‹œê°í™”"""
        if hasattr(self.best_model, 'evals_result_'):
            print("\nğŸ“ˆ í•™ìŠµ ê³¡ì„  ì‹œê°í™”")
            
            results = self.best_model.evals_result_
            epochs = len(results['train']['auc'])
            x_axis = range(0, epochs)
            
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(x_axis, results['train']['auc'], label='Train')
            ax.plot(x_axis, results['valid']['auc'], label='Valid')
            ax.axvline(x=self.best_model.best_iteration, color='red', linestyle='--', 
                      label=f'Best Iteration ({self.best_model.best_iteration})')
            ax.legend()
            ax.set_ylabel('AUC')
            ax.set_xlabel('Epoch')
            ax.set_title('XGBoost í•™ìŠµ ê³¡ì„ ')
            ax.grid(True)
            
            # ì €ì¥
            os.makedirs(save_path, exist_ok=True)
            plt.savefig(f'{save_path}/xgboost_learning_curves.png', dpi=300, bbox_inches='tight')
            print(f"âœ… í•™ìŠµ ê³¡ì„  ì €ì¥: {save_path}/xgboost_learning_curves.png")
            
            plt.show()
    
    def save_results(self, test_metrics: Dict[str, float], feature_names: list, 
                    model: XGBClassifier = None, best_params: Dict[str, Any] = None):
        """ê²°ê³¼ ì €ì¥"""
        if model is None:
            model = self.best_model
            
        # ëª¨ë¸ ì €ì¥
        model_path = 'outputs/models/xgboost_best_model.joblib'
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        joblib.dump(model, model_path)
        print(f"âœ… ëª¨ë¸ ì €ì¥: {model_path}")
        
        # ê²°ê³¼ ì €ì¥
        results = {
            'model_type': 'XGBoost',
            'best_params': best_params if best_params else self.best_params,
            'test_metrics': test_metrics,
            'feature_names': feature_names,
            'timestamp': datetime.now().isoformat()
        }
        
        results_path = 'outputs/models/xgboost_results.json'
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"âœ… ê²°ê³¼ ì €ì¥: {results_path}")
        
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¢ í•œêµ­ ê¸°ì—… ë¶€ì‹¤ì˜ˆì¸¡ - XGBoost ëª¨ë¸")
    print("="*60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("ğŸ“‚ ë°ì´í„° ë¡œë“œ")
    
    # SMOTE ë²„ì „ ë°ì´í„° ë¡œë“œ
    X_train = pd.read_csv('data_new/final/X_train_smote.csv')
    X_valid = pd.read_csv('data_new/final/X_valid_smote.csv')
    X_test = pd.read_csv('data_new/final/X_test_smote.csv')
    
    y_train = pd.read_csv('data_new/final/y_train_smote.csv').iloc[:, 0]
    y_valid = pd.read_csv('data_new/final/y_valid_smote.csv').iloc[:, 0]
    y_test = pd.read_csv('data_new/final/y_test_smote.csv').iloc[:, 0]
    
    feature_names = X_train.columns.tolist()
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"   í›ˆë ¨: {X_train.shape}, ê²€ì¦: {X_valid.shape}, í…ŒìŠ¤íŠ¸: {X_test.shape}")
    print(f"   íŠ¹ì„± ìˆ˜: {len(feature_names)}")
    print(f"   í›ˆë ¨ ë¶€ì‹¤ ë¹„ìœ¨: {y_train.mean():.2%}")
    
    # 2. ëª¨ë¸ ìµœì í™”
    optimizer = XGBoostOptimizer(random_state=42)
    best_params, best_score = optimizer.optimize(X_train, y_train, n_trials=100, cv_folds=5)
    
    # ìµœì  ëª¨ë¸ í›ˆë ¨
    print("\nğŸš€ ìµœì  ëª¨ë¸ í›ˆë ¨ (Early Stopping)")
    print("="*60)
    best_model = optimizer.train_best_model(X_train, y_train, X_valid, y_valid, best_params)
    
    # ê²€ì¦ ë°ì´í„° í‰ê°€
    print("\nğŸ“Š ê²€ì¦ ë°ì´í„° ì„±ëŠ¥ í‰ê°€")
    print("="*60)
    y_valid_pred = best_model.predict(X_valid)
    y_valid_proba = best_model.predict_proba(X_valid)[:, 1]
    
    valid_metrics = {
        'auc': roc_auc_score(y_valid, y_valid_proba),
        'precision': precision_score(y_valid, y_valid_pred),
        'recall': recall_score(y_valid, y_valid_pred),
        'f1': f1_score(y_valid, y_valid_pred),
        'cv_score': best_score
    }
    
    print(f"ğŸ“ˆ ê²€ì¦ ë°ì´í„° ì„±ëŠ¥:")
    print(f"   AUC: {valid_metrics['auc']:.4f}")
    print(f"   Precision: {valid_metrics['precision']:.4f}")
    print(f"   Recall: {valid_metrics['recall']:.4f}")
    print(f"   F1-Score: {valid_metrics['f1']:.4f}")
    print(f"   CV Score: {valid_metrics['cv_score']:.4f}")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
    print("\nğŸ¯ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìµœì¢… í‰ê°€")
    print("="*60)
    test_metrics = optimizer.evaluate_test(X_test, y_test, best_model)
    
    # ëª¨ë¸ ì €ì¥
    print("\nğŸ’¾ ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥")
    print("="*60)
    optimizer.save_results(test_metrics, feature_names, best_model, best_params)
    
    print("\nğŸ‰ XGBoost ëª¨ë¸ë§ ì™„ë£Œ!")
    print("ğŸ“Š ëª¨ë“  ê²°ê³¼ëŠ” outputs/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
