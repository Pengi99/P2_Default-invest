"""
ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ - Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° K-fold CV
"""

import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import (
    roc_auc_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, roc_curve, auc
)
from sklearn.preprocessing import StandardScaler
import optuna
from optuna.samplers import TPESampler
import joblib

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic' if plt.matplotlib.get_backend() != 'Agg' else 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class LogisticRegressionOptimizer:
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.best_model = None
        self.best_params = None
        self.best_score = None
        self.study = None
        self.cv_results = {}
        
    def objective(self, trial, X_train, y_train, cv_folds=5):
        """Optuna ëª©ì  í•¨ìˆ˜"""
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„
        params = {
            'penalty': trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet']),
            'C': trial.suggest_float('C', 1e-4, 100, log=True),
            'solver': 'saga',  # l1, l2, elasticnet ëª¨ë‘ ì§€ì›
            'max_iter': trial.suggest_int('max_iter', 100, 2000),
            'random_state': self.random_state
        }
        
        # elasticnetì¸ ê²½ìš° l1_ratio ì¶”ê°€
        if params['penalty'] == 'elasticnet':
            params['l1_ratio'] = trial.suggest_float('l1_ratio', 0.1, 0.9)
        
        # ëª¨ë¸ ìƒì„±
        model = LogisticRegression(**params)
        
        # Stratified K-fold Cross Validation
        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=self.random_state)
        
        # AUC ì ìˆ˜ ê³„ì‚°
        auc_scores = cross_val_score(
            model, X_train, y_train, 
            cv=skf, scoring='roc_auc', n_jobs=-1
        )
        
        return auc_scores.mean()
    
    def optimize(self, X_train, y_train, n_trials=100, cv_folds=5):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”"""
        print("ğŸ” ë¡œì§€ìŠ¤í‹± íšŒê·€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘")
        print("="*60)
        
        # Optuna study ìƒì„±
        sampler = TPESampler(seed=self.random_state)
        self.study = optuna.create_study(
            direction='maximize',
            sampler=sampler,
            study_name='logistic_regression_optimization'
        )
        
        # ìµœì í™” ì‹¤í–‰
        self.study.optimize(
            lambda trial: self.objective(trial, X_train, y_train, cv_folds),
            n_trials=n_trials,
            show_progress_bar=True
        )
        
        # ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥
        self.best_params = self.study.best_params
        self.best_score = self.study.best_value
        
        print(f"âœ… ìµœì í™” ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœì  AUC: {self.best_score:.4f}")
        print(f"ğŸ¯ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
        for key, value in self.best_params.items():
            print(f"   {key}: {value}")
        
        return self.best_params, self.best_score
    
    def train_best_model(self, X_train, y_train, X_valid, y_valid):
        """ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í›ˆë ¨"""
        print("\nğŸš€ ìµœì  ëª¨ë¸ í›ˆë ¨")
        print("="*60)
        
        # ìµœì  ëª¨ë¸ ìƒì„±
        self.best_model = LogisticRegression(**self.best_params)
        self.best_model.fit(X_train, y_train)
        
        # ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡
        y_valid_pred = self.best_model.predict(X_valid)
        y_valid_proba = self.best_model.predict_proba(X_valid)[:, 1]
        
        # ì„±ëŠ¥ í‰ê°€
        metrics = {
            'auc': roc_auc_score(y_valid, y_valid_proba),
            'precision': precision_score(y_valid, y_valid_pred),
            'recall': recall_score(y_valid, y_valid_pred),
            'f1': f1_score(y_valid, y_valid_pred)
        }
        
        print(f"ğŸ“ˆ ê²€ì¦ ë°ì´í„° ì„±ëŠ¥:")
        print(f"   AUC: {metrics['auc']:.4f}")
        print(f"   Precision: {metrics['precision']:.4f}")
        print(f"   Recall: {metrics['recall']:.4f}")
        print(f"   F1-Score: {metrics['f1']:.4f}")
        
        return metrics
    
    def evaluate_test(self, X_test, y_test):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€"""
        print("\nğŸ¯ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìµœì¢… í‰ê°€")
        print("="*60)
        
        # ì˜ˆì¸¡
        y_test_pred = self.best_model.predict(X_test)
        y_test_proba = self.best_model.predict_proba(X_test)[:, 1]
        
        # ì„±ëŠ¥ ì§€í‘œ
        test_metrics = {
            'auc': roc_auc_score(y_test, y_test_proba),
            'precision': precision_score(y_test, y_test_pred),
            'recall': recall_score(y_test, y_test_pred),
            'f1': f1_score(y_test, y_test_pred)
        }
        
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
        for metric, value in test_metrics.items():
            print(f"   {metric.upper()}: {value:.4f}")
        
        # ë¶„ë¥˜ ë¦¬í¬íŠ¸
        print(f"\nğŸ“‹ ìƒì„¸ ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
        print(classification_report(y_test, y_test_pred))
        
        return test_metrics, y_test_pred, y_test_proba
    
    def plot_results(self, X_test, y_test, feature_names, save_path='outputs/visualizations/'):
        """ê²°ê³¼ ì‹œê°í™”"""
        print("\nğŸ“Š ê²°ê³¼ ì‹œê°í™” ìƒì„±")
        print("="*60)
        
        # ì˜ˆì¸¡ ê²°ê³¼
        y_test_pred = self.best_model.predict(X_test)
        y_test_proba = self.best_model.predict_proba(X_test)[:, 1]
        
        # ì‹œê°í™” ì„¤ì •
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ê²°ê³¼', fontsize=16, fontweight='bold')
        
        # 1. ROC ê³¡ì„ 
        fpr, tpr, _ = roc_curve(y_test, y_test_proba)
        roc_auc = auc(fpr, tpr)
        
        axes[0, 0].plot(fpr, tpr, color='darkorange', lw=2, 
                       label=f'ROC curve (AUC = {roc_auc:.4f})')
        axes[0, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        axes[0, 0].set_xlim([0.0, 1.0])
        axes[0, 0].set_ylim([0.0, 1.05])
        axes[0, 0].set_xlabel('False Positive Rate')
        axes[0, 0].set_ylabel('True Positive Rate')
        axes[0, 0].set_title('ROC ê³¡ì„ ')
        axes[0, 0].legend(loc="lower right")
        axes[0, 0].grid(True)
        
        # 2. í˜¼ë™ í–‰ë ¬
        cm = confusion_matrix(y_test, y_test_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1])
        axes[0, 1].set_title('í˜¼ë™ í–‰ë ¬')
        axes[0, 1].set_xlabel('ì˜ˆì¸¡ê°’')
        axes[0, 1].set_ylabel('ì‹¤ì œê°’')
        
        # 3. íŠ¹ì„± ê³„ìˆ˜ (ìƒìœ„ 10ê°œ)
        coefficients = self.best_model.coef_[0]
        coef_df = pd.DataFrame({
            'feature': feature_names,
            'coefficient': coefficients
        }).sort_values(by='coefficient', key=abs, ascending=False).head(10)
        
        colors = ['red' if x < 0 else 'blue' for x in coef_df['coefficient']]
        axes[1, 0].barh(coef_df['feature'], coef_df['coefficient'], color=colors)
        axes[1, 0].set_title('íŠ¹ì„± ê³„ìˆ˜ (ìƒìœ„ 10ê°œ)')
        axes[1, 0].set_xlabel('ê³„ìˆ˜ ê°’')
        
        # 4. ìµœì í™” íˆìŠ¤í† ë¦¬
        if hasattr(self.study, 'trials'):
            trial_values = [trial.value for trial in self.study.trials if trial.value is not None]
            axes[1, 1].plot(trial_values, 'b-', alpha=0.7)
            axes[1, 1].axhline(y=max(trial_values), color='r', linestyle='--', 
                              label=f'Best: {max(trial_values):.4f}')
            axes[1, 1].set_title('ìµœì í™” íˆìŠ¤í† ë¦¬')
            axes[1, 1].set_xlabel('Trial')
            axes[1, 1].set_ylabel('AUC Score')
            axes[1, 1].legend()
            axes[1, 1].grid(True)
        
        plt.tight_layout()
        
        # ì €ì¥
        import os
        os.makedirs(save_path, exist_ok=True)
        plt.savefig(f'{save_path}/logistic_regression_results.png', dpi=300, bbox_inches='tight')
        print(f"âœ… ì‹œê°í™” ì €ì¥: {save_path}/logistic_regression_results.png")
        
        plt.show()
    
    def save_results(self, test_metrics, feature_names, save_path='outputs/models/'):
        """ê²°ê³¼ ì €ì¥"""
        print("\nğŸ’¾ ê²°ê³¼ ì €ì¥")
        print("="*60)
        
        import os
        os.makedirs(save_path, exist_ok=True)
        
        # 1. ëª¨ë¸ ì €ì¥
        model_path = f'{save_path}/logistic_regression_best_model.joblib'
        joblib.dump(self.best_model, model_path)
        print(f"âœ… ëª¨ë¸ ì €ì¥: {model_path}")
        
        # 2. ê²°ê³¼ ì •ë³´ ì €ì¥
        results = {
            'model_name': 'LogisticRegression',
            'optimization_date': datetime.now().isoformat(),
            'best_params': self.best_params,
            'cv_best_score': self.best_score,
            'test_metrics': test_metrics,
            'feature_names': feature_names,
            'feature_coefficients': {
                name: float(coef) for name, coef in 
                zip(feature_names, self.best_model.coef_[0])
            }
        }
        
        results_path = f'{save_path}/logistic_regression_results.json'
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"âœ… ê²°ê³¼ ì €ì¥: {results_path}")
        
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¢ í•œêµ­ ê¸°ì—… ë¶€ì‹¤ì˜ˆì¸¡ - ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸")
    print("="*60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("ğŸ“‚ ë°ì´í„° ë¡œë“œ")
    
    # SMOTE ë²„ì „ ë°ì´í„° ë¡œë“œ
    X_train = pd.read_csv('data_new/final/X_train_smote.csv')
    X_valid = pd.read_csv('data_new/final/X_valid_smote.csv')
    X_test = pd.read_csv('data_new/final/X_test_smote.csv')
    
    y_train = pd.read_csv('data_new/final/y_train_smote.csv').iloc[:, 0]
    y_valid = pd.read_csv('data_new/final/y_valid_smote.csv').iloc[:, 0]
    y_test = pd.read_csv('data_new/final/y_test_smote.csv').iloc[:, 0]
    
    feature_names = X_train.columns.tolist()
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"   í›ˆë ¨: {X_train.shape}, ê²€ì¦: {X_valid.shape}, í…ŒìŠ¤íŠ¸: {X_test.shape}")
    print(f"   íŠ¹ì„± ìˆ˜: {len(feature_names)}")
    print(f"   í›ˆë ¨ ë¶€ì‹¤ ë¹„ìœ¨: {y_train.mean():.2%}")
    
    # 2. ëª¨ë¸ ìµœì í™”
    optimizer = LogisticRegressionOptimizer(random_state=42)
    best_params, best_score = optimizer.optimize(X_train, y_train, n_trials=100, cv_folds=5)
    
    # 3. ìµœì  ëª¨ë¸ í›ˆë ¨
    valid_metrics = optimizer.train_best_model(X_train, y_train, X_valid, y_valid)
    
    # 4. í…ŒìŠ¤íŠ¸ í‰ê°€
    test_metrics, y_pred, y_proba = optimizer.evaluate_test(X_test, y_test)
    
    # 5. ì‹œê°í™”
    optimizer.plot_results(X_test, y_test, feature_names)
    
    # 6. ê²°ê³¼ ì €ì¥
    results = optimizer.save_results(test_metrics, feature_names)
    
    print("\nğŸ‰ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ë§ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ AUC: {test_metrics['auc']:.4f}")

if __name__ == "__main__":
    main()
