"""
Factor Backtesting Framework v3.0
Daily Data-Based Backtesting with 4 Core Strategies
Enhanced with business day handling, forward-fill, and robust return calculations
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import glob
import os
import yaml
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from scipy import stats
from pathlib import Path
from multiprocessing import Pool, cpu_count
import multiprocessing

# Optimize multiprocessing start method for better performance on macOS
if __name__ == "__main__":
    try:
        multiprocessing.set_start_method('fork', force=True)
    except RuntimeError:
        pass  # Already set

# Performance optimization libraries
try:
    import polars as pl
    POLARS_AVAILABLE = True
except ImportError:
    POLARS_AVAILABLE = False

try:
    from numba import jit, prange
    NUMBA_AVAILABLE = True
except ImportError:
    NUMBA_AVAILABLE = False

try:
    import dask.dataframe as dd
    DASK_AVAILABLE = True
except ImportError:
    DASK_AVAILABLE = False
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="pykrx")

try:
    from pykrx import bond
    PYKRX_AVAILABLE = True
except ImportError:
    PYKRX_AVAILABLE = False
    print("Warning: pykrx not available. Using fallback risk-free rate.")

try:
    import plotly.graph_objects as go
    import plotly.express as px
    from plotly.subplots import make_subplots
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False
    print("Warning: plotly not available. Using matplotlib for visualization.")

# Korean font settings
import platform
if platform.system() == 'Darwin':  # macOS
    plt.rcParams['font.family'] = 'AppleGothic'
elif platform.system() == 'Windows':  # Windows
    plt.rcParams['font.family'] = 'Malgun Gothic'
else:  # Linux
    plt.rcParams['font.family'] = 'DejaVu Sans'

plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore')


class DataHandler:
    """Data processing and master dataframe creation"""
    
    def __init__(self, config):
        self.config = config
        self.daily_price_df = None
        self.fs_df = None
        self.market_cap_df = None
        self.master_df = None
        
    def load_data(self):
        """Load and process all required data"""
        print("ğŸ“Š ë°ì´í„° ë¡œë”© ì‹œì‘...")
        
        # 1. Load daily price data
        self._load_daily_price_data()
        
        # 2. Load financial statement data
        self._load_financial_data()
        
        # 3. Load market cap data
        self._load_market_cap_data()
        
        # 4. Create master dataframe
        self._create_master_dataframe()
        
        print("âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ")
        
    def _load_daily_price_data(self):
        """Load daily price data from multiple CSV files"""
        print("  ğŸ“ˆ ì¼ê°„ ê°€ê²© ë°ì´í„° ë¡œë”©...")
        
        # Look for yearly price data files (2013.csv, 2014.csv, etc.)
        price_files = glob.glob(os.path.join(self.config['data_paths']['price_data_dir'], "[0-9][0-9][0-9][0-9].csv"))
        if not price_files:
            print("  âš ï¸ ê°€ê²© ë°ì´í„° íŒŒì¼ì´ ì—†ìŒ - ê¸°ë³¸ ê°€ê²© ì‚¬ìš©")
            self.daily_price_df = pd.DataFrame()
            return
            
        all_price_data = []
        
        for file in sorted(price_files):  # Process all yearly files
            try:
                print(f"    ğŸ“ {os.path.basename(file)} ë¡œë”© ì¤‘...")
                df = pd.read_csv(file, encoding='utf-8-sig')
                
                # Handle different date column names
                if 'ë§¤ë§¤ë…„ì›”ì¼' in df.columns:
                    df['date'] = pd.to_datetime(df['ë§¤ë§¤ë…„ì›”ì¼'])
                elif 'Date' in df.columns:
                    df['date'] = pd.to_datetime(df['Date'])
                elif 'date' in df.columns:
                    df['date'] = pd.to_datetime(df['date'])
                elif 'ë‚ ì§œ' in df.columns:
                    df['date'] = pd.to_datetime(df['ë‚ ì§œ'])
                else:
                    print(f"    âš ï¸ {file}: ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    continue
                
                # Check required columns exist
                if 'ê±°ë˜ì†Œì½”ë“œ' not in df.columns:
                    print(f"    âš ï¸ {file}: ê±°ë˜ì†Œì½”ë“œ ì»¬ëŸ¼ ì—†ìŒ")
                    continue
                    
                # Handle different price column names
                if 'ì¢…ê°€(ì›)' in df.columns:
                    df['ì¢…ê°€'] = df['ì¢…ê°€(ì›)']
                elif 'ì¢…ê°€' in df.columns:
                    pass  # Already has correct column
                elif 'Adj Close' in df.columns:
                    df['ì¢…ê°€'] = df['Adj Close']
                elif 'Close' in df.columns:
                    df['ì¢…ê°€'] = df['Close']
                else:
                    print(f"    âš ï¸ {file}: ì¢…ê°€ ì»¬ëŸ¼ ì—†ìŒ")
                    continue
                    
                # Select necessary columns
                df = df[['ê±°ë˜ì†Œì½”ë“œ', 'date', 'ì¢…ê°€']].copy()
                
                # Remove invalid data
                df = df.dropna(subset=['ê±°ë˜ì†Œì½”ë“œ', 'date', 'ì¢…ê°€'])
                df = df[df['ì¢…ê°€'] > 0]  # Remove zero or negative prices
                
                all_price_data.append(df)
                
            except Exception as e:
                print(f"    âš ï¸ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨ {file}: {e}")
                continue
        
        if all_price_data:
            self.daily_price_df = pd.concat(all_price_data, ignore_index=True)
            self.daily_price_df = self.daily_price_df.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'date'])
            print(f"    âœ… ê°€ê²© ë°ì´í„°: {len(self.daily_price_df):,}í–‰, {self.daily_price_df['ê±°ë˜ì†Œì½”ë“œ'].nunique()}ê°œ ì¢…ëª©")
        else:
            self.daily_price_df = pd.DataFrame()
            print("    âš ï¸ ìœ íš¨í•œ ê°€ê²© ë°ì´í„° ì—†ìŒ")
    
    def _load_financial_data(self):
        """Load financial statement data"""
        print("  ğŸ“‹ ì¬ë¬´ì œí‘œ ë°ì´í„° ë¡œë”©...")
        
        fs_path = self.config['data_paths']['fundamental']
        try:
            self.fs_df = pd.read_csv(fs_path, encoding='utf-8-sig')
            print(f"    âœ… ì¬ë¬´ ë°ì´í„°: {len(self.fs_df):,}í–‰, {self.fs_df['ê±°ë˜ì†Œì½”ë“œ'].nunique()}ê°œ ì¢…ëª©")
        except Exception as e:
            print(f"    âŒ ì¬ë¬´ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            self.fs_df = pd.DataFrame()
    
    def _load_market_cap_data(self):
        """Load market cap data"""
        print("  ğŸ’° ì‹œê°€ì´ì•¡ ë°ì´í„° ë¡œë”©...")
        
        cap_path = self.config['data_paths']['market_cap']
        try:
            self.market_cap_df = pd.read_csv(cap_path, encoding='utf-8-sig')
            
            # Convert date column
            if 'date' in self.market_cap_df.columns:
                self.market_cap_df['date'] = pd.to_datetime(self.market_cap_df['date'])
            elif 'ë‚ ì§œ' in self.market_cap_df.columns:
                self.market_cap_df['date'] = pd.to_datetime(self.market_cap_df['ë‚ ì§œ'])
                
            print(f"    âœ… ì‹œê°€ì´ì•¡ ë°ì´í„°: {len(self.market_cap_df):,}í–‰")
        except Exception as e:
            print(f"    âŒ ì‹œê°€ì´ì•¡ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            self.market_cap_df = pd.DataFrame()
    
    def _create_master_dataframe(self):
        """Create master dataframe with all data"""
        print("  ğŸ”— ë§ˆìŠ¤í„° ë°ì´í„°í”„ë ˆì„ ìƒì„±...")
        
        if self.fs_df.empty:
            print("    âŒ ì¬ë¬´ ë°ì´í„°ê°€ ì—†ì–´ ë§ˆìŠ¤í„° ë°ì´í„°í”„ë ˆì„ ìƒì„± ë¶ˆê°€")
            return
        
        # Start with financial data
        self.master_df = self.fs_df.copy()
        
        # Add date handling - convert year to date
        if 'ì—°ë„' in self.master_df.columns:
            self.master_df['date'] = pd.to_datetime(self.master_df['ì—°ë„'].astype(str) + '-12-31')
        elif 'íšŒê³„ë…„ë„' in self.master_df.columns:
            self.master_df['date'] = pd.to_datetime(self.master_df['íšŒê³„ë…„ë„'].astype(str) + '-12-31')
        else:
            print("    âš ï¸ ì—°ë„ ì»¬ëŸ¼ ì—†ìŒ - ê¸°ë³¸ ë‚ ì§œ ì‚¬ìš©")
            self.master_df['date'] = pd.to_datetime('2023-12-31')
        
        # Simplified master dataframe - avoid memory explosion
        # Just use annual data without daily expansion
        if not self.market_cap_df.empty and 'ê±°ë˜ì†Œì½”ë“œ' in self.market_cap_df.columns:
            print("    ğŸ“ˆ ì‹œê°€ì´ì•¡ ë°ì´í„° ë³‘í•©...")
            # Simple merge on stock code and year
            self.master_df = pd.merge(self.master_df, self.market_cap_df, 
                                    on=['ê±°ë˜ì†Œì½”ë“œ'], how='left', suffixes=('', '_mcap'))
        
        # Skip daily price expansion to avoid memory issues
        # Keep only annual financial data
        print("    ğŸ’° ê°€ê²© ë°ì´í„°ëŠ” ë°±í…ŒìŠ¤íŒ… ì‹œ ì§ì ‘ í™œìš©...")
            
        # Ensure date column is datetime
        self.master_df['date'] = pd.to_datetime(self.master_df['date'])
        
        # Sort by stock code and date
        self.master_df = self.master_df.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'date']).reset_index(drop=True)
        
        print(f"    âœ… ë§ˆìŠ¤í„° ë°ì´í„°: {len(self.master_df):,}í–‰, {self.master_df['ê±°ë˜ì†Œì½”ë“œ'].nunique()}ê°œ ì¢…ëª©")


class FactorEngine:
    """Factor calculation engine with optimizations"""
    
    def __init__(self, config):
        self.config = config
        self.ff3_factors = None
        
    def compute_factors(self, df):
        """Compute all factors for the given dataframe"""
        print("âš™ï¸ íŒ©í„° ê³„ì‚° ì‹œì‘...")
        
        # Check optimization availability
        self._check_optimizations()
        
        # Compute factors in order
        print("  ğŸª„ Magic Formula ê³„ì‚°...")
        df = self._compute_magic_formula(df)
        
        print("  ğŸ“Š F-Score ê³„ì‚°...")
        df = self._compute_fscore(df)
        
        print("  ğŸ“ˆ ëª¨ë©˜í…€ ê³„ì‚°...")
        df = self._compute_momentum(df)
        
        print("  ğŸ“Š FF3 íŒ©í„° êµ¬ì¶•...")
        df = self._build_ff3_factors(df)
        
        print("  ğŸ“Š FF3-Alpha ê³„ì‚°...")
        df = self._compute_ff3_alpha(df)
        
        print("âœ… íŒ©í„° ê³„ì‚° ì™„ë£Œ")
        return df
    
    def _check_optimizations(self):
        """Check which optimizations are available"""
        optimizations = []
        if POLARS_AVAILABLE:
            optimizations.append("Polars")
        if NUMBA_AVAILABLE:
            optimizations.append("Numba")
        if DASK_AVAILABLE:
            optimizations.append("Dask")
            
        if optimizations:
            print(f"    ğŸš€ ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì í™”: {', '.join(optimizations)}")
        else:
            print("    âš ï¸ ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ê¸°ë³¸ pandas ì‚¬ìš©")
    
    def _compute_magic_formula(self, df):
        """
        Compute Magic Formula factor
        
        ìˆ˜ì • ì‚¬í•­:
        1. Earnings Yield = EBIT/EV (ê¸°ì¡´: ì˜ì—…ì´ìµ/ì‹œê°€ì´ì•¡)
           - EV = Market Cap + Total Debt - Cashë¡œ ì •í™•í•œ ê¸°ì—…ê°€ì¹˜ ë°˜ì˜
        2. ROIC = EBIT / Invested Capital (ê¸°ì¡´: ì˜ì—…ì´ìµ / (ì´ìì‚°-ì´ë¶€ì±„-í˜„ê¸ˆ))
           - Invested Capital = Total Assets - Cashë¡œ ìˆ˜ì •í•˜ì—¬ ë” ì •í™•í•œ íˆ¬í•˜ìë³¸ ê³„ì‚°
        """
        
        # Use year column (handle both ì—°ë„ and íšŒê³„ë…„ë„)
        year_col = 'íšŒê³„ë…„ë„' if 'íšŒê³„ë…„ë„' in df.columns else 'ì—°ë„'
        
        # Calculate Earnings Yield (EBIT/EV) - corrected formula
        if 'ì˜ì—…ì´ìµ' in df.columns and 'ì‹œê°€ì´ì•¡' in df.columns:
            ebit = pd.to_numeric(df['ì˜ì—…ì´ìµ'], errors='coerce')
            market_cap = pd.to_numeric(df['ì‹œê°€ì´ì•¡'], errors='coerce')
            
            # Calculate Enterprise Value (EV) = Market Cap + Total Debt - Cash
            if 'ì´ë¶€ì±„' in df.columns and 'í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°' in df.columns:
                total_debt = pd.to_numeric(df['ì´ë¶€ì±„'], errors='coerce')
                cash = pd.to_numeric(df['í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°'], errors='coerce')
                enterprise_value = market_cap + total_debt - cash
            else:
                enterprise_value = market_cap  # Fallback to market cap if debt/cash not available
            
            df['earnings_yield'] = ebit / enterprise_value.replace(0, np.nan)
        else:
            df['earnings_yield'] = 0
        
        # Calculate ROIC (Return on Invested Capital) - corrected formula
        if 'íˆ¬í•˜ìë³¸ìˆ˜ìµë¥ (ROIC)' in df.columns:
            df['roic'] = pd.to_numeric(df['íˆ¬í•˜ìë³¸ìˆ˜ìµë¥ (ROIC)'], errors='coerce')
        elif 'ì˜ì—…ì´ìµ' in df.columns and 'ì´ìì‚°' in df.columns and 'ì´ë¶€ì±„' in df.columns and 'í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°' in df.columns:
            # Calculate ROIC = EBIT / Invested Capital
            ebit = pd.to_numeric(df['ì˜ì—…ì´ìµ'], errors='coerce')
            total_assets = pd.to_numeric(df['ì´ìì‚°'], errors='coerce')
            total_debt = pd.to_numeric(df['ì´ë¶€ì±„'], errors='coerce')
            cash = pd.to_numeric(df['í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°'], errors='coerce')
            
            # Invested Capital = Total Assets - Non-interest bearing liabilities
            # Approximation: Invested Capital = Total Assets - Cash - Non-interest bearing debt
            invested_capital = total_assets - cash
            invested_capital = invested_capital.replace(0, np.nan)  # Avoid division by zero
            
            df['roic'] = ebit / invested_capital
        else:
            df['roic'] = 0
        
        # Calculate ranks within each year (1 = best, higher number = worse)
        df['ey_rank'] = df.groupby(year_col)['earnings_yield'].rank(ascending=False, method='average')
        df['roic_rank'] = df.groupby(year_col)['roic'].rank(ascending=False, method='average')
        
        # Combined Magic Formula rank (lower rank sum = better)
        df['magic_rank'] = df['ey_rank'] + df['roic_rank']
        
        # Magic Formula signal: lower rank sum = higher signal (ì§ì ‘ ì—­ìˆœ ë³€í™˜)
        df['magic_signal'] = df.groupby(year_col)['magic_rank'].transform(lambda x: x.max() - x + 1)
        
        return df
    
    def _compute_fscore(self, df):
        """
        Compute Piotroski F-Score
        
        ìˆ˜ì • ì‚¬í•­:
        1. f_shares (ì£¼ì‹ í¬ì„ ë°©ì§€): ë‚©ì…ìë³¸ê¸ˆ ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½ (ê¸°ì¡´: ë°œí–‰ì£¼ì‹ìˆ˜)
           - ë‚©ì…ìë³¸ê¸ˆì´ ì „ë…„ëŒ€ë¹„ ê°ì†Œí•˜ê±°ë‚˜ ë™ì¼í•˜ë©´ 1ì , ì¦ê°€í•˜ë©´ 0ì 
           - ì „ë…„ë„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ 1ì  ë¶€ì—¬ (ë³´ìˆ˜ì  ì ‘ê·¼)
        """
        
        # F-Score êµ¬ì„± ìš”ì†Œë“¤ì„ í•˜ë‚˜ì”© ê³„ì‚°
        fscore_components = []
        
        # 1. ROA > 0
        if 'ì´ìì‚°ìˆ˜ìµë¥ (ROA)' in df.columns:
            df['f_roa'] = (pd.to_numeric(df['ì´ìì‚°ìˆ˜ìµë¥ (ROA)'], errors='coerce') > 0).astype(int)
        else:
            df['f_roa'] = 0
        fscore_components.append('f_roa')
        
        # 2. Operating Cash Flow > 0  
        if 'ì˜ì—…í˜„ê¸ˆíë¦„' in df.columns:
            df['f_cfo'] = (pd.to_numeric(df['ì˜ì—…í˜„ê¸ˆíë¦„'], errors='coerce') > 0).astype(int)
        else:
            df['f_cfo'] = 0
        fscore_components.append('f_cfo')
        
        # 3. Change in ROA > 0 (compared to previous year)
        if 'ì´ìì‚°ìˆ˜ìµë¥ (ROA)' in df.columns:
            roa_values = pd.to_numeric(df['ì´ìì‚°ìˆ˜ìµë¥ (ROA)'], errors='coerce')
            prev_roa_values = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì´ìì‚°ìˆ˜ìµë¥ (ROA)'].shift(1)
            prev_roa_values = pd.to_numeric(prev_roa_values, errors='coerce')
            df['f_droa'] = (roa_values > prev_roa_values).astype(int)
        else:
            df['f_droa'] = 0
        fscore_components.append('f_droa')
        
        # 4. Operating Cash Flow > Net Income
        if 'ì˜ì—…í˜„ê¸ˆíë¦„' in df.columns and 'ë‹¹ê¸°ìˆœì´ìµ' in df.columns:
            df['f_accrual'] = (pd.to_numeric(df['ì˜ì—…í˜„ê¸ˆíë¦„'], errors='coerce') > pd.to_numeric(df['ë‹¹ê¸°ìˆœì´ìµ'], errors='coerce')).astype(int)
        else:
            df['f_accrual'] = 0
        fscore_components.append('f_accrual')
        
        # 5. Decrease in Long-term Debt ratio
        if 'ì´ë¶€ì±„' in df.columns and 'ì´ìì‚°' in df.columns:
            df['debt_ratio'] = pd.to_numeric(df['ì´ë¶€ì±„'], errors='coerce') / pd.to_numeric(df['ì´ìì‚°'], errors='coerce')
            df['prev_debt_ratio'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['debt_ratio'].shift(1)
            df['f_leverage'] = (df['debt_ratio'] < df['prev_debt_ratio']).astype(int)
        else:
            df['f_leverage'] = 0
        fscore_components.append('f_leverage')
        
        # 6. Increase in Current Ratio  
        if 'ìœ ë™ìì‚°' in df.columns and 'ìœ ë™ë¶€ì±„' in df.columns:
            df['current_ratio'] = pd.to_numeric(df['ìœ ë™ìì‚°'], errors='coerce') / pd.to_numeric(df['ìœ ë™ë¶€ì±„'], errors='coerce').replace(0, np.nan)
            df['prev_current_ratio'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['current_ratio'].shift(1)
            df['f_liquid'] = (df['current_ratio'] > df['prev_current_ratio']).astype(int)
        else:
            df['f_liquid'] = 0
        fscore_components.append('f_liquid')
        
        # 7. No new shares issued (check for decrease in paid-in capital)
        if 'ë‚©ì…ìë³¸ê¸ˆ' in df.columns:
            df['ë‚©ì…ìë³¸ê¸ˆ'] = pd.to_numeric(df['ë‚©ì…ìë³¸ê¸ˆ'], errors='coerce')
            df['prev_capital'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ë‚©ì…ìë³¸ê¸ˆ'].shift(1)
            # Score 1 if paid-in capital decreased or stayed same (no dilution), or if no previous year data
            df['f_shares'] = ((df['ë‚©ì…ìë³¸ê¸ˆ'] <= df['prev_capital']) | (df['prev_capital'].isna())).astype(int)
        else:
            df['f_shares'] = 1  # Default to 1 (no dilution) if no paid-in capital data
        fscore_components.append('f_shares')
        
        # 8. Increase in Gross Margin
        if 'ë§¤ì¶œì´ì´ìµ' in df.columns and 'ë§¤ì¶œì•¡' in df.columns:
            df['gross_margin'] = pd.to_numeric(df['ë§¤ì¶œì´ì´ìµ'], errors='coerce') / pd.to_numeric(df['ë§¤ì¶œì•¡'], errors='coerce').replace(0, np.nan)
            df['prev_gross_margin'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['gross_margin'].shift(1)
            df['f_margin'] = (df['gross_margin'] > df['prev_gross_margin']).astype(int)
        else:
            df['f_margin'] = 0
        fscore_components.append('f_margin')
        
        # 9. Increase in Asset Turnover
        if 'ì´ìì‚°íšŒì „ìœ¨' in df.columns:
            df['prev_turnover'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì´ìì‚°íšŒì „ìœ¨'].shift(1)
            df['f_turnover'] = (pd.to_numeric(df['ì´ìì‚°íšŒì „ìœ¨'], errors='coerce') > pd.to_numeric(df['prev_turnover'], errors='coerce')).astype(int)
        elif 'ë§¤ì¶œì•¡' in df.columns and 'ì´ìì‚°' in df.columns:
            # Calculate asset turnover manually
            df['asset_turnover'] = pd.to_numeric(df['ë§¤ì¶œì•¡'], errors='coerce') / pd.to_numeric(df['ì´ìì‚°'], errors='coerce').replace(0, np.nan)
            df['prev_asset_turnover'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['asset_turnover'].shift(1)
            df['f_turnover'] = (df['asset_turnover'] > df['prev_asset_turnover']).astype(int)
        else:
            df['f_turnover'] = 0
        fscore_components.append('f_turnover')
        
        # Calculate total F-Score
        df['fscore'] = df[fscore_components].sum(axis=1)
        
        return df
    
    @staticmethod
    def _process_momentum_chunk_optimized(chunk_data):
        """Optimized momentum calculation for pre-filtered chunk data"""
        chunk, chunk_df, lookback_months, skip_months, chunk_num, total_chunks = chunk_data
        
        # Remove print to reduce I/O overhead in worker processes
        
        chunk_results = []
        for code in chunk:
            stock_data = chunk_df[chunk_df['ê±°ë˜ì†Œì½”ë“œ'] == code].copy()
            stock_data = stock_data.sort_values('date')
            
            # Calculate momentum returns
            stock_data['momentum'] = np.nan
            
            for i in range(len(stock_data)):
                current_date = stock_data.iloc[i]['date']
                
                # Skip period
                lookback_date = current_date - relativedelta(months=lookback_months)
                
                # Find prices
                # Use best available price column
                if 'ì¢…ê°€' in stock_data.columns:
                    current_price = stock_data.iloc[i]['ì¢…ê°€']
                elif 'ì¼ê°„_ì‹œê°€ì´ì•¡' in stock_data.columns:
                    current_price = stock_data.iloc[i]['ì¼ê°„_ì‹œê°€ì´ì•¡']
                else:
                    current_price = stock_data.iloc[i]['ì‹œê°€ì´ì•¡']
                
                # Get price at lookback date
                past_data = stock_data[stock_data['date'] <= lookback_date]
                if len(past_data) > 0:
                    # Use best available price column for past price
                    if 'ì¢…ê°€' in past_data.columns:
                        past_price = past_data.iloc[-1]['ì¢…ê°€']
                    elif 'ì¼ê°„_ì‹œê°€ì´ì•¡' in past_data.columns:
                        past_price = past_data.iloc[-1]['ì¼ê°„_ì‹œê°€ì´ì•¡']
                    else:
                        past_price = past_data.iloc[-1]['ì‹œê°€ì´ì•¡']
                    
                    if past_price > 0:
                        momentum = (current_price / past_price) - 1
                        stock_data.iloc[i, stock_data.columns.get_loc('momentum')] = momentum
            
            chunk_results.append(stock_data)
        
        return chunk_results
    
    def _compute_momentum(self, df):
        """
        Compute momentum factor with vectorized calculation
        
        ìˆ˜ì • ì‚¬í•­:
        1. ë©€í‹°í”„ë¡œì„¸ì‹±ì—ì„œ ë²¡í„°í™” ê³„ì‚°ìœ¼ë¡œ ë³€ê²½
        2. ë…„ë„ë³„ ëª¨ë©˜í…€ ê³„ì‚°ìœ¼ë¡œ ë‹¨ìˆœí™”
        3. ê·¹ë‹¨ê°’ í•„í„°ë§ ì¶”ê°€ (Â±200% ì´ˆê³¼ ëª¨ë©˜í…€ ì œì™¸)
        4. ì—°ê°„ ë°ì´í„° íŠ¹ì„±ì— ë§ê²Œ ìµœì í™”
        """
        
        print("    ğŸ“Š ëª¨ë©˜í…€ ì„¤ì • í™•ì¸...")
        momentum_params = self.config.get('strategy_params', {}).get('momentum', {})
        lookback_months = momentum_params.get('lookback_months', 12)
        skip_months = momentum_params.get('skip_months', 1)
        
        # Vectorized momentum calculation
        df = df.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'date'])
        
        # Determine price column to use (ì‹œê°€ì´ì•¡ì€ ë¶€ì •í™•í•˜ë¯€ë¡œ í”¼í•¨)
        if 'ì¢…ê°€' in df.columns:
            price_col = 'ì¢…ê°€'
        elif 'ì¼ê°„_ì‹œê°€ì´ì•¡' in df.columns:
            price_col = 'ì¼ê°„_ì‹œê°€ì´ì•¡'
        else:
            # ì‹œê°€ì´ì•¡ì€ ë§ˆì§€ë§‰ ì„ íƒì§€ë¡œë§Œ ì‚¬ìš©
            price_col = 'ì‹œê°€ì´ì•¡'
            print("    âš ï¸ ì¢…ê°€ ë°ì´í„° ì—†ìŒ - ì‹œê°€ì´ì•¡ ì‚¬ìš© (ë¶€ì •í™•í•  ìˆ˜ ìˆìŒ)")
        
        # Convert price column to numeric
        df[price_col] = pd.to_numeric(df[price_col], errors='coerce')
        
        # Calculate momentum using vectorized operations
        df['momentum'] = np.nan
        
        # For annual data, calculate year-over-year momentum
        if 'ì—°ë„' in df.columns:
            year_col = 'ì—°ë„'
        elif 'íšŒê³„ë…„ë„' in df.columns:
            year_col = 'íšŒê³„ë…„ë„'
        else:
            # Extract year from date
            df['year'] = df['date'].dt.year
            year_col = 'year'
        
        # Calculate momentum as price change from previous year
        for code in df['ê±°ë˜ì†Œì½”ë“œ'].unique():
            stock_mask = df['ê±°ë˜ì†Œì½”ë“œ'] == code
            stock_data = df[stock_mask].copy()
            
            if len(stock_data) < 2:
                continue
                
            # Sort by year/date
            stock_data = stock_data.sort_values(year_col)
            
            # Calculate year-over-year momentum
            current_prices = stock_data[price_col].values
            lagged_prices = np.roll(current_prices, 1)  # 1-year lag
            
            # Calculate momentum returns, skip first observation (no lag available)
            momentum_values = np.where(
                (lagged_prices > 0) & (current_prices > 0) & (np.arange(len(current_prices)) > 0),
                (current_prices / lagged_prices) - 1,
                np.nan
            )
            
            # í•©ë¦¬ì  ëª¨ë©˜í…€ í•„í„°ë§: íˆ¬ì ê°€ëŠ¥í•œ ë²”ìœ„ë¡œ ì œí•œ
            momentum_values = np.where(
                (momentum_values > 0.8) | (momentum_values < -0.6),  # Â±80/60% ì´ˆê³¼ ì œê±°
                np.nan,
                momentum_values
            )
            
            # Update momentum values in original dataframe
            df.loc[stock_mask, 'momentum'] = momentum_values
        
        # Clean up momentum values
        df['momentum'] = df['momentum'].replace([np.inf, -np.inf], np.nan)
        
        # ì¶”ê°€ ê·¹ë‹¨ê°’ í•„í„°ë§
        valid_momentum = df['momentum'].notna()
        extreme_mask = (df['momentum'].abs() > 2.0) & valid_momentum
        df.loc[extreme_mask, 'momentum'] = np.nan
        
        df['mom'] = df['momentum'].fillna(0)
        
        # í†µê³„ ì¶œë ¥
        valid_count = df['momentum'].notna().sum()
        mean_momentum = df['momentum'].mean()
        print(f"    ğŸ“Š ìœ íš¨ ëª¨ë©˜í…€: {valid_count}ê°œ, í‰ê· : {mean_momentum:.2%}")
        
        print("    âœ… ë²¡í„°í™”ëœ ëª¨ë©˜í…€ ê³„ì‚° ì™„ë£Œ (ê·¹ë‹¨ê°’ í•„í„°ë§ ì ìš©)")
        return df
        
    def _build_ff3_factors(self, df):
        """
        Build Fama-French 3-factor model
        
        ìˆ˜ì • ì‚¬í•­:
        1. ì›”ë§ ê°€ê²©ì„ ì›”ê°„ ìˆ˜ìµë¥ (pct_change())ë¡œ ë³€í™˜ í›„ ì‚¬ìš©
        2. NYSE ë°©ì‹ 6-í¬íŠ¸í´ë¦¬ì˜¤(Size Ã— Value)ë¡œ SMB/HML ì‚°ì¶œ
        3. ê¸¸ì´ ë¶ˆì¼ì¹˜Â·shift() NaN ì˜¤ë¥˜ ì œê±°
        """
        print("    ğŸ“Š FF3 íŒ©í„° ë°ì´í„° ìƒì„±...")
        
        try:
            # Determine price column
            if 'ì¢…ê°€' in df.columns:
                price_col = 'ì¢…ê°€'
            elif 'ì¼ê°„_ì‹œê°€ì´ì•¡' in df.columns:
                price_col = 'ì¼ê°„_ì‹œê°€ì´ì•¡'
            else:
                price_col = 'ì‹œê°€ì´ì•¡'
            
            # Create monthly data with returns
            df['month_year'] = df['date'].dt.to_period('M')
            monthly_data = df.groupby(['ê±°ë˜ì†Œì½”ë“œ', 'month_year']).last().reset_index()
            monthly_data[price_col] = pd.to_numeric(monthly_data[price_col], errors='coerce')
            
            # Calculate monthly returns for each stock
            monthly_data = monthly_data.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'month_year'])
            monthly_data['monthly_return'] = monthly_data.groupby('ê±°ë˜ì†Œì½”ë“œ')[price_col].pct_change()
            
            # Remove first period (NaN returns) and invalid returns
            monthly_data = monthly_data.dropna(subset=['monthly_return'])
            monthly_data = monthly_data[monthly_data['monthly_return'].replace([np.inf, -np.inf], np.nan).notna()]
            
            if len(monthly_data) == 0:
                print("    âš ï¸ ìœ íš¨í•œ ì›”ê°„ ìˆ˜ìµë¥  ë°ì´í„° ì—†ìŒ")
                self.ff3_factors = pd.DataFrame()
                return df
            
            # Risk-free rate - ì—°ë„ë³„ ë¬´ìœ„í—˜ ìˆ˜ìµë¥  ë°ì´í„° í™œìš©
            annual_risk_free_rates = {
                2012: 3.42, 2013: 3.37, 2014: 3.05, 2015: 2.37, 2016: 1.73,
                2017: 2.32, 2018: 2.60, 2019: 1.74, 2020: 1.41, 2021: 2.08,
                2022: 3.37, 2023: 3.64
            }
            
            # ì›”ë³„ ë¬´ìœ„í—˜ ìˆ˜ìµë¥  ê³„ì‚° í•¨ìˆ˜
            def get_monthly_risk_free_rate(period):
                year = period.year
                if year in annual_risk_free_rates:
                    return annual_risk_free_rates[year] / 100 / 12  # ì—°ìœ¨ì„ ì›”ìœ¨ë¡œ ë³€í™˜
                else:
                    return 0.02 / 12  # ê¸°ë³¸ê°’: 2% ì—°ìœ¨
            
            # Calculate market return (value-weighted)
            monthly_data['market_cap'] = pd.to_numeric(monthly_data['ì‹œê°€ì´ì•¡'], errors='coerce')
            monthly_market = monthly_data.groupby('month_year').apply(
                lambda x: np.average(x['monthly_return'], weights=x['market_cap']) 
                if not x['market_cap'].isna().all() else x['monthly_return'].mean()
            )
            
            # NYSE-style 6-portfolio construction
            smb_returns = []
            hml_returns = []
            
            # Determine value measure
            if 'PBR' in monthly_data.columns:
                value_col = 'PBR'
                value_ascending = True  # Low PBR = High value
            elif 'ì£¼ë‹¹ìˆœìì‚°ê°€ì¹˜(BPS)' in monthly_data.columns and 'ì‹œê°€ì´ì•¡' in monthly_data.columns:
                monthly_data['pb_ratio'] = monthly_data['ì‹œê°€ì´ì•¡'] / monthly_data['ì£¼ë‹¹ìˆœìì‚°ê°€ì¹˜(BPS)']
                value_col = 'pb_ratio'
                value_ascending = True
            else:
                # Use book-to-market proxy
                if 'ì´ìì‚°' in monthly_data.columns:
                    monthly_data['bm_proxy'] = monthly_data['ì´ìì‚°'] / monthly_data['ì‹œê°€ì´ì•¡']
                    value_col = 'bm_proxy'
                    value_ascending = False  # High B/M = High value
                else:
                    value_col = None
            
            for period in monthly_market.index:
                period_data = monthly_data[monthly_data['month_year'] == period].copy()
                
                if len(period_data) < 6:  # Need minimum stocks for 6 portfolios
                    smb_returns.append(0)
                    hml_returns.append(0)
                    continue
                
                # Size breakpoint (median)
                size_median = period_data['market_cap'].median()
                period_data['size_group'] = np.where(period_data['market_cap'] <= size_median, 'Small', 'Big')
                
                # Value breakpoints (30th and 70th percentiles)
                if value_col and value_col in period_data.columns:
                    value_30 = period_data[value_col].quantile(0.3)
                    value_70 = period_data[value_col].quantile(0.7)
                    
                    if value_ascending:
                        period_data['value_group'] = pd.cut(period_data[value_col], 
                                                          bins=[-np.inf, value_30, value_70, np.inf],
                                                          labels=['High', 'Medium', 'Low'])
                    else:
                        period_data['value_group'] = pd.cut(period_data[value_col], 
                                                          bins=[-np.inf, value_30, value_70, np.inf],
                                                          labels=['Low', 'Medium', 'High'])
                else:
                    period_data['value_group'] = 'Medium'  # Neutral if no value measure
                
                # Create 6 portfolios
                portfolios = {}
                for size in ['Small', 'Big']:
                    for value in ['Low', 'Medium', 'High']:
                        portfolio_stocks = period_data[
                            (period_data['size_group'] == size) & 
                            (period_data['value_group'] == value)
                        ]
                        if len(portfolio_stocks) > 0:
                            # Value-weighted returns
                            portfolio_return = np.average(
                                portfolio_stocks['monthly_return'], 
                                weights=portfolio_stocks['market_cap']
                            )
                            portfolios[f'{size}_{value}'] = portfolio_return
                        else:
                            portfolios[f'{size}_{value}'] = 0
                
                # Calculate SMB (Small Minus Big)
                small_avg = (portfolios.get('Small_Low', 0) + 
                           portfolios.get('Small_Medium', 0) + 
                           portfolios.get('Small_High', 0)) / 3
                big_avg = (portfolios.get('Big_Low', 0) + 
                         portfolios.get('Big_Medium', 0) + 
                         portfolios.get('Big_High', 0)) / 3
                smb = small_avg - big_avg
                smb_returns.append(smb)
                
                # Calculate HML (High Minus Low)
                high_avg = (portfolios.get('Small_High', 0) + portfolios.get('Big_High', 0)) / 2
                low_avg = (portfolios.get('Small_Low', 0) + portfolios.get('Big_Low', 0)) / 2
                hml = high_avg - low_avg
                hml_returns.append(hml)
            
            # Create FF3 factors dataframe
            if len(monthly_market) > 0:
                # ê° ê¸°ê°„ë³„ ë¬´ìœ„í—˜ ìˆ˜ìµë¥  ê³„ì‚°
                period_risk_free_rates = [get_monthly_risk_free_rate(period) for period in monthly_market.index]
                
                ff3_data = {
                    'date': monthly_market.index,
                    'Mkt_RF': monthly_market - period_risk_free_rates,
                    'SMB': smb_returns[:len(monthly_market)],
                    'HML': hml_returns[:len(monthly_market)],
                    'RF': period_risk_free_rates
                }
                
                self.ff3_factors = pd.DataFrame(ff3_data)
                self.ff3_factors = self.ff3_factors.fillna(0)
                
                print(f"    âœ… FF3 íŒ©í„° ìƒì„± ì™„ë£Œ: {len(self.ff3_factors)}ê°œ ì›”")
            else:
                self.ff3_factors = pd.DataFrame()
                print("    âš ï¸ FF3 íŒ©í„° ìƒì„± ì‹¤íŒ¨: ì‹œì¥ ìˆ˜ìµë¥  ë°ì´í„° ì—†ìŒ")
            
        except Exception as e:
            print(f"    âš ï¸ FF3 íŒ©í„° ìƒì„± ì‹¤íŒ¨: {e}")
            self.ff3_factors = pd.DataFrame()
        
        return df
    
    def _compute_ff3_alpha(self, df):
        """
        Compute FF3-Alpha for each stock using Fama-French 3-factor model
        
        ìˆ˜ì • ì‚¬í•­:
        1. FF3 íŒ©í„°ì™€ ê°œë³„ ì¢…ëª© ìˆ˜ìµë¥ ì„ ì—°ê°„ ë°ì´í„°ë¡œ íšŒê·€ë¶„ì„
        2. Alpha = íšŒê·€ ì ˆí¸ (Intercept)
        3. P-valueë¡œ ìœ ì˜ì„± ê²€ì¦
        4. ì—°ê°„ ë°ì´í„° íŠ¹ì„±ì— ë§ê²Œ ìµœì í™”
        """
        
        # Initialize FF3-Alpha columns
        df['ff3_alpha'] = np.nan
        df['ff3_alpha_pvalue'] = np.nan
        df['ff3_r_squared'] = np.nan
        
        # Check if FF3 factors are available
        if self.ff3_factors is None or len(self.ff3_factors) == 0:
            print("    âš ï¸ FF3 íŒ©í„°ê°€ ì—†ì–´ FF3-Alpha ê³„ì‚° ë¶ˆê°€")
            return df
        
        print(f"    ğŸ“Š FF3 íŒ©í„° ë°ì´í„°: {len(self.ff3_factors)}ê°œ ê¸°ê°„")
        
        # Determine price column
        if 'ì¢…ê°€' in df.columns:
            price_col = 'ì¢…ê°€'
        elif 'ì¼ê°„_ì‹œê°€ì´ì•¡' in df.columns:
            price_col = 'ì¼ê°„_ì‹œê°€ì´ì•¡'
        else:
            price_col = 'ì‹œê°€ì´ì•¡'
        
        # Use annual data approach
        if 'ì—°ë„' in df.columns:
            year_col = 'ì—°ë„'
        elif 'íšŒê³„ë…„ë„' in df.columns:
            year_col = 'íšŒê³„ë…„ë„'
        else:
            df['year'] = df['date'].dt.year
            year_col = 'year'
        
        # Calculate annual returns for each stock
        df[price_col] = pd.to_numeric(df[price_col], errors='coerce')
        df = df.sort_values(['ê±°ë˜ì†Œì½”ë“œ', year_col])
        df['annual_return'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')[price_col].pct_change()
        
        # Convert FF3 factors to annual
        if not self.ff3_factors.empty:
            ff3_annual = self.ff3_factors.copy()
            ff3_annual['year'] = ff3_annual['date'].astype(str).str[:4].astype(int)
            
            # Aggregate monthly to annual (compound returns)
            ff3_annual_agg = ff3_annual.groupby('year').agg({
                'Mkt_RF': lambda x: (1 + x).prod() - 1,
                'SMB': lambda x: (1 + x).prod() - 1, 
                'HML': lambda x: (1 + x).prod() - 1,
                'RF': 'mean'
            }).reset_index()
            
            print(f"    ğŸ“Š ì—°ê°„ FF3 íŒ©í„°: {len(ff3_annual_agg)}ê°œ ë…„ë„")
            
            alpha_count = 0
            total_stocks = df['ê±°ë˜ì†Œì½”ë“œ'].nunique()
            
            # Calculate FF3-Alpha for each stock
            for code in df['ê±°ë˜ì†Œì½”ë“œ'].unique():
                try:
                    stock_data = df[df['ê±°ë˜ì†Œì½”ë“œ'] == code].copy()
                    stock_data = stock_data.dropna(subset=['annual_return'])
                    
                    if len(stock_data) < 3:  # Need minimum observations
                        continue
                    
                    # Merge with FF3 factors
                    merged_data = pd.merge(
                        stock_data[[year_col, 'annual_return']], 
                        ff3_annual_agg,
                        left_on=year_col, 
                        right_on='year',
                        how='inner'
                    )
                    
                    if len(merged_data) < 3:
                        continue
                    
                    # Calculate excess returns
                    merged_data['Stock_Excess'] = merged_data['annual_return'] - merged_data['RF']
                    
                    # Prepare regression variables
                    X = merged_data[['Mkt_RF', 'SMB', 'HML']].fillna(0)
                    y = merged_data['Stock_Excess'].fillna(0)
                    
                    # Remove infinite and NaN values
                    mask = np.isfinite(X).all(axis=1) & np.isfinite(y)
                    X = X[mask]
                    y = y[mask]
                    
                    if len(X) >= 3 and len(y) >= 3:
                        try:
                            # Use statsmodels for proper regression
                            import statsmodels.api as sm
                            X_with_const = sm.add_constant(X)
                            model = sm.OLS(y, X_with_const)
                            results = model.fit()
                            
                            alpha = results.params['const']
                            alpha_pvalue = results.pvalues['const']
                            r_squared = results.rsquared
                            
                        except ImportError:
                            # Fallback to simple linear regression
                            from sklearn.linear_model import LinearRegression
                            from scipy import stats
                            
                            reg = LinearRegression()
                            reg.fit(X, y)
                            alpha = reg.intercept_
                            
                            # Simple p-value approximation
                            y_pred = reg.predict(X)
                            mse = np.mean((y - y_pred) ** 2)
                            alpha_pvalue = 0.05 if abs(alpha) > np.sqrt(mse) else 0.5
                            r_squared = reg.score(X, y)
                        
                        # Update dataframe with FF3-Alpha values
                        mask = df['ê±°ë˜ì†Œì½”ë“œ'] == code
                        df.loc[mask, 'ff3_alpha'] = alpha
                        df.loc[mask, 'ff3_alpha_pvalue'] = alpha_pvalue
                        df.loc[mask, 'ff3_r_squared'] = r_squared
                        
                        alpha_count += 1
                        
                except Exception:
                    continue
            
            print(f"    âœ… FF3-Alpha ê³„ì‚° ì™„ë£Œ: {alpha_count}/{total_stocks}ê°œ ì¢…ëª©")
        
        return df


class StrategyBuilder:
    """Portfolio construction for different strategies"""
    
    def __init__(self, config):
        self.config = config
        self.portfolio_size = config['portfolio_params']['portfolio_size']
        self.weighting_scheme = config['portfolio_params']['weighting_scheme']
    
    @staticmethod  
    def _process_ff3_alpha_chunk_optimized(chunk_data):
        """
        Optimized FF3 Alpha calculation with statsmodels OLS
        
        ìˆ˜ì • ì‚¬í•­:
        - statsmodels.api.OLSë¡œ ë‹¤ì¤‘íšŒê·€ ìˆ˜í–‰
        - alpha = results.params['const'], p_value = results.pvalues['const'] ì €ì¥
        """
        chunk, chunk_df, ff3_factors, regression_window, alpha_threshold = chunk_data[:5]
        
        try:
            import statsmodels.api as sm
        except ImportError:
            print("    âš ï¸ statsmodels ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. scipyë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            sm = None
        
        chunk_alpha_results = []
        
        # Determine price column
        if 'ì¢…ê°€' in chunk_df.columns:
            price_col = 'ì¢…ê°€'
        elif 'ì¼ê°„_ì‹œê°€ì´ì•¡' in chunk_df.columns:
            price_col = 'ì¼ê°„_ì‹œê°€ì´ì•¡'
        else:
            price_col = 'ì‹œê°€ì´ì•¡'
        
        for code in chunk:
            try:
                # Get stock data for regression window
                stock_data = chunk_df[chunk_df['ê±°ë˜ì†Œì½”ë“œ'] == code].copy()
                stock_data = stock_data.sort_values('date')
                
                if len(stock_data) < 12:  # Minimum 12 observations
                    continue
                
                # Calculate monthly returns
                stock_data['month_year'] = stock_data['date'].dt.to_period('M')
                monthly_data = stock_data.groupby('month_year').last().reset_index()
                monthly_data[price_col] = pd.to_numeric(monthly_data[price_col], errors='coerce')
                monthly_data = monthly_data.sort_values('month_year')
                
                # Calculate monthly returns
                monthly_data['monthly_return'] = monthly_data[price_col].pct_change()
                monthly_data = monthly_data.dropna(subset=['monthly_return'])
                
                if len(monthly_data) < 12:
                    continue
                
                # Get last N months of data
                recent_data = monthly_data.tail(min(regression_window, len(monthly_data)))
                
                if len(recent_data) < 12:
                    continue
                
                # Merge with FF3 factors
                if ff3_factors is not None and len(ff3_factors) > 0:
                    factor_data = ff3_factors.copy()
                    factor_data['month_year'] = factor_data['date']
                    
                    # Merge on month_year
                    merged_data = pd.merge(recent_data[['month_year', 'monthly_return']], 
                                         factor_data[['month_year', 'Mkt_RF', 'SMB', 'HML', 'RF']], 
                                         on='month_year', 
                                         how='inner')
                    
                    if len(merged_data) < 12:
                        continue
                    
                    # Calculate excess returns
                    merged_data['Stock_Excess'] = merged_data['monthly_return'] - merged_data['RF']
                    
                    # Prepare regression variables
                    X = merged_data[['Mkt_RF', 'SMB', 'HML']].fillna(0)
                    y = merged_data['Stock_Excess'].fillna(0)
                    
                    # Remove infinite values
                    mask = np.isfinite(X).all(axis=1) & np.isfinite(y)
                    X = X[mask]
                    y = y[mask]
                    
                    if len(X) >= 12 and len(y) >= 12:
                        if sm is not None:
                            # Use statsmodels OLS for proper multi-factor regression
                            X_with_const = sm.add_constant(X)
                            model = sm.OLS(y, X_with_const)
                            results = model.fit()
                            
                            alpha = results.params['const']
                            p_value = results.pvalues['const']
                            r_squared = results.rsquared
                            
                        else:
                            # Fallback to scipy
                            from scipy.stats import linregress
                            # Simple approximation using market factor only
                            _, alpha, r_value, p_value, _ = linregress(X['Mkt_RF'], y)
                            r_squared = r_value**2
                        
                        if p_value < alpha_threshold:
                            chunk_alpha_results.append({
                                'code': code,
                                'alpha': alpha,
                                'p_value': p_value,
                                'r_squared': r_squared
                            })
                
            except Exception as e:
                # Skip problematic stocks
                continue
        
        return chunk_alpha_results
        
    def build_portfolios(self, df, factor_engine):
        """Build portfolios for all strategies"""
        print("ğŸ¯ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ì‹œì‘...")
        
        strategies = {
            'Magic_Formula': self._build_magic_formula_portfolio,
            'F_Score': self._build_fscore_portfolio,
            'Momentum': self._build_momentum_portfolio,
            'FF3_Alpha': self._build_ff3_alpha_portfolio
        }
        
        portfolio_results = {}
        
        for strategy_name, strategy_func in strategies.items():
            print(f"  ğŸ“Š {strategy_name} í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ì¤‘...")
            try:
                portfolio_results[strategy_name] = strategy_func(df, factor_engine)
                print(f"    âœ… {strategy_name} ì™„ë£Œ")
            except Exception as e:
                print(f"    âŒ {strategy_name} ì‹¤íŒ¨: {e}")
                portfolio_results[strategy_name] = {'All': [], 'Normal': []}
        
        return portfolio_results
    
    def _build_magic_formula_portfolio(self, df, factor_engine):
        """Build Magic Formula portfolio"""
        portfolios = {'All': [], 'Normal': []}
        
        # Get rebalancing dates - Magic Formula rebalances on April 1st each year
        start_date = pd.to_datetime(self.config['start_date'])
        end_date = pd.to_datetime(self.config['end_date'])
        
        # Generate April 1st dates
        start_year = start_date.year
        end_year = end_date.year
        rebalance_dates = [pd.Timestamp(f'{year}-04-01') for year in range(start_year, end_year + 1)]
        rebalance_dates = [date for date in rebalance_dates if start_date <= date <= end_date]
        
        for rebalance_date in rebalance_dates:
            print(f"    ğŸ”„ Magic Formula ë¦¬ë°¸ëŸ°ì‹±: {rebalance_date.strftime('%Y-%m-%d')}")
            
            # Get data for rebalancing date (use annual data)
            year = rebalance_date.year
            rebalance_data = df[
                (df['ì—°ë„'] == year) if 'ì—°ë„' in df.columns else 
                (df['íšŒê³„ë…„ë„'] == year) if 'íšŒê³„ë…„ë„' in df.columns else 
                (df['date'].dt.year == year)
            ]
            
            if len(rebalance_data) == 0:
                print(f"      âš ï¸ {year}ë…„ ë°ì´í„° ì—†ìŒ")
                continue
            
            print(f"      ğŸ” ë¶„ì„ ëŒ€ìƒ: {len(rebalance_data)}ê°œ ì¢…ëª©")
            
            # Filter stocks with valid magic signal
            valid_data = rebalance_data[rebalance_data['magic_signal'].notna()]
            print(f"      ğŸ” Magic ì‹œê·¸ë„ ìœ íš¨: {len(valid_data)}ê°œ ì¢…ëª©")
            
            if len(valid_data) >= self.portfolio_size:
                # Select top stocks by magic signal
                top_stocks = valid_data.nlargest(self.portfolio_size, 'magic_signal')
                print(f"      âœ… All í¬íŠ¸í´ë¦¬ì˜¤: {len(top_stocks)}ê°œ ì¢…ëª© ì„ íƒ")
                
                portfolios['All'].append({
                    'date': rebalance_date,
                    'stocks': top_stocks['ê±°ë˜ì†Œì½”ë“œ'].tolist(),
                    'signals': top_stocks['magic_signal'].tolist()
                })
            
            # Normal firms (non-default) portfolio
            normal_data = valid_data[valid_data.get('default', 0) == 0]
            if len(normal_data) >= self.portfolio_size:
                top_normal_stocks = normal_data.nlargest(self.portfolio_size, 'magic_signal')
                print(f"      âœ… Normal í¬íŠ¸í´ë¦¬ì˜¤: {len(top_normal_stocks)}ê°œ ì¢…ëª© ì„ íƒ")
                
                portfolios['Normal'].append({
                    'date': rebalance_date,
                    'stocks': top_normal_stocks['ê±°ë˜ì†Œì½”ë“œ'].tolist(),
                    'signals': top_normal_stocks['magic_signal'].tolist()
                })
        
        return portfolios
    
    def _build_fscore_portfolio(self, df, factor_engine):
        """Build F-Score portfolio"""
        portfolios = {'All': [], 'Normal': []}
        
        # Get rebalancing dates - F-Score rebalances on April 1st each year
        start_date = pd.to_datetime(self.config['start_date'])
        end_date = pd.to_datetime(self.config['end_date'])
        
        # Generate April 1st dates
        start_year = start_date.year
        end_year = end_date.year
        rebalance_dates = [pd.Timestamp(f'{year}-04-01') for year in range(start_year, end_year + 1)]
        rebalance_dates = [date for date in rebalance_dates if start_date <= date <= end_date]
        
        min_score = self.config['strategy_params']['f_score']['min_score']
        
        for rebalance_date in rebalance_dates:
            print(f"    ğŸ”„ F-Score ë¦¬ë°¸ëŸ°ì‹±: {rebalance_date.strftime('%Y-%m-%d')}")
            
            # Get data for rebalancing date (use annual data)
            year = rebalance_date.year
            rebalance_data = df[
                (df['ì—°ë„'] == year) if 'ì—°ë„' in df.columns else 
                (df['íšŒê³„ë…„ë„'] == year) if 'íšŒê³„ë…„ë„' in df.columns else 
                (df['date'].dt.year == year)
            ]
            
            if len(rebalance_data) == 0:
                print(f"      âš ï¸ {year}ë…„ ë°ì´í„° ì—†ìŒ")
                continue
                
            print(f"      ğŸ” ë¶„ì„ ëŒ€ìƒ: {len(rebalance_data)}ê°œ ì¢…ëª©")
            
            # Filter stocks with F-Score >= minimum threshold
            valid_data = rebalance_data[rebalance_data['fscore'] >= min_score]
            print(f"      ğŸ” F-Score >= {min_score}: {len(valid_data)}ê°œ í›„ë³´")
            
            if len(valid_data) >= self.portfolio_size:
                # Select top stocks by F-Score
                top_stocks = valid_data.nlargest(self.portfolio_size, 'fscore')
                print(f"      âœ… All í¬íŠ¸í´ë¦¬ì˜¤: {len(top_stocks)}ê°œ ì¢…ëª© ì„ íƒ")
                
                portfolios['All'].append({
                    'date': rebalance_date,
                    'stocks': top_stocks['ê±°ë˜ì†Œì½”ë“œ'].tolist(),
                    'signals': top_stocks['fscore'].tolist()
                })
            
            # Normal firms (non-default) portfolio
            normal_data = valid_data[valid_data.get('default', 0) == 0]
            if len(normal_data) >= self.portfolio_size:
                top_normal_stocks = normal_data.nlargest(self.portfolio_size, 'fscore')
                print(f"      âœ… Normal í¬íŠ¸í´ë¦¬ì˜¤: {len(top_normal_stocks)}ê°œ ì¢…ëª© ì„ íƒ")
                
                portfolios['Normal'].append({
                    'date': rebalance_date,
                    'stocks': top_normal_stocks['ê±°ë˜ì†Œì½”ë“œ'].tolist(),
                    'signals': top_normal_stocks['fscore'].tolist()
                })
        
        return portfolios
    
    def _build_momentum_portfolio(self, df, factor_engine):
        """Build Momentum portfolio"""
        portfolios = {'All': [], 'Normal': []}
        
        # Get rebalancing dates - Momentum rebalances on April 1st each year
        start_date = pd.to_datetime(self.config['start_date'])
        end_date = pd.to_datetime(self.config['end_date'])
        
        # Generate April 1st dates
        start_year = start_date.year
        end_year = end_date.year
        rebalance_dates = [pd.Timestamp(f'{year}-04-01') for year in range(start_year, end_year + 1)]
        rebalance_dates = [date for date in rebalance_dates if start_date <= date <= end_date]
        
        for rebalance_date in rebalance_dates:
            print(f"    ğŸ”„ ëª¨ë©˜í…€ ë¦¬ë°¸ëŸ°ì‹±: {rebalance_date.strftime('%Y-%m-%d')}")
            
            # Get data for rebalancing year (use annual data like other strategies)
            year = rebalance_date.year
            rebalance_data = df[
                (df['ì—°ë„'] == year) if 'ì—°ë„' in df.columns else 
                (df['íšŒê³„ë…„ë„'] == year) if 'íšŒê³„ë…„ë„' in df.columns else 
                (df['date'].dt.year == year)
            ]
            
            if len(rebalance_data) == 0:
                print(f"      âš ï¸ {year}ë…„ ë°ì´í„° ì—†ìŒ")
                continue
                
            print(f"      ğŸ” ë¶„ì„ ëŒ€ìƒ: {len(rebalance_data)}ê°œ ì¢…ëª©")
                
            # All firms portfolio
            valid_data = rebalance_data[rebalance_data['momentum'].notna() & (rebalance_data['momentum'] != 0)]
            print(f"      ğŸ” ìœ íš¨ ëª¨ë©˜í…€: {len(valid_data)}ê°œ ì¢…ëª©")
            
            if len(valid_data) >= self.portfolio_size:
                # ê· í˜•ì¡íŒ ëª¨ë©˜í…€ í¬íŠ¸í´ë¦¬ì˜¤ ì„ íƒ
                # ë„ˆë¬´ ê·¹ë‹¨ì ì¸ ëª¨ë©˜í…€ì€ ì œì™¸í•˜ê³  ì•ˆì •ì ì¸ ë²”ìœ„ì—ì„œ ì„ íƒ
                moderate_momentum = valid_data[
                    (valid_data['momentum'] > 0.1) & (valid_data['momentum'] <= 0.6)
                ]  # 10-60% ë²”ìœ„
                
                if len(moderate_momentum) >= self.portfolio_size:
                    # ì ë‹¹í•œ ëª¨ë©˜í…€ ë²”ìœ„ì—ì„œ ìƒìœ„ ì¢…ëª© ì„ íƒ
                    top_stocks = moderate_momentum.nlargest(self.portfolio_size, 'momentum')
                    print(f"      âœ… All í¬íŠ¸í´ë¦¬ì˜¤: {len(top_stocks)}ê°œ ì¢…ëª© ì„ íƒ (ì ë‹¹í•œ ëª¨ë©˜í…€)")
                else:
                    # ì ë‹¹í•œ ë²”ìœ„ì— ì¶©ë¶„í•œ ì¢…ëª©ì´ ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ ì„ íƒí•˜ë˜ ê·¹ë‹¨ê°’ ì œí•œ
                    valid_data_filtered = valid_data[valid_data['momentum'] <= 0.8]  # 80% ì´í•˜ë§Œ
                    if len(valid_data_filtered) >= self.portfolio_size:
                        top_stocks = valid_data_filtered.nlargest(self.portfolio_size, 'momentum')
                        print(f"      âœ… All í¬íŠ¸í´ë¦¬ì˜¤: {len(top_stocks)}ê°œ ì¢…ëª© ì„ íƒ (í•„í„°ë§ë¨)")
                    else:
                        top_stocks = valid_data.nlargest(self.portfolio_size, 'momentum')
                        print(f"      âœ… All í¬íŠ¸í´ë¦¬ì˜¤: {len(top_stocks)}ê°œ ì¢…ëª© ì„ íƒ (ì›ë³¸)")
                
                portfolios['All'].append({
                    'date': rebalance_date,
                    'stocks': top_stocks['ê±°ë˜ì†Œì½”ë“œ'].tolist(),
                    'signals': top_stocks['momentum'].tolist()
                })
            
            # Normal firms portfolio
            normal_data = valid_data[valid_data.get('default', 0) == 0]
            if len(normal_data) >= self.portfolio_size:
                top_normal_stocks = normal_data.nlargest(self.portfolio_size, 'momentum')
                print(f"      âœ… Normal í¬íŠ¸í´ë¦¬ì˜¤: {len(top_normal_stocks)}ê°œ ì¢…ëª© ì„ íƒ")
                
                portfolios['Normal'].append({
                    'date': rebalance_date,
                    'stocks': top_normal_stocks['ê±°ë˜ì†Œì½”ë“œ'].tolist(),
                    'signals': top_normal_stocks['momentum'].tolist()
                })
        
        return portfolios
        
    def _build_ff3_alpha_portfolio(self, df, factor_engine):
        """Build FF3-Alpha portfolio"""
        portfolios = {'All': [], 'Normal': []}
        
        # Check if FF3 factors are available
        if factor_engine.ff3_factors is None or factor_engine.ff3_factors.empty:
            print("    âš ï¸ FF3 íŒ©í„°ê°€ ì—†ì–´ FF3-Alpha í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„± ë¶ˆê°€")
            return portfolios
        
        # Get FF3 parameters
        ff3_params = self.config['strategy_params'].get('ff3_alpha', {})
        regression_window = ff3_params.get('regression_window', 5)  # Use 5 years for annual data
        alpha_threshold = ff3_params.get('alpha_pvalue_threshold', 0.1)
        
        # Get rebalancing dates - FF3-Alpha rebalances on July 1st each year
        start_date = pd.to_datetime(self.config['start_date'])
        end_date = pd.to_datetime(self.config['end_date'])
        
        # Generate July 1st dates
        start_year = start_date.year + regression_window  # Start after regression window
        end_year = end_date.year
        rebalance_dates = [pd.Timestamp(f'{year}-07-01') for year in range(start_year, end_year + 1)]
        rebalance_dates = [date for date in rebalance_dates if start_date <= date <= end_date]
        
        for rebalance_date in rebalance_dates:
            print(f"    ğŸ”„ FF3-Alpha ë¦¬ë°¸ëŸ°ì‹±: {rebalance_date.strftime('%Y-%m-%d')}")
            
            # Get data for regression window (annual data)
            window_end_year = rebalance_date.year - 1  # Use previous year's data
            window_start_year = window_end_year - regression_window + 1
            
            year_col = 'íšŒê³„ë…„ë„' if 'íšŒê³„ë…„ë„' in df.columns else 'ì—°ë„'
            window_data = df[
                (df[year_col] >= window_start_year) & 
                (df[year_col] <= window_end_year)
            ]
            
            if len(window_data) == 0:
                print(f"      âš ï¸ {window_start_year}-{window_end_year}ë…„ ë°ì´í„° ì—†ìŒ")
                continue
            
            print(f"      ğŸ” íšŒê·€ ìœˆë„ìš°: {window_start_year}-{window_end_year}ë…„")
            
            unique_codes = window_data['ê±°ë˜ì†Œì½”ë“œ'].unique()
            total_stocks = len(unique_codes)
            print(f"      ğŸ” ë¶„ì„ ëŒ€ìƒ: {total_stocks}ê°œ ì¢…ëª©")
            
            # Use rebalancing year data for portfolio selection
            rebalance_year = rebalance_date.year - 1  # Use previous year's calculated FF3-Alpha
            rebalance_data = df[df[year_col] == rebalance_year].copy()
            
            if len(rebalance_data) == 0:
                print(f"      âš ï¸ {rebalance_year}ë…„ ë°ì´í„° ì—†ìŒ")
                continue
            
            # Filter stocks with valid FF3-Alpha data
            valid_alpha_data = rebalance_data.dropna(subset=['ff3_alpha', 'ff3_alpha_pvalue'])
            print(f"      ğŸ” ìœ íš¨ FF3-Alpha: {len(valid_alpha_data)}ê°œ ì¢…ëª©")
            
            # Filter by p-value threshold for significant alphas
            significant_alpha_data = valid_alpha_data[valid_alpha_data['ff3_alpha_pvalue'] < alpha_threshold]
            print(f"      ğŸ” ìœ ì˜ë¯¸í•œ ì•ŒíŒŒ (p<{alpha_threshold}): {len(significant_alpha_data)}ê°œ ì¢…ëª©")
            
            # Build portfolio if we have enough significant stocks
            if len(significant_alpha_data) >= self.portfolio_size:
                # Select top alpha stocks (highest alpha values)
                top_alpha = significant_alpha_data.nlargest(self.portfolio_size, 'ff3_alpha')
                print(f"      âœ… All í¬íŠ¸í´ë¦¬ì˜¤: {len(top_alpha)}ê°œ ì¢…ëª© ì„ íƒ")
                
                portfolios['All'].append({
                    'date': rebalance_date,
                    'stocks': [{'code': code, 'alpha': alpha} for code, alpha in 
                             zip(top_alpha['ê±°ë˜ì†Œì½”ë“œ'], top_alpha['ff3_alpha'])]
                })
                
                # Normal firms (non-default) portfolio
                normal_alpha_data = significant_alpha_data[significant_alpha_data.get('default', 0) == 0]
                if len(normal_alpha_data) >= self.portfolio_size:
                    top_normal_alpha = normal_alpha_data.nlargest(self.portfolio_size, 'ff3_alpha')
                    print(f"      âœ… Normal í¬íŠ¸í´ë¦¬ì˜¤: {len(top_normal_alpha)}ê°œ ì¢…ëª© ì„ íƒ")
                    
                    portfolios['Normal'].append({
                        'date': rebalance_date,
                        'stocks': [{'code': code, 'alpha': alpha} for code, alpha in 
                                 zip(top_normal_alpha['ê±°ë˜ì†Œì½”ë“œ'], top_normal_alpha['ff3_alpha'])]
                    })
                else:
                    # Use same as All portfolio if not enough normal firms
                    print(f"      âœ… Normal í¬íŠ¸í´ë¦¬ì˜¤: {len(top_alpha)}ê°œ ì¢…ëª© ì„ íƒ (Allê³¼ ë™ì¼)")
                    portfolios['Normal'].append({
                        'date': rebalance_date,
                        'stocks': [{'code': code, 'alpha': alpha} for code, alpha in 
                                 zip(top_alpha['ê±°ë˜ì†Œì½”ë“œ'], top_alpha['ff3_alpha'])]
                    })
            else:
                print(f"      âš ï¸ ìœ ì˜ë¯¸í•œ ì•ŒíŒŒ ì¢…ëª© ë¶€ì¡±: {len(significant_alpha_data)}ê°œ < {self.portfolio_size}ê°œ")
        
        return portfolios


class BacktestEngine:
    """Backtesting engine with performance calculation"""
    
    def __init__(self, config):
        self.config = config
        self.start_date = pd.to_datetime(config['start_date'])
        self.end_date = pd.to_datetime(config['end_date'])
        self.initial_capital = config['portfolio_params'].get('initial_capital', 1000000)
        
    def run_backtest(self, portfolios, price_data):
        """Run backtest for all strategies and universes"""
        print("ğŸš€ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œì‘...")
        
        # Determine strategy processing method
        universes_to_process = ['All', 'Normal']
        total_combinations = sum(len(strategy_portfolios.get(universe, [])) 
                               for strategy_portfolios in portfolios.values() 
                               for universe in universes_to_process)
        
        print(f"    ğŸ“Š ì´ {total_combinations}ê°œ ì „ëµ-ìœ ë‹ˆë²„ìŠ¤ ì¡°í•© ì²˜ë¦¬")
        
        if total_combinations > 20:
            print("    âš¡ ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ - ë©€í‹°í”„ë¡œì„¸ì‹± ì‚¬ìš©")
            return self._backtest_with_multiprocessing(portfolios, price_data, universes_to_process)
        else:
            print("    ğŸ”„ ì†Œê·œëª¨ ì²˜ë¦¬ - ìˆœì°¨ ì²˜ë¦¬ ì‚¬ìš©")
            return self._backtest_sequential(portfolios, price_data, universes_to_process)
    
    def _backtest_sequential(self, portfolios, price_data, universes_to_process):
        """Sequential backtesting for small datasets"""
        results = {}
        
        for strategy_name, strategy_portfolios in portfolios.items():
            print(f"  ğŸ“ˆ {strategy_name} ë°±í…ŒìŠ¤íŠ¸...")
            results[strategy_name] = {}
            
            for universe in universes_to_process:
                if universe not in strategy_portfolios:
                    continue
                    
                print(f"    ğŸŒ {universe} ìœ ë‹ˆë²„ìŠ¤...")
                portfolio_list = strategy_portfolios[universe]
                
                if not portfolio_list:
                    print(f"      âš ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ì—†ìŒ")
                    results[strategy_name][universe] = self._create_empty_results()
                    continue
                
                # Calculate portfolio performance
                performance = self._calculate_portfolio_performance(
                    portfolio_list, price_data, strategy_name, universe
                )
                results[strategy_name][universe] = performance
        
        return results
    
    def _backtest_with_multiprocessing(self, portfolios, price_data, universes_to_process):
        """Multiprocessing backtesting for large datasets"""
        
        # Prepare tasks for multiprocessing
        tasks = []
        for strategy_name, strategy_portfolios in portfolios.items():
            for universe in universes_to_process:
                if universe in strategy_portfolios and strategy_portfolios[universe]:
                    tasks.append((strategy_name, universe, strategy_portfolios[universe], price_data))
        
        if not tasks:
            print("    âš ï¸ ë°±í…ŒìŠ¤íŠ¸í•  ì‘ì—… ì—†ìŒ")
            return {}
        
        # Use multiprocessing for parallel execution
        num_processes = min(len(universes_to_process), 2)
        print(f"    ğŸ”„ {num_processes}ê°œ í”„ë¡œì„¸ìŠ¤ë¡œ ë³‘ë ¬ ì²˜ë¦¬...")
        
        with Pool(processes=min(len(universes_to_process), 2)) as pool:
            results_list = pool.map(self._backtest_universe, tasks)
        
        # Reorganize results
        results = {}
        for (strategy_name, universe), performance in results_list:
            if strategy_name not in results:
                results[strategy_name] = {}
            results[strategy_name][universe] = performance
        
        return results
    
    def _backtest_universe(self, task_data):
        """Backtest a single strategy-universe combination"""
        strategy_name, universe, portfolio_list, price_data = task_data
        
        print(f"    ğŸ”„ {strategy_name}-{universe} ë°±í…ŒìŠ¤íŠ¸ ì²˜ë¦¬ ì¤‘...")
        
        try:
            performance = self._calculate_portfolio_performance(
                portfolio_list, price_data, strategy_name, universe
            )
            return (strategy_name, universe), performance
            
        except Exception as e:
            print(f"    âŒ {strategy_name}-{universe} ë°±í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return (strategy_name, universe), self._create_empty_results()
    
    def _create_price_lookup(self, price_data):
        """Create optimized price lookup structure with forward fill"""
        print("    ğŸ“Š ê°€ê²© ì¡°íšŒ êµ¬ì¡° ìƒì„± ì¤‘...")
        
        if price_data.empty:
            print("      âš ï¸ ê°€ê²© ë°ì´í„° ì—†ìŒ")
            return {}
        
        # Determine price column
        if 'ì¢…ê°€' in price_data.columns:
            price_col = 'ì¢…ê°€'
        elif 'ì¼ê°„_ì‹œê°€ì´ì•¡' in price_data.columns:
            # Check if we have share count data to calculate per-share price
            if 'ë°œí–‰ì£¼ì‹ìˆ˜' in price_data.columns or 'ìƒì¥ì£¼ì‹ìˆ˜' in price_data.columns:
                share_count_col = 'ë°œí–‰ì£¼ì‹ìˆ˜' if 'ë°œí–‰ì£¼ì‹ìˆ˜' in price_data.columns else 'ìƒì¥ì£¼ì‹ìˆ˜'
                # Calculate Adjusted Close price
                price_data['Adj_Close'] = pd.to_numeric(price_data['ì¼ê°„_ì‹œê°€ì´ì•¡'], errors='coerce') / pd.to_numeric(price_data[share_count_col], errors='coerce').replace(0, np.nan)
                price_col = 'Adj_Close'
                print(f"      ğŸ“Š ì£¼ë‹¹ ê°€ê²© ê³„ì‚°: ì‹œê°€ì´ì•¡ / {share_count_col}")
            else:
                print("      âš ï¸ ì£¼ì‹ìˆ˜ ì •ë³´ ì—†ìŒ - ì‹œê°€ì´ì•¡ ì§ì ‘ ì‚¬ìš©")
                price_col = 'ì¼ê°„_ì‹œê°€ì´ì•¡'
        else:
            print("      âŒ ê°€ê²© ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return {}
        
        # Clean price data
        price_data[price_col] = pd.to_numeric(price_data[price_col], errors='coerce')
        price_data = price_data.replace([np.inf, -np.inf], np.nan)
        
        # Remove stocks with no valid price data
        valid_stocks = price_data.groupby('ê±°ë˜ì†Œì½”ë“œ')[price_col].count()
        valid_stock_codes = valid_stocks[valid_stocks > 0].index
        price_data = price_data[price_data['ê±°ë˜ì†Œì½”ë“œ'].isin(valid_stock_codes)]
        
        if price_data.empty:
            print("      âš ï¸ ìœ íš¨í•œ ê°€ê²© ë°ì´í„° ì—†ìŒ")
            return {}
        
        # Create pivot table and forward fill
        print(f"      ğŸ“Š {price_col} ì»¬ëŸ¼ ì‚¬ìš©í•˜ì—¬ í”¼ë²— í…Œì´ë¸” ìƒì„±...")
        price_pivot = price_data.pivot_table(
            index='date', 
            columns='ê±°ë˜ì†Œì½”ë“œ', 
            values=price_col, 
            aggfunc='last'
        ).sort_index().ffill()  # Forward fill missing values
        
        # Create O(1) lookup dictionary
        price_lookup = price_pivot.stack().to_dict()
        
        print(f"      âœ… ê°€ê²© ì¡°íšŒ êµ¬ì¡° ì™„ì„±: {len(price_lookup):,}ê°œ ê°€ê²© í¬ì¸íŠ¸")
        return price_lookup
    
    def _calculate_portfolio_performance(self, portfolio_list, price_data, strategy_name, universe):
        """
        Calculate performance for a single portfolio
        
        ìˆ˜ì • ì‚¬í•­:
        1. ë¦¬ë°¸ëŸ°ìŠ¤ ì‹œ ì¢…ëª©ë³„ shares = w * portfolio_value / entry_priceë¡œ ê³ ì •
        2. entry_price = ë¦¬ë°¸ëŸ°ìŠ¤ ë‚ ì§œ ì²« ê±°ë˜ì¼ ê°€ê²©
        3. ë³´ìœ ê¸°ê°„ ë™ì•ˆ shares ë¶ˆë³€, daily_value = Î£(shares_i Ã— price_i)ë¡œ ê³„ì‚°
        4. ê±°ë˜ë¹„ìš©: ë§¤ë„Â·ë§¤ìˆ˜ ì²´ê²° ê¸ˆì•¡ ê¸°ì¤€ìœ¼ë¡œ ì°¨ê°
        5. holding_dates = price pivot ì¸ë±ìŠ¤ë¡œ ëŒ€ì²´í•˜ì—¬ ì¤‘ë³µ í•„í„° ì œê±°
        """
        print(f"      ğŸ“Š {strategy_name}-{universe} ì„±ê³¼ ê³„ì‚° ì¤‘...")
        
        if not portfolio_list:
            print(f"        âš ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤íŠ¸ ë¹„ì–´ìˆìŒ")
            return self._create_empty_results()
        
        # Create price lookup structure and get available dates
        price_lookup = self._create_price_lookup(price_data)
        if not price_lookup:
            print(f"        âŒ ê°€ê²© ë°ì´í„° ì—†ìŒ")
            return self._create_empty_results()
        
        # Get available trading dates from price data
        available_dates = sorted(set(date for date, _ in price_lookup.keys()))
        
        # Get transaction costs
        transaction_costs = self.config['portfolio_params'].get('transaction_cost', 0.003)
        
        # Initialize portfolio tracking
        portfolio_values = []
        daily_returns = []
        portfolio_value = self.initial_capital
        current_shares = {}  # Track shares held for each stock
        
        print(f"        ğŸ“… ì¼ì¼ ì„±ê³¼ ê³„ì‚° ì‹œì‘...")
        
        for i, portfolio in enumerate(portfolio_list):
            rebalance_date = portfolio['date']
            stocks = portfolio['stocks']
            
            print(f"        ğŸ”„ ë¦¬ë°¸ëŸ°ì‹± {i+1}/{len(portfolio_list)}: {rebalance_date.strftime('%Y-%m-%d')} ({len(stocks)}ê°œ ì¢…ëª©)")
            
            # Determine holding period using available trading dates
            if i < len(portfolio_list) - 1:
                next_rebalance = portfolio_list[i + 1]['date']
                holding_dates = [d for d in available_dates if rebalance_date <= d < next_rebalance]
            else:
                # Last portfolio - hold for 1 year or until end date
                one_year_later = rebalance_date + pd.DateOffset(years=1)
                end_holding = min(one_year_later, self.end_date)
                holding_dates = [d for d in available_dates if rebalance_date <= d <= end_holding]
            
            if not holding_dates:
                print(f"          âš ï¸ ë³´ìœ  ê¸°ê°„ ì—†ìŒ")
                continue
            
            print(f"          ğŸ“… ë³´ìœ  ê¸°ê°„: {len(holding_dates)}ì¼")
            
            # Calculate entry prices and shares at rebalancing
            if stocks:
                # Equal weight allocation
                weight_per_stock = 1.0 / len(stocks)
                allocation_per_stock = portfolio_value * weight_per_stock
                
                # Calculate transaction costs for selling old positions
                if current_shares:
                    sell_value = 0
                    for old_stock, shares in current_shares.items():
                        # Get price for selling
                        price_key = (pd.Timestamp(rebalance_date), old_stock)
                        if price_key in price_lookup and shares > 0:
                            sell_price = price_lookup[price_key]
                            if pd.notna(sell_price) and sell_price > 0:
                                sell_value += shares * sell_price
                    
                    # Apply selling transaction costs
                    sell_cost = sell_value * transaction_costs
                    portfolio_value -= sell_cost
                    print(f"          ğŸ’¸ ë§¤ë„ ê±°ë˜ë¹„ìš©: {sell_cost:,.0f}ì›")
                
                # Buy new positions
                new_shares = {}
                buy_value = 0
                
                for stock in stocks:
                    # Get entry price (first available price on or after rebalance date)
                    entry_price = None
                    for date in holding_dates:
                        price_key = (pd.Timestamp(date), stock)
                        if price_key in price_lookup:
                            price = price_lookup[price_key]
                            if pd.notna(price) and price > 0:
                                entry_price = price
                                break
                    
                    if entry_price and entry_price > 0:
                        # Calculate shares to buy
                        shares = allocation_per_stock / entry_price
                        new_shares[stock] = shares
                        buy_value += allocation_per_stock
                        
                        # Check for negative or infinite shares
                        if shares <= 0 or not np.isfinite(shares):
                            print(f"          âš ï¸ {stock}: ë¹„ì •ìƒ ì£¼ì‹ìˆ˜ {shares}")
                            new_shares[stock] = 0
                    else:
                        print(f"          âš ï¸ {stock}: ì§„ì… ê°€ê²© ì—†ìŒ")
                        new_shares[stock] = 0
                
                # Apply buying transaction costs
                buy_cost = buy_value * transaction_costs
                portfolio_value -= buy_cost
                print(f"          ğŸ’¸ ë§¤ìˆ˜ ê±°ë˜ë¹„ìš©: {buy_cost:,.0f}ì›")
                
                current_shares = new_shares
            else:
                print(f"          âš ï¸ ì„ íƒëœ ì¢…ëª© ì—†ìŒ")
                current_shares = {}
                continue
            
            # Calculate daily portfolio values during holding period
            prev_value = portfolio_value
            
            for date in holding_dates:
                daily_value = 0
                valid_positions = 0
                
                # Calculate portfolio value as sum of position values
                for stock, shares in current_shares.items():
                    if shares > 0:
                        price_key = (pd.Timestamp(date), stock)
                        if price_key in price_lookup:
                            price = price_lookup[price_key]
                            if pd.notna(price) and price > 0:
                                position_value = shares * price
                                daily_value += position_value
                                valid_positions += 1
                
                if valid_positions > 0 and daily_value > 0:
                    # Calculate return
                    if prev_value > 0:
                        daily_return = daily_value / prev_value - 1
                        
                        # Check for abnormal returns
                        if np.isfinite(daily_return):
                            daily_returns.append(daily_return)
                        else:
                            daily_returns.append(0)  # Replace infinite returns with 0
                    else:
                        daily_returns.append(0)
                        
                    portfolio_values.append({
                        'date': date,
                        'value': daily_value,
                        'return': daily_returns[-1] if daily_returns else 0
                    })
                    prev_value = daily_value
                else:
                    print(f"          âš ï¸ {date.strftime('%Y-%m-%d')} - ìœ íš¨ í¬ì§€ì…˜ ì—†ìŒ")
                    daily_returns.append(0)  # Use 0 instead of NaN for missing data
            
            # Update portfolio value for next rebalancing
            if portfolio_values:
                portfolio_value = portfolio_values[-1]['value']
        
        # Clean returns - filter extreme values
        daily_returns = [r for r in daily_returns if np.isfinite(r) and abs(r) < 1.0]  # Remove >100% daily returns
        
        if not daily_returns:
            print(f"        âš ï¸ ìœ íš¨í•œ ìˆ˜ìµë¥  ì—†ìŒ")
            return self._create_empty_results()
        
        # Check for flat returns (all zeros)
        if all(r == 0 for r in daily_returns):
            print(f"        âš ï¸ ëª¨ë“  ìˆ˜ìµë¥ ì´ 0 - ê³„ì‚° ì˜¤ë¥˜ ì˜ì‹¬")
        
        print(f"        âœ… ì„±ê³¼ ê³„ì‚° ì™„ë£Œ: {len(daily_returns)}ì¼ ìˆ˜ìµë¥  ë°ì´í„°")
        
        # Calculate performance metrics with robust error handling
        returns_series = pd.Series(daily_returns)
        
        if len(returns_series) == 0:
            return self._create_empty_results()
        
        # Calculate total return with error handling
        try:
            total_return = (1 + returns_series).prod() - 1
            if not np.isfinite(total_return):
                total_return = 0
        except:
            total_return = 0
        
        # Annualized return
        try:
            if len(returns_series) > 0:
                annual_return = (1 + total_return) ** (252 / len(returns_series)) - 1
                if not np.isfinite(annual_return):
                    annual_return = 0
            else:
                annual_return = 0
        except:
            annual_return = 0
        
        # Volatility
        try:
            volatility = returns_series.std() * np.sqrt(252)
            if not np.isfinite(volatility):
                volatility = 0
        except:
            volatility = 0
        
        # Sharpe ratio
        sharpe = annual_return / volatility if volatility > 0 else 0
        if not np.isfinite(sharpe):
            sharpe = 0
        
        # Drawdown calculation with error handling
        try:
            cumulative_returns = (1 + returns_series).cumprod()
            if len(cumulative_returns) > 0:
                rolling_max = cumulative_returns.expanding().max()
                drawdowns = (cumulative_returns - rolling_max) / rolling_max.replace(0, np.nan)
                max_drawdown = drawdowns.min() if len(drawdowns) > 0 else 0
                if not np.isfinite(max_drawdown):
                    max_drawdown = 0
            else:
                max_drawdown = 0
        except:
            max_drawdown = 0
        
        return {
            'total_return': total_return,
            'annual_return': annual_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe,
            'max_drawdown': max_drawdown,
            'portfolio_values': portfolio_values,
            'daily_returns': returns_series.tolist()
        }
    
    def _create_empty_results(self):
        """Create empty results structure"""
        return {
            'total_return': 0,
            'annual_return': 0,
            'volatility': 0,
            'sharpe_ratio': 0,
            'max_drawdown': 0,
            'portfolio_values': [],
            'daily_returns': []
        }
    
    def _validate_backtest_results(self, results, portfolios, master_df):
        """
        ë°±í…ŒìŠ¤íŒ… ì˜¤ë¥˜Â·ì‹¤ìˆ˜ ê²€ì¶œ ê°€ì´ë“œ êµ¬í˜„
        
        ê²€ì¦ í•­ëª©:
        - ë£©ì–´í—¤ë“œ(ë¯¸ë˜ì •ë³´) ê²€ì¦
        - ë°ì´í„° ëˆ„ìˆ˜ ê²€ì‚¬
        - ë¡¤ë§ ìœˆë„ ê°±ì‹  í™•ì¸
        - ì¼ì¼ ìˆ˜ìµë¥  í‰íƒ„í™” ê²€ì‚¬
        - ê±°ë˜ì¼ ë¶ˆì¼ì¹˜ í™•ì¸
        - ê±°ë˜ë¹„ìš© ê²€ì¦
        - Shares ìŒìˆ˜/ë¬´í•œëŒ€ ê²€ì‚¬
        - ìµœëŒ€ ë‚™í­ ê³„ì‚° ê²€ì¦
        """
        print("  ğŸ” ë°±í…ŒìŠ¤íŒ… ê²€ì¦ ì‹œì‘...")
        
        validation_issues = []
        
        # 1. ë£©ì–´í—¤ë“œ ë°”ì´ì–´ìŠ¤ ê²€ì¦
        print("    ğŸ“… ë£©ì–´í—¤ë“œ ë°”ì´ì–´ìŠ¤ ê²€ì‚¬...")
        for strategy_name, strategy_portfolios in portfolios.items():
            for universe, portfolio_list in strategy_portfolios.items():
                for i, portfolio in enumerate(portfolio_list):
                    rebalance_date = portfolio['date']
                    
                    # ì¬ë¬´ì œí‘œ ë°ì´í„°ê°€ ë¦¬ë°¸ëŸ°ìŠ¤ ë‚ ì§œ ì´í›„ ê²ƒì„ ì‚¬ìš©í–ˆëŠ”ì§€ í™•ì¸
                    if 'ì—°ë„' in master_df.columns:
                        year_col = 'ì—°ë„'
                    elif 'íšŒê³„ë…„ë„' in master_df.columns:
                        year_col = 'íšŒê³„ë…„ë„'
                    else:
                        continue
                    
                    # ë¦¬ë°¸ëŸ°ìŠ¤ ì—°ë„ ì´í›„ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€ í™•ì¸
                    rebalance_year = rebalance_date.year
                    future_data = master_df[master_df[year_col] > rebalance_year]
                    if not future_data.empty:
                        validation_issues.append(f"âš ï¸ {strategy_name}-{universe}: {rebalance_date.strftime('%Y-%m-%d')} ë¦¬ë°¸ëŸ°ì‹±ì—ì„œ ë¯¸ë˜ ë°ì´í„° ì‚¬ìš© ì˜ì‹¬")
        
        # 2. ì¼ì¼ ìˆ˜ìµë¥  í‰íƒ„í™” ê²€ì‚¬
        print("    ğŸ“Š ìˆ˜ìµë¥  í‰íƒ„í™” ê²€ì‚¬...")
        for strategy_name, strategy_results in results.items():
            for universe, performance in strategy_results.items():
                daily_returns = performance.get('daily_returns', [])
                
                if len(daily_returns) > 10:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ê²€ì‚¬
                    # ëª¨ë“  ìˆ˜ìµë¥ ì´ 0ì¸ì§€ í™•ì¸
                    if all(r == 0 for r in daily_returns):
                        validation_issues.append(f"âš ï¸ {strategy_name}-{universe}: ëª¨ë“  ì¼ì¼ ìˆ˜ìµë¥ ì´ 0 - ê³„ì‚° ì˜¤ë¥˜ ì˜ì‹¬")
                    
                    # ë™ì¼í•œ ê°’ì´ 90% ì´ìƒ ë°˜ë³µë˜ëŠ”ì§€ í™•ì¸
                    from collections import Counter
                    value_counts = Counter(daily_returns)
                    max_count = max(value_counts.values()) if value_counts else 0
                    if max_count > len(daily_returns) * 0.9:
                        validation_issues.append(f"âš ï¸ {strategy_name}-{universe}: ìˆ˜ìµë¥ ì´ ê³¼ë„í•˜ê²Œ ë°˜ë³µë¨ - ê³„ì‚° ì˜¤ë¥˜ ì˜ì‹¬")
                    
                    # ê·¹ë‹¨ì  ìˆ˜ìµë¥  í™•ì¸ (ì¼ì¼ 100% ì´ìƒ)
                    extreme_returns = [r for r in daily_returns if abs(r) > 1.0]
                    if extreme_returns:
                        validation_issues.append(f"âš ï¸ {strategy_name}-{universe}: ê·¹ë‹¨ì  ì¼ì¼ ìˆ˜ìµë¥  {len(extreme_returns)}ê°œ ë°œê²¬")
        
        # 3. ì„±ê³¼ ì§€í‘œ ê²€ì¦
        print("    ğŸ“ˆ ì„±ê³¼ ì§€í‘œ ê²€ì¦...")
        for strategy_name, strategy_results in results.items():
            for universe, performance in strategy_results.items():
                # ë¬´í•œëŒ€ê°’ ë˜ëŠ” NaN í™•ì¸
                metrics = ['total_return', 'annual_return', 'volatility', 'sharpe_ratio', 'max_drawdown']
                for metric in metrics:
                    value = performance.get(metric, 0)
                    if not np.isfinite(value):
                        validation_issues.append(f"âš ï¸ {strategy_name}-{universe}: {metric}ì´ ë¹„ì •ìƒê°’ ({value})")
                
                # ìƒ¤í”„ ë¹„ìœ¨ ë²”ìœ„ í™•ì¸ (ì¼ë°˜ì ìœ¼ë¡œ -5 ~ 5 ë²”ìœ„)
                sharpe = performance.get('sharpe_ratio', 0)
                if abs(sharpe) > 10:
                    validation_issues.append(f"âš ï¸ {strategy_name}-{universe}: ìƒ¤í”„ ë¹„ìœ¨ì´ ë¹„í˜„ì‹¤ì  ({sharpe:.2f})")
                
                # ë³€ë™ì„± ê²€ì‚¬ (0% ~ 200% ë²”ìœ„)
                volatility = performance.get('volatility', 0)
                if volatility > 2.0 or volatility < 0:
                    validation_issues.append(f"âš ï¸ {strategy_name}-{universe}: ë³€ë™ì„±ì´ ë¹„í˜„ì‹¤ì  ({volatility:.2%})")
        
        # 4. í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ê²€ì¦
        print("    ğŸ¯ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ê²€ì¦...")
        for strategy_name, strategy_portfolios in portfolios.items():
            for universe, portfolio_list in strategy_portfolios.items():
                if not portfolio_list:
                    validation_issues.append(f"âš ï¸ {strategy_name}-{universe}: í¬íŠ¸í´ë¦¬ì˜¤ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                    continue
                
                # ê° í¬íŠ¸í´ë¦¬ì˜¤ì˜ ì¢…ëª© ìˆ˜ í™•ì¸
                for i, portfolio in enumerate(portfolio_list):
                    stocks = portfolio.get('stocks', [])
                    if len(stocks) == 0:
                        validation_issues.append(f"âš ï¸ {strategy_name}-{universe}: {portfolio['date'].strftime('%Y-%m-%d')} í¬íŠ¸í´ë¦¬ì˜¤ì— ì¢…ëª© ì—†ìŒ")
                    elif len(stocks) < 5:
                        validation_issues.append(f"âš ï¸ {strategy_name}-{universe}: {portfolio['date'].strftime('%Y-%m-%d')} í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª©ìˆ˜ ë¶€ì¡± ({len(stocks)}ê°œ)")
        
        # 5. ê²°ê³¼ ìš”ì•½
        if validation_issues:
            print("  âŒ ê²€ì¦ ì´ìŠˆ ë°œê²¬:")
            for issue in validation_issues[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                print(f"    {issue}")
            if len(validation_issues) > 10:
                print(f"    ... ì´ {len(validation_issues)}ê°œ ì´ìŠˆ ë°œê²¬")
        else:
            print("  âœ… ë°±í…ŒìŠ¤íŒ… ê²€ì¦ í†µê³¼ - ì£¼ìš” ì˜¤ë¥˜ ì—†ìŒ")
        
        print("  ğŸ” ë°±í…ŒìŠ¤íŒ… ê²€ì¦ ì™„ë£Œ")


class ResultsAnalyzer:
    """Analysis and visualization of backtest results"""
    
    def __init__(self, config):
        self.config = config
        
    def analyze_results(self, results):
        """Analyze and display backtest results"""
        print("ğŸ“Š ê²°ê³¼ ë¶„ì„ ì‹œì‘...")
        
        # Create performance summary
        summary_df = self._create_performance_summary(results)
        
        # Display results
        self._display_summary(summary_df)
        
        # Save results
        self._save_results(summary_df, results)
        
        return summary_df
    
    def _create_performance_summary(self, results):
        """Create performance summary dataframe"""
        summary_data = []
        
        for strategy, universes in results.items():
            for universe, performance in universes.items():
                summary_data.append({
                    'Strategy': strategy,
                    'Universe': universe,
                    'Total_Return': performance['total_return'],
                    'Annual_Return': performance['annual_return'],
                    'Volatility': performance['volatility'],
                    'Sharpe_Ratio': performance['sharpe_ratio'],
                    'Max_Drawdown': performance['max_drawdown']
                })
        
        summary_df = pd.DataFrame(summary_data)
        
        # Sort by Sharpe ratio
        summary_df = summary_df.sort_values('Sharpe_Ratio', ascending=False)
        
        return summary_df
    
    def _display_summary(self, summary_df):
        """Display performance summary"""
        print("\nğŸ“ˆ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
        print("=" * 80)
        
        for _, row in summary_df.iterrows():
            print(f"ğŸ¯ {row['Strategy']} ({row['Universe']}):")
            print(f"   ì´ ìˆ˜ìµë¥ : {row['Total_Return']:.2%}")
            print(f"   ì—°ê°„ ìˆ˜ìµë¥ : {row['Annual_Return']:.2%}")
            print(f"   ë³€ë™ì„±: {row['Volatility']:.2%}")
            print(f"   ìƒ¤í”„ ë¹„ìœ¨: {row['Sharpe_Ratio']:.3f}")
            print(f"   ìµœëŒ€ ë‚™í­: {row['Max_Drawdown']:.2%}")
            print("-" * 40)
    
    def _save_results(self, summary_df, detailed_results):
        """Save results to files"""
        output_dir = Path(self.config.get('output_dir', 'outputs/backtesting_v3'))
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Save summary
        summary_path = output_dir / 'performance_summary.csv'
        summary_df.to_csv(summary_path, index=False, encoding='utf-8-sig')
        print(f"ğŸ“„ ìš”ì•½ ê²°ê³¼ ì €ì¥: {summary_path}")
        
        # Save detailed results
        detailed_path = output_dir / 'detailed_results.yaml'
        with open(detailed_path, 'w', encoding='utf-8') as f:
            yaml.dump(detailed_results, f, default_flow_style=False, allow_unicode=True)
        print(f"ğŸ“„ ìƒì„¸ ê²°ê³¼ ì €ì¥: {detailed_path}")


def main():
    """Main execution function"""
    print("ğŸš€ Factor Backtesting Framework v3.0 ì‹œì‘")
    print("=" * 60)
    
    # Load configuration
    try:
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print("âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    try:
        # 1. Data Loading
        print("\n" + "="*60)
        data_handler = DataHandler(config)
        data_handler.load_data()
        
        if data_handler.master_df is None or data_handler.master_df.empty:
            print("âŒ ë§ˆìŠ¤í„° ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆìŒ - ì‹¤í–‰ ì¤‘ë‹¨")
            return
        
        # 2. Factor Calculation
        print("\n" + "="*60)
        factor_engine = FactorEngine(config)
        master_df = factor_engine.compute_factors(data_handler.master_df)
        
        # 3. Portfolio Construction
        print("\n" + "="*60)
        strategy_builder = StrategyBuilder(config)
        portfolios = strategy_builder.build_portfolios(master_df, factor_engine)
        
        # Check if any portfolios were created
        total_portfolios = sum(len(strategy_portfolios.get('All', [])) + len(strategy_portfolios.get('Normal', []))
                             for strategy_portfolios in portfolios.values())
        
        if total_portfolios == 0:
            print("âŒ ìƒì„±ëœ í¬íŠ¸í´ë¦¬ì˜¤ ì—†ìŒ - ë°±í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
            return
        
        print(f"âœ… ì´ {total_portfolios}ê°œ í¬íŠ¸í´ë¦¬ì˜¤ ìƒì„±ë¨")
        
        # 4. Backtesting
        print("\n" + "="*60)
        backtest_engine = BacktestEngine(config)
        
        # Use price data for backtesting
        if not data_handler.daily_price_df.empty:
            price_data = data_handler.daily_price_df
        else:
            # Fallback to master dataframe price data
            price_columns = ['ê±°ë˜ì†Œì½”ë“œ', 'date']
            if 'ì¢…ê°€' in master_df.columns:
                price_columns.append('ì¢…ê°€')
            elif 'ì¼ê°„_ì‹œê°€ì´ì•¡' in master_df.columns:
                price_columns.append('ì¼ê°„_ì‹œê°€ì´ì•¡')
            else:
                print("âŒ ê°€ê²© ë°ì´í„° ì—†ìŒ - ë°±í…ŒìŠ¤íŠ¸ ë¶ˆê°€")
                return
                
            price_data = master_df[price_columns].dropna()
        
        results = backtest_engine.run_backtest(portfolios, price_data)
        
        # 4.5. Backtesting Error Detection
        print("\n" + "="*50)
        print("ğŸ” ë°±í…ŒìŠ¤íŒ… ì˜¤ë¥˜ ê²€ì¶œ ìˆ˜í–‰...")
        backtest_engine._validate_backtest_results(results, portfolios, master_df)
        
        # 5. Results Analysis
        print("\n" + "="*60)
        analyzer = ResultsAnalyzer(config)
        analysis_summary = analyzer.analyze_results(results)
        
        print("\nğŸ‰ ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nğŸ’¥ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()