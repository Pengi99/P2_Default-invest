import streamlit as st
import pandas as pd
import json
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import os
from pathlib import Path

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë¶€ì‹¤ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ ì½”ë“œë¦¬ë·°",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì‚¬ì´ë“œë°” ë©”ë‰´
st.sidebar.title("ğŸ“Š Navigation")
menu = st.sidebar.selectbox(
    "ë©”ë‰´ ì„ íƒ",
    ["ğŸ  í”„ë¡œì íŠ¸ ê°œìš”", "ğŸ—ï¸ ì½”ë“œë² ì´ìŠ¤ êµ¬ì¡°", "ğŸ“ ë°ì´í„° íŒŒì´í”„ë¼ì¸", "ğŸ”§ í•µì‹¬ ê¸°ëŠ¥", "ğŸ“ˆ ë°ì´í„° í˜„í™©", "ğŸ¯ ëª¨ë¸ë§ ì¤€ë¹„"]
)

# ë©”ì¸ íƒ€ì´í‹€
st.title("ğŸ¢ í•œêµ­ ê¸°ì—… ë¶€ì‹¤ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸")
st.markdown("---")

if menu == "ğŸ  í”„ë¡œì íŠ¸ ê°œìš”":
    st.header("ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ")
        st.markdown("""
        **í•œêµ­ ê¸°ì—…ì˜ ì¬ë¬´ë°ì´í„°ì™€ ì£¼ê°€ë°ì´í„°ë¥¼ í™œìš©í•œ ë¶€ì‹¤ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ**
        
        - ğŸ“Š **ë°ì´í„° ê¸°ê°„**: 2012~2023ë…„ (12ë…„ê°„)
        - ğŸ¢ **ëŒ€ìƒ ê¸°ì—…**: í•œêµ­ ìƒì¥ê¸°ì—… ì•½ 2,630ê°œ
        - ğŸ¯ **ì˜ˆì¸¡ ëª©í‘œ**: ê¸°ì—… ë¶€ì‹¤ (ìƒì¥íì§€) 1ë…„ ì „ ì˜ˆì¸¡
        - ğŸ¤– **ëª¨ë¸ë§**: Machine Learning ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë¸
        """)
        
        st.subheader("ğŸ”„ í”„ë¡œì íŠ¸ ì›Œí¬í”Œë¡œìš°")
        st.markdown("""
        1. **ë°ì´í„° ìˆ˜ì§‘ ë° ì •ì œ** â†’ ì¬ë¬´ì œí‘œ + ì£¼ê°€ë°ì´í„°
        2. **ë°ì´í„° ë§¤ì¹­ ë° í†µí•©** â†’ ê±°ë˜ì†Œì½”ë“œ ì •ê·œí™”
        3. **ì¬ë¬´ë¹„ìœ¨ ê³„ì‚°** â†’ 17ê°œ í•µì‹¬ ì¬ë¬´ì§€í‘œ
        4. **ë¶€ì‹¤ ë¼ë²¨ë§** â†’ ìƒì¥íì§€ ì „ë…„ë„ = ë¶€ì‹¤
        5. **íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§** â†’ SMOTE + ìŠ¤ì¼€ì¼ë§
        6. **ëª¨ë¸ ê°œë°œ** â†’ ë‹¤ì¤‘ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ
        """)
    
    with col2:
        st.subheader("ğŸ“Š í”„ë¡œì íŠ¸ ì§€í‘œ")
        
        # ë©”íŠ¸ë¦­ ì¹´ë“œ
        st.metric("ì´ ë°ì´í„°", "22,780ê°œ", "ê¸°ì—…-ì—°ë„ ì¡°í•©")
        st.metric("ê³ ìœ  ê¸°ì—…", "2,630ê°œ", "12ë…„ê°„")
        st.metric("ì¬ë¬´ë¹„ìœ¨", "17ê°œ", "í•µì‹¬ ì§€í‘œ")
        st.metric("ë¶€ì‹¤ ê¸°ì—…", "132ê°œ", "0.58%")
        
        st.subheader("ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ")
        st.markdown("""
        - **ì–¸ì–´**: Python ğŸ
        - **ë°ì´í„°**: Pandas, NumPy
        - **ì‹œê°í™”**: Matplotlib, Seaborn, Plotly
        - **ML**: Scikit-learn, XGBoost, Imbalanced-learn
        - **ëŒ€ì‹œë³´ë“œ**: Streamlit
        """)

elif menu == "ğŸ—ï¸ ì½”ë“œë² ì´ìŠ¤ êµ¬ì¡°":
    st.header("ğŸ—ï¸ ì½”ë“œë² ì´ìŠ¤ êµ¬ì¡°")
    
    # í”„ë¡œì íŠ¸ êµ¬ì¡° ì‹œê°í™”
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°")
        st.code("""
P2_Default-invest/
â”œâ”€â”€ ğŸ“ data_new/
â”‚   â”œâ”€â”€ raw/           # ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ processed/     # ì „ì²˜ë¦¬ëœ ë°ì´í„°  
â”‚   â””â”€â”€ final/         # ìµœì¢… ëª¨ë¸ë§ ë°ì´í„°
â”œâ”€â”€ ğŸ“ src_new/
â”‚   â”œâ”€â”€ data_processing/    # ë°ì´í„° ì²˜ë¦¬
â”‚   â”œâ”€â”€ feature_engineering/ # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
â”‚   â”œâ”€â”€ analysis/          # ë°ì´í„° ë¶„ì„
â”‚   â”œâ”€â”€ modeling/          # ëª¨ë¸ë§
â”‚   â””â”€â”€ utils/             # ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ ğŸ“ outputs/
â”‚   â”œâ”€â”€ visualizations/    # ì‹œê°í™” ê²°ê³¼
â”‚   â”œâ”€â”€ reports/          # ë¶„ì„ ë³´ê³ ì„œ
â”‚   â””â”€â”€ models/           # í›ˆë ¨ëœ ëª¨ë¸
â”œâ”€â”€ ğŸ“ notebooks/         # Jupyter ë…¸íŠ¸ë¶
â””â”€â”€ ğŸ“ dashboard/         # ëŒ€ì‹œë³´ë“œ
        """, language="text")
    
    with col2:
        st.subheader("ğŸ”§ í•µì‹¬ ëª¨ë“ˆ")
        
        modules = {
            "data_processing": {
                "files": ["create_financial_ratios_master.py"],
                "description": "4ë‹¨ê³„ ì¬ë¬´ë¹„ìœ¨ ê³„ì‚° íŒŒì´í”„ë¼ì¸",
                "color": "#FF6B6B"
            },
            "feature_engineering": {
                "files": ["add_financial_variables.py", "create_final_modeling_dataset.py"],
                "description": "íŠ¹ì„± ìƒì„±, SMOTE, ìŠ¤ì¼€ì¼ë§",
                "color": "#4ECDC4"
            },
            "analysis": {
                "files": ["analyze_scaling_needs.py", "apply_default_labeling_and_scaling.py"],
                "description": "ë°ì´í„° ë¶„ì„ ë° ë¼ë²¨ë§",
                "color": "#45B7D1"
            },
            "modeling": {
                "files": ["logistic_regression.py", "RF.py", "xgboost.py"],
                "description": "ML ëª¨ë¸ êµ¬í˜„",
                "color": "#96CEB4"
            }
        }
        
        for module, info in modules.items():
            with st.expander(f"ğŸ“¦ {module}"):
                st.markdown(f"**ì„¤ëª…**: {info['description']}")
                st.markdown("**íŒŒì¼ë“¤**:")
                for file in info['files']:
                    st.markdown(f"- `{file}`")

    # ë°ì´í„° í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨
    st.subheader("ğŸ”„ ë°ì´í„° í”Œë¡œìš°")
    
    # Plotlyë¡œ í”Œë¡œìš°ì°¨íŠ¸ ìƒì„±
    fig = go.Figure()
    
    # ë…¸ë“œ ì •ì˜
    nodes = [
        {"name": "ì›ë³¸ ë°ì´í„°", "x": 0, "y": 4, "color": "#FF6B6B"},
        {"name": "ë°ì´í„° ì •ì œ", "x": 1, "y": 4, "color": "#FF6B6B"},
        {"name": "ì¬ë¬´ë¹„ìœ¨ ê³„ì‚°", "x": 2, "y": 4, "color": "#4ECDC4"},
        {"name": "ë¶€ì‹¤ ë¼ë²¨ë§", "x": 3, "y": 4, "color": "#45B7D1"},
        {"name": "SMOTE ì ìš©", "x": 4, "y": 5, "color": "#96CEB4"},
        {"name": "ìŠ¤ì¼€ì¼ë§", "x": 4, "y": 3, "color": "#96CEB4"},
        {"name": "ëª¨ë¸ í›ˆë ¨", "x": 5, "y": 4, "color": "#FFEAA7"}
    ]
    
    # ë…¸ë“œ ê·¸ë¦¬ê¸°
    for node in nodes:
        fig.add_trace(go.Scatter(
            x=[node["x"]], y=[node["y"]],
            mode='markers+text',
            marker=dict(size=60, color=node["color"]),
            text=node["name"],
            textposition="middle center",
            textfont=dict(size=10, color="white"),
            name=node["name"],
            showlegend=False
        ))
    
    # í™”ì‚´í‘œ ì—°ê²°
    arrows = [
        (0, 1), (1, 2), (2, 3), (3, 4), (3, 5), (4, 6), (5, 6)
    ]
    
    for start, end in arrows:
        fig.add_annotation(
            x=nodes[end]["x"], y=nodes[end]["y"],
            ax=nodes[start]["x"], ay=nodes[start]["y"],
            xref="x", yref="y",
            axref="x", ayref="y",
            arrowhead=2, arrowsize=1, arrowwidth=2,
            arrowcolor="gray"
        )
    
    fig.update_layout(
        title="ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸",
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        height=400,
        plot_bgcolor="white"
    )
    
    st.plotly_chart(fig, use_container_width=True)

elif menu == "ğŸ“ ë°ì´í„° íŒŒì´í”„ë¼ì¸":
    st.header("ğŸ“ ë°ì´í„° íŒŒì´í”„ë¼ì¸")
    
    # íƒ­ìœ¼ë¡œ êµ¬ë¶„
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ë°ì´í„° ìˆ˜ì§‘", "ğŸ”§ ì „ì²˜ë¦¬", "ğŸ“ˆ ì¬ë¬´ë¹„ìœ¨", "ğŸ¯ ìµœì¢… ì¤€ë¹„"])
    
    with tab1:
        st.subheader("ğŸ“Š ì›ë³¸ ë°ì´í„°")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ì¬ë¬´ì œí‘œ ë°ì´í„°**")
            st.code("""
# íŒŒì¼: FS.csv, cFS.csv
- ê¸°ê°„: 2012~2023ë…„
- ê¸°ì—…: 2,632ê°œ ê³ ìœ  ê¸°ì—…
- ë‚´ìš©: ëŒ€ì°¨ëŒ€ì¡°í‘œ, ì†ìµê³„ì‚°ì„œ, í˜„ê¸ˆíë¦„í‘œ
- í¬ê¸°: ì•½ 50MB
            """)
            
        with col2:
            st.markdown("**ì£¼ê°€ ë°ì´í„°**")
            st.code("""
# íŒŒì¼: 2012.csv ~ 2023.csv (ì—°ë„ë³„)
- ê¸°ê°„: 2012~2023ë…„  
- ê¸°ì—…: 1,997ê°œ ê³ ìœ  ê¸°ì—…
- ë‚´ìš©: ì¼ë³„ ì£¼ê°€, ê±°ë˜ëŸ‰, ì‹œê°€ì´ì•¡
- í¬ê¸°: ì•½ 200MB
            """)
        
        st.subheader("ğŸ” ì£¼ìš” ì´ìŠˆ ë° í•´ê²°")
        
        issues = [
            {
                "ë¬¸ì œ": "ê±°ë˜ì†Œì½”ë“œ í˜•ì‹ ë¶ˆì¼ì¹˜",
                "ì›ì¸": "FSë°ì´í„°: ì •ìˆ˜í˜•(5380), ì£¼ê°€ë°ì´í„°: ë¬¸ìì—´(005380)",
                "í•´ê²°": "ëª¨ë“  ê±°ë˜ì†Œì½”ë“œë¥¼ 6ìë¦¬ ë¬¸ìì—´ë¡œ ì •ê·œí™”",
                "ê²°ê³¼": "ë§¤ì¹­ë¥  67.2% â†’ 73.4% í–¥ìƒ"
            },
            {
                "ë¬¸ì œ": "íšŒì‚¬ëª… í‘œê¸° ì°¨ì´",
                "ì›ì¸": "FS: í˜„ëŒ€ìë™ì°¨(ì£¼), ì£¼ê°€: í˜„ëŒ€ìë™ì°¨ë³´í†µì£¼",
                "í•´ê²°": "ê±°ë˜ì†Œì½”ë“œ ê¸°ì¤€ ë§¤ì¹­ìœ¼ë¡œ ë³€ê²½",
                "ê²°ê³¼": "íšŒì‚¬ëª… ì˜ì¡´ì„± ì œê±°"
            }
        ]
        
        for i, issue in enumerate(issues):
            with st.expander(f"ì´ìŠˆ {i+1}: {issue['ë¬¸ì œ']}"):
                st.markdown(f"**ì›ì¸**: {issue['ì›ì¸']}")
                st.markdown(f"**í•´ê²°**: {issue['í•´ê²°']}")
                st.markdown(f"**ê²°ê³¼**: {issue['ê²°ê³¼']}")
    
    with tab2:
        st.subheader("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬")
        
        st.markdown("**í•µì‹¬ ì „ì²˜ë¦¬ ë‹¨ê³„**")
        
        preprocessing_steps = [
            {"step": "1. ê±°ë˜ì†Œì½”ë“œ ì •ê·œí™”", "code": "df['ê±°ë˜ì†Œì½”ë“œ'] = df['ê±°ë˜ì†Œì½”ë“œ'].astype(str).str.zfill(6)"},
            {"step": "2. ì¤‘ë³µ ë°ì´í„° ì œê±°", "code": "df = df.drop_duplicates(subset=['ê±°ë˜ì†Œì½”ë“œ', 'íšŒê³„ë…„ë„'])"},
            {"step": "3. ê²°ì¸¡ê°’ ì²˜ë¦¬", "code": "df[col] = df[col].fillna(df[col].median())"},
            {"step": "4. ë°ì´í„° íƒ€ì… í†µì¼", "code": "df = df.astype({'ê±°ë˜ì†Œì½”ë“œ': str, 'íšŒê³„ë…„ë„': str})"}
        ]
        
        for step in preprocessing_steps:
            st.markdown(f"**{step['step']}**")
            st.code(step['code'], language="python")
    
    with tab3:
        st.subheader("ğŸ“ˆ ì¬ë¬´ë¹„ìœ¨ ê³„ì‚°")
        
        st.markdown("**17ê°œ í•µì‹¬ ì¬ë¬´ë¹„ìœ¨**")
        
        ratios = {
            "ìˆ˜ìµì„± ì§€í‘œ": ["ROA", "RE_TA", "EBIT_TA", "CFO_TA"],
            "ì•ˆì •ì„± ì§€í‘œ": ["TLTA", "CR", "CLCA", "WC_TA"],
            "ì‹œì¥ ì§€í‘œ": ["MVE_TL", "TLMTA", "MB"],
            "í™œë™ì„± ì§€í‘œ": ["S_TA"],
            "ê¸°íƒ€ ì§€í‘œ": ["CFO_TD", "SIGMA", "RET_3M", "RET_9M", "OENEG"]
        }
        
        for category, ratio_list in ratios.items():
            with st.expander(f"ğŸ“Š {category} ({len(ratio_list)}ê°œ)"):
                cols = st.columns(2)
                for i, ratio in enumerate(ratio_list):
                    with cols[i % 2]:
                        st.markdown(f"- **{ratio}**")
        
        st.markdown("**ê³„ì‚° íŒŒì´í”„ë¼ì¸**")
        st.code("""
# 4ë‹¨ê³„ ê³„ì‚° í”„ë¡œì„¸ìŠ¤
def calculate_financial_ratios():
    # 1ë‹¨ê³„: ê¸°ë³¸ ì¬ë¬´ë¹„ìœ¨ (FS_flow í™œìš©)
    calculate_basic_ratios()
    
    # 2ë‹¨ê³„: ì‹œì¥ê¸°ë°˜ ë¹„ìœ¨ (ì£¼ê°€ë°ì´í„° í™œìš©)  
    calculate_market_ratios()
    
    # 3ë‹¨ê³„: ë³€ë™ì„±ê³¼ ìˆ˜ìµë¥ 
    calculate_volatility_returns()
    
    # 4ë‹¨ê³„: ìµœì¢… í†µí•© ë° ì €ì¥
    finalize_ratios()
        """, language="python")
    
    with tab4:
        st.subheader("ğŸ¯ ìµœì¢… ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ë¶€ì‹¤ ë¼ë²¨ë§**")
            st.code("""
# ìƒì¥íì§€ ì „ë…„ë„ = ë¶€ì‹¤(1)
for company in failed_companies:
    target_year = delisting_year - 1
    df.loc[condition, 'default'] = 1

# ê²°ê³¼: 132ê°œ ë¶€ì‹¤ ê¸°ì—… (0.58%)
            """, language="python")
        
        with col2:
            st.markdown("**SMOTE ì ìš©**")
            st.code("""
# BorderlineSMOTEë¡œ í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° (1:10 ë¹„ìœ¨)
smote = BorderlineSMOTE(
    sampling_strategy=0.1,  # ë¶€ì‹¤:ì •ìƒ = 1:10
    random_state=42
)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# ê²°ê³¼: ë¶€ì‹¤ ë¹„ìœ¨ 0.58% â†’ 10%
            """, language="python")

elif menu == "ğŸ”§ í•µì‹¬ ê¸°ëŠ¥":
    st.header("ğŸ”§ í•µì‹¬ ê¸°ëŠ¥ ì½”ë“œ ë¦¬ë·°")
    
    # í•µì‹¬ í•¨ìˆ˜ë“¤ ì†Œê°œ
    function_tabs = st.tabs(["ğŸ“Š ì¬ë¬´ë¹„ìœ¨ ê³„ì‚°", "ğŸ¯ SMOTE ì ìš©", "ğŸ“ˆ ìŠ¤ì¼€ì¼ë§", "ğŸ” ë°ì´í„° ê²€ì¦"])
    
    with function_tabs[0]:
        st.subheader("ğŸ“Š ì¬ë¬´ë¹„ìœ¨ ê³„ì‚° ë§ˆìŠ¤í„°")
        
        st.code("""
def calculate_financial_ratios_master():
    \"\"\"4ë‹¨ê³„ ì¬ë¬´ë¹„ìœ¨ ê³„ì‚° í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬ì\"\"\"
    
    steps = [
        ("step1_basic_financial_ratios.py", "ê¸°ë³¸ ì¬ë¬´ë¹„ìœ¨"),
        ("step2_market_based_ratios.py", "ì‹œì¥ê¸°ë°˜ ë¹„ìœ¨"),
        ("step3_volatility_returns.py", "ë³€ë™ì„±ê³¼ ìˆ˜ìµë¥ "),
        ("step4_finalize_ratios.py", "ìµœì¢… í†µí•©")
    ]
    
    for step_file, step_name in steps:
        success = run_step(step_file, step_name)
        if not success:
            break
    
    return success

def run_step(step_file, step_name):
    \"\"\"ë‹¨ê³„ë³„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§\"\"\"
    start_time = time.time()
    
    result = subprocess.run([sys.executable, f'archive_old_structure/src/{step_file}'])
    
    duration = time.time() - start_time
    print(f"âœ… {step_name} ì™„ë£Œ (ì†Œìš”ì‹œê°„: {duration:.1f}ì´ˆ)")
    
    return result.returncode == 0
        """, language="python")
        
        st.markdown("**íŠ¹ì§•:**")
        st.markdown("- ê° ë‹¨ê³„ë³„ ë…ë¦½ ì‹¤í–‰ ë° ì˜¤ë¥˜ ì²˜ë¦¬")
        st.markdown("- ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë° ì„±ê³µë¥  í†µê³„")
        st.markdown("- íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨ ì‹œ ìƒì„¸ ë””ë²„ê¹… ì •ë³´")
    
    with function_tabs[1]:
        st.subheader("ğŸ¯ SMOTE ì ìš©")
        
        st.code("""
def apply_borderline_smote(X_train, y_train):
    \"\"\"BorderlineSMOTEë¡œ í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° (1:10 ë¹„ìœ¨)\"\"\"
    
    # SMOTE ì„¤ì • (1:10 ë¹„ìœ¨)
    smote = BorderlineSMOTE(
        sampling_strategy=0.1,  # ë¶€ì‹¤:ì •ìƒ = 1:10 ë¹„ìœ¨
        random_state=42,
        k_neighbors=5,
        m_neighbors=10
    )
    
    print(f"SMOTE ì ìš© ì „: ë¶€ì‹¤ {(y_train==1).sum()}ê°œ, ì •ìƒ {(y_train==0).sum()}ê°œ")
    
    # SMOTE ì ìš© (í›ˆë ¨ ë°ì´í„°ì—ë§Œ!)
    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
    
    print(f"SMOTE ì ìš© í›„: ë¶€ì‹¤ {(y_train_smote==1).sum()}ê°œ, ì •ìƒ {(y_train_smote==0).sum()}ê°œ")
    print(f"ì´ ì¦ê°€: {len(X_train_smote) - len(X_train)}ê°œ ìƒ˜í”Œ")
    print(f"ìµœì¢… ë¹„ìœ¨: 1:{(y_train_smote==0).sum()/(y_train_smote==1).sum():.0f}")
    
    return X_train_smote, y_train_smote
        """, language="python")
        
        st.markdown("**í•µì‹¬ í¬ì¸íŠ¸:**")
        st.markdown("- í›ˆë ¨ ë°ì´í„°ì—ë§Œ ì ìš©í•˜ì—¬ ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€")
        st.markdown("- BorderlineSMOTEë¡œ ê²½ê³„ì„  ê·¼ì²˜ ìƒ˜í”Œ ìƒì„±")
        st.markdown("- ë¶€ì‹¤ ë¹„ìœ¨ 0.58% â†’ 10% (1:10 ë¹„ìœ¨)ë¡œ ì¡°ì •")
    
    with function_tabs[2]:
        st.subheader("ğŸ“ˆ ìŠ¤ì¼€ì¼ë§")
        
        st.code("""
def apply_scaling(X_train, X_valid, X_test):
    \"\"\"ì¬ë¬´ë¹„ìœ¨ íŠ¹ì„±ì— ë§ëŠ” ìŠ¤ì¼€ì¼ë§ ì ìš©\"\"\"
    
    # ìŠ¤ì¼€ì¼ë§ ë°©ë²•ë³„ ì»¬ëŸ¼ ë¶„ë¥˜ (ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
    robust_scaler_columns = [
        'ROA', 'CFO_TD', 'RE_TA', 'EBIT_TA', 'MVE_TL', 'S_TA', 
        'CLCA', 'OENEG', 'CR', 'CFO_TA', 'RET_3M', 'RET_9M', 'MB'
    ]
    
    standard_scaler_columns = ['TLTA', 'WC_TA', 'SIGMA', 'TLMTA']
    
    # RobustScaler: ì´ìƒì¹˜ê°€ ë§ì€ ì¬ë¬´ë¹„ìœ¨
    robust_scaler = RobustScaler()
    robust_scaler.fit(X_train[robust_scaler_columns])
    
    X_train_scaled[robust_scaler_columns] = robust_scaler.transform(X_train[robust_scaler_columns])
    X_valid_scaled[robust_scaler_columns] = robust_scaler.transform(X_valid[robust_scaler_columns])
    X_test_scaled[robust_scaler_columns] = robust_scaler.transform(X_test[robust_scaler_columns])
    
    # StandardScaler: ì •ê·œë¶„í¬ì— ê°€ê¹Œìš´ ì¬ë¬´ë¹„ìœ¨
    standard_scaler = StandardScaler()
    standard_scaler.fit(X_train[standard_scaler_columns])
    
    # ... ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì ìš©
    
    return X_train_scaled, X_valid_scaled, X_test_scaled
        """, language="python")
        
        st.markdown("**ìŠ¤ì¼€ì¼ë§ ì „ëµ:**")
        st.markdown("- **RobustScaler**: ì´ìƒì¹˜ ë§ì€ 13ê°œ ë¹„ìœ¨")
        st.markdown("- **StandardScaler**: ì •ê·œë¶„í¬ ê°€ê¹Œìš´ 4ê°œ ë¹„ìœ¨")
        st.markdown("- í›ˆë ¨ ë°ì´í„°ë¡œë§Œ fití•˜ì—¬ ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€")
    
    with function_tabs[3]:
        st.subheader("ğŸ” ë°ì´í„° ê²€ì¦")
        
        st.code("""
def validate_data_quality(df):
    \"\"\"ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ë¦¬í¬íŠ¸\"\"\"
    
    validation_results = {}
    
    # 1. ê²°ì¸¡ê°’ ê²€ì‚¬
    missing_info = []
    for col in df.columns:
        missing_count = df[col].isna().sum()
        missing_pct = missing_count / len(df) * 100
        if missing_count > 0:
            missing_info.append({
                'column': col,
                'missing_count': missing_count,
                'missing_pct': missing_pct
            })
    
    validation_results['missing_values'] = missing_info
    
    # 2. ì´ìƒì¹˜ ê²€ì‚¬
    outlier_info = []
    for col in numeric_columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        outliers = ((df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)).sum()
        outlier_info.append({
            'column': col,
            'outlier_count': outliers,
            'outlier_pct': outliers / len(df) * 100
        })
    
    validation_results['outliers'] = outlier_info
    
    # 3. ë°ì´í„° ë¶„í¬ ê²€ì‚¬
    distribution_info = []
    for col in numeric_columns:
        skewness = df[col].skew()
        kurtosis = df[col].kurtosis()
        distribution_info.append({
            'column': col,
            'skewness': skewness,
            'kurtosis': kurtosis
        })
    
    validation_results['distributions'] = distribution_info
    
    return validation_results
        """, language="python")

elif menu == "ğŸ“ˆ ë°ì´í„° í˜„í™©":
    st.header("ğŸ“ˆ ë°ì´í„° í˜„í™© ë¶„ì„")
    
    # ë°ì´í„° ì •ë³´ ë¡œë“œ ì‹œë„
    try:
        with open('data_new/final/dataset_info_final.json', 'r', encoding='utf-8') as f:
            dataset_info = json.load(f)
        
        # ë©”íŠ¸ë¦­ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ì´ ìƒ˜í”Œ", 
                f"{dataset_info['dataset_info']['original_samples']:,}ê°œ",
                "ê¸°ì—…-ì—°ë„ ì¡°í•©"
            )
        
        with col2:
            st.metric(
                "ì´ íŠ¹ì„±", 
                f"{dataset_info['dataset_info']['total_features']}ê°œ",
                "ì¬ë¬´ë¹„ìœ¨"
            )
        
        with col3:
            st.metric(
                "ë¶€ì‹¤ ë¹„ìœ¨", 
                f"{dataset_info['dataset_info']['original_default_rate']*100:.2f}%",
                "ì›ë³¸ ë°ì´í„°"
            )
        
        with col4:
            st.metric(
                "SMOTE í›„", 
                f"{dataset_info['smote_version']['train_default_rate']*100:.0f}%",
                "í›ˆë ¨ ë°ì´í„°"
            )
        
        # ë°ì´í„° ë¶„í•  í˜„í™©
        st.subheader("ğŸ“Š ë°ì´í„° ë¶„í•  í˜„í™©")
        
        # ë¶„í•  ë¹„ìœ¨ ì°¨íŠ¸
        split_data = {
            'Dataset': ['Train', 'Valid', 'Test'],
            'Normal': [
                dataset_info['normal_version']['train_samples'],
                dataset_info['normal_version']['valid_samples'],
                dataset_info['normal_version']['test_samples']
            ],
            'SMOTE': [
                dataset_info['smote_version']['train_samples'],
                dataset_info['smote_version']['valid_samples'],
                dataset_info['smote_version']['test_samples']
            ]
        }
        
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            name='Normal Version',
            x=split_data['Dataset'],
            y=split_data['Normal'],
            marker_color='lightblue'
        ))
        
        fig.add_trace(go.Bar(
            name='SMOTE Version',
            x=split_data['Dataset'],
            y=split_data['SMOTE'],
            marker_color='orange'
        ))
        
        fig.update_layout(
            title='ë°ì´í„°ì…‹ í¬ê¸° ë¹„êµ (Normal vs SMOTE)',
            xaxis_title='Dataset',
            yaxis_title='Sample Count',
            barmode='group'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # íŠ¹ì„± ì •ë³´
        st.subheader("ğŸ”§ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**RobustScaler ì ìš© (13ê°œ)**")
            for feature in dataset_info['feature_info']['robust_scaled']:
                st.markdown(f"- {feature}")
        
        with col2:
            st.markdown("**StandardScaler ì ìš© (4ê°œ)**")
            for feature in dataset_info['feature_info']['standard_scaled']:
                st.markdown(f"- {feature}")
        
    except FileNotFoundError:
        st.warning("ë°ì´í„°ì…‹ ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        # ì˜ˆì‹œ ë°ì´í„°ë¡œ ì‹œê°í™”
        st.subheader("ğŸ“Š ì˜ˆì‹œ ë°ì´í„° í˜„í™©")
        
        # ê°€ìƒì˜ ë°ì´í„° ë¶„í¬
        sample_data = pd.DataFrame({
            'ROA': pd.np.random.normal(0.05, 0.1, 1000),
            'TLTA': pd.np.random.normal(0.6, 0.2, 1000),
            'MVE_TL': pd.np.random.lognormal(0, 1, 1000)
        })
        
        fig = make_subplots(rows=1, cols=3, subplot_titles=['ROA', 'TLTA', 'MVE_TL'])
        
        for i, col in enumerate(sample_data.columns):
            fig.add_trace(
                go.Histogram(x=sample_data[col], name=col),
                row=1, col=i+1
            )
        
        fig.update_layout(title='ì¬ë¬´ë¹„ìœ¨ ë¶„í¬ ì˜ˆì‹œ', showlegend=False)
        st.plotly_chart(fig, use_container_width=True)

elif menu == "ğŸ¯ ëª¨ë¸ë§ ì¤€ë¹„":
    st.header("ğŸ¯ ëª¨ë¸ë§ ì¤€ë¹„")
    
    st.subheader("ğŸ¤– êµ¬í˜„ëœ ëª¨ë¸ë“¤")
    
    models = [
        {
            "name": "Logistic Regression",
            "description": "ì„ í˜• ë¶„ë¥˜ ëª¨ë¸, í•´ì„ ê°€ëŠ¥ì„± ìš°ìˆ˜",
            "pros": ["ë¹ ë¥¸ í›ˆë ¨", "ê³„ìˆ˜ í•´ì„", "í™•ë¥  ì¶œë ¥"],
            "cons": ["ì„ í˜• ê´€ê³„ ê°€ì •", "ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ ì œí•œ"],
            "use_case": "ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸, í•´ì„ì´ ì¤‘ìš”í•œ ê²½ìš°"
        },
        {
            "name": "Random Forest",
            "description": "ì•™ìƒë¸” ê¸°ë°˜ ê²°ì • íŠ¸ë¦¬ ëª¨ë¸",
            "pros": ["ë†’ì€ ì •í™•ë„", "íŠ¹ì„± ì¤‘ìš”ë„", "ì˜¤ë²„í”¼íŒ… ë°©ì§€"],
            "cons": ["í•´ì„ì„± ì œí•œ", "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ"],
            "use_case": "ì•ˆì •ì ì¸ ì„±ëŠ¥, íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„"
        },
        {
            "name": "XGBoost",
            "description": "ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ê¸°ë°˜ ê³ ì„±ëŠ¥ ëª¨ë¸",
            "pros": ["ìµœê³  ìˆ˜ì¤€ ì„±ëŠ¥", "ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬", "ë¹ ë¥¸ í›ˆë ¨"],
            "cons": ["í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë³µì¡"],
            "use_case": "ìµœê³  ì„±ëŠ¥ ì¶”êµ¬, ë¶ˆê· í˜• ë°ì´í„°"
        }
    ]
    
    for model in models:
        with st.expander(f"ğŸ”§ {model['name']}"):
            st.markdown(f"**ì„¤ëª…**: {model['description']}")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("**ì¥ì **")
                for pro in model['pros']:
                    st.markdown(f"âœ… {pro}")
            
            with col2:
                st.markdown("**ë‹¨ì **")
                for con in model['cons']:
                    st.markdown(f"âš ï¸ {con}")
            
            with col3:
                st.markdown("**ì‚¬ìš© ì‚¬ë¡€**")
                st.markdown(f"ğŸ’¡ {model['use_case']}")
    
    st.subheader("ğŸ“Š í‰ê°€ ì§€í‘œ")
    
    metrics_info = {
        "AUC-ROC": "ë¶ˆê· í˜• ë°ì´í„°ì˜ ì£¼ìš” í‰ê°€ ì§€í‘œ",
        "Precision": "ë¶€ì‹¤ ì˜ˆì¸¡ ì •í™•ë„ (False Positive ìµœì†Œí™”)",
        "Recall": "ë¶€ì‹¤ íƒì§€ìœ¨ (False Negative ìµœì†Œí™”)",
        "F1-Score": "Precisionê³¼ Recallì˜ ì¡°í™”í‰ê· "
    }
    
    for metric, description in metrics_info.items():
        st.markdown(f"**{metric}**: {description}")
    
    st.subheader("ğŸš€ ë‹¤ìŒ ë‹¨ê³„")
    
    next_steps = [
        "ì¼ë°˜ ë²„ì „ìœ¼ë¡œ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í›ˆë ¨",
        "SMOTE ë²„ì „ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ ëª¨ë¸ í›ˆë ¨",
        "ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ë° ë¶„ì„",
        "í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹",
        "ìµœì¢… ëª¨ë¸ ì„ íƒ ë° í•´ì„"
    ]
    
    for i, step in enumerate(next_steps, 1):
        st.markdown(f"{i}. {step}")

# í‘¸í„°
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>ğŸ¢ í•œêµ­ ê¸°ì—… ë¶€ì‹¤ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸ | ğŸ“Š Code Review Dashboard</p>
        <p>Made with â¤ï¸ using Streamlit</p>
    </div>
    """, 
    unsafe_allow_html=True
) 