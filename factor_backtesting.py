"""
Factor Investing Backtesting Framework
8ê°œ íŒ©í„° ì „ëµ ë°±í…ŒìŠ¤íŠ¸ ë° ì„±ê³¼ ë¶„ì„
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from sklearn.preprocessing import StandardScaler
from scipy import stats
import warnings
import glob
import os
from datetime import datetime
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì • (OSë³„ ìë™ ê°ì§€)
import platform

if platform.system() == 'Darwin':  # macOS
    plt.rcParams['font.family'] = 'AppleGothic'
elif platform.system() == 'Windows':  # Windows
    plt.rcParams['font.family'] = 'Malgun Gothic'
else:  # Linux and others
    plt.rcParams['font.family'] = 'DejaVu Sans'
    
plt.rcParams['axes.unicode_minus'] = False

plt.style.use('seaborn-v0_8')

class FactorBacktester:
    """íŒ©í„° íˆ¬ì ë°±í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, data_path=None):
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
        base_dir = os.path.dirname(os.path.abspath(__file__))
        
        # ë°ì´í„° ê²½ë¡œ ì„¤ì •
        if data_path is None:
            self.data_path = os.path.join(base_dir, 'data', 'raw')
        else:
            self.data_path = data_path
        
        # ì¬ë¬´ ë°ì´í„° ê²½ë¡œ ì„¤ì •
        self.fs_path = os.path.join(base_dir, 'data', 'processed', 'FS.csv')
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.output_dir = os.path.join(base_dir, 'outputs', 'backtesting')
        os.makedirs(self.output_dir, exist_ok=True)
        self.prices_df = None
        self.fs_df = None
        self.df = None
        self.predictions_df = None
        self.factor_returns = {}
        self.performance_stats = {}
        
    def load_data(self):
        """1ë‹¨ê³„: ë°ì´í„° ë¡œë”©"""
        print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ê°€ê²© ë°ì´í„° ë¡œë”© (2012~2023)
        price_files = sorted(glob.glob(os.path.join(self.data_path, '20*.csv')))
        price_dfs = []
        
        if not price_files:
            raise FileNotFoundError(f"No price files found in directory: {self.data_path}")
        
        for file in price_files:
            df_temp = pd.read_csv(file, encoding='utf-8')
            
            # ì»¬ëŸ¼ rename (ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ì¶° ìˆ˜ì •)
            df_temp = df_temp.rename(columns={
                'ë§¤ë§¤ë…„ì›”ì¼': 'date',
                'ì¢…ê°€(ì›)': 'price',
                'ìƒì¥ì£¼ì‹ìˆ˜(ì£¼)': 'shares_out'
            })
            
            # ìˆ˜ìµë¥  ê³„ì‚° (ì¼ê°„ ìˆ˜ìµë¥ )
            df_temp = df_temp.sort_values(['íšŒì‚¬ëª…', 'ê±°ë˜ì†Œì½”ë“œ', 'date'])
            df_temp['ret'] = df_temp.groupby(['íšŒì‚¬ëª…', 'ê±°ë˜ì†Œì½”ë“œ'])['price'].pct_change()
            
            # ticker_key ìƒì„±
            df_temp['ticker_key'] = df_temp['ê±°ë˜ì†Œì½”ë“œ'].astype(str)
            
            # ë‚ ì§œ ë³€í™˜ (YYYY/MM/DD í˜•ì‹)
            df_temp['date'] = pd.to_datetime(df_temp['date'], format='%Y/%m/%d', errors='coerce')
            
            # íšŒê³„ë…„ë„ ì •ë³´ ì¶”ê°€
            df_temp['year'] = df_temp['date'].dt.year
            
            price_dfs.append(df_temp)
        
        self.prices_df = pd.concat(price_dfs, ignore_index=True)
        print(f"âœ… ê°€ê²© ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(self.prices_df):,}í–‰")
        
        # ì¬ë¬´ ë°ì´í„° ë¡œë”© (processed í´ë”ì—ì„œ)
        self.fs_df = pd.read_csv(self.fs_path, encoding='utf-8-sig')
        print(f"âœ… ì¬ë¬´ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(self.fs_df):,}í–‰")
        
        return self
    
    def preprocess(self):
        """2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬"""
        print("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        
        # íšŒê³„ë…„ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¬ë¬´ ë°ì´í„° ë§¤í•‘
        # íšŒê³„ë…„ë„ ì»¬ëŸ¼ëª… í™•ì¸ ë° ì •ë¦¬
        if 'íšŒê³„ë…„ë„' in self.fs_df.columns:
            # YYYY/MM í˜•ì‹ì„ ë…„ë„ë¡œ ë³€í™˜
            self.fs_df['year'] = self.fs_df['íšŒê³„ë…„ë„']
        
        # ticker_keyë¥¼ fs_dfì—ë„ ì¶”ê°€
        self.fs_df['ticker_key'] = self.fs_df['ê±°ë˜ì†Œì½”ë“œ'].astype(str)
        
        # ê°€ê²© ë°ì´í„°ì— ì—°ë§ ê¸°ì¤€ìœ¼ë¡œ ì¬ë¬´ ë°ì´í„° ë³‘í•©
        # ê° ë…„ë„ì˜ 12ì›” ë°ì´í„°ë§Œ ì‚¬ìš© (ì—°ê°„ íŒ©í„° ê³„ì‚°ìš©)
        monthly_prices = self.prices_df.copy()
        monthly_prices['month'] = monthly_prices['date'].dt.month
        
        # ê° ì›” ë§ˆì§€ë§‰ ê±°ë˜ì¼ ë°ì´í„°ë§Œ ì¶”ì¶œ
        monthly_prices = monthly_prices.loc[monthly_prices.groupby(['ticker_key', 'year', 'month'])['date'].idxmax()]
        
        # ì¬ë¬´ ë°ì´í„°ì™€ ë³‘í•©
        self.df = monthly_prices.merge(
            self.fs_df, 
            on=['ticker_key', 'year'], 
            how='left'
        )
        
        # ì‹œê°€ì´ì•¡ ê³„ì‚°
        self.df['mktcap'] = self.df['price'] * self.df['shares_out']

        # ë¬´í•œê°’ê³¼ ê²°ì¸¡ì¹˜ ì œê±°
        self.df = self.df.replace([np.inf, -np.inf], np.nan).dropna()

        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(self.df):,}í–‰")
        return self
    
    def _compute_annual_returns(self):
        """ì—°ê°„ ë¦¬ë°¸ëŸ°ì‹± ë°ì´í„° ë° ìˆ˜ìµë¥  ê³„ì‚° (4ì›” 1ì¼ ê¸°ì¤€)"""
        # 4ì›” 1ì¼ ê¸°ì¤€ ë¦¬ë°¸ëŸ°ì‹± ë°ì´í„° ì¶”ì¶œ
        rebalance_dates = []
        
        # ê° ë…„ë„ì˜ 4ì›” 1ì¼ ë˜ëŠ” ê°€ì¥ ê°€ê¹Œìš´ ê±°ë˜ì¼ ì°¾ê¸°
        years = sorted(self.df['date'].dt.year.unique())
        for year in years:
            # 4ì›” 1ì¼ ë˜ëŠ” ê·¸ ì´í›„ ê°€ì¥ ê°€ê¹Œìš´ ê±°ë˜ì¼
            target_date = pd.Timestamp(f'{year}-04-01')
            year_data = self.df[self.df['date'].dt.year == year]
            april_data = year_data[year_data['date'] >= target_date]
            
            if not april_data.empty:
                # 4ì›” 1ì¼ ì´í›„ ê°€ì¥ ë¹ ë¥¸ ë‚ ì§œ
                rebalance_date = april_data['date'].min()
                rebalance_dates.append(rebalance_date)
        
        # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ ì¶”ì¶œ
        rebalance_data = self.df[self.df['date'].isin(rebalance_dates)].copy()
        rebalance_data = rebalance_data.sort_values(['ticker_key', 'date'])
        
        # ì—°ê°„ ìˆ˜ìµë¥  ê³„ì‚° (ë¦¬ë°¸ëŸ°ì‹± ê¸°ê°„ ê°„ ìˆ˜ìµë¥ )
        rebalance_data['annual_ret'] = rebalance_data.groupby('ticker_key')['price'].pct_change()
        
        # ì—°ê°„ ìˆ˜ìµë¥ ì„ ì›ë³¸ ë°ì´í„°ì— ë³‘í•©
        annual_ret_df = rebalance_data[['ticker_key', 'date', 'annual_ret']]
        self.df = self.df.merge(annual_ret_df, on=['ticker_key', 'date'], how='left')
        self.df['annual_ret'] = self.df['annual_ret'].fillna(0)
        
        # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ í‘œì‹œ
        self.df['is_rebalance_date'] = self.df['date'].isin(rebalance_dates)
    
    def _compute_magic_formula(self):
        """ë§¤ì§ í¬ë®¬ë¼ - ë­í¬ ê¸°ë°˜ ì ìˆ˜ ì‚¬ìš©"""
        # ì˜ì—…ì´ìµ ìˆ˜ìµë¥  = ì˜ì—…ì´ìµ / ê¸°ì—…ê°€ì¹˜
        self.df['operating_income'] = self.df['ì˜ì—…ì´ìµ']
        self.df['enterprise_value'] = self.df['ê¸°ì—…ê°€ì¹˜']
        self.df['earnings_yield'] = self.df['operating_income'] / self.df['enterprise_value']
        
        # ROIC = ê²½ì˜ìë³¸ì˜ì—…ì´ìµë¥  / 100
        self.df['roic'] = self.df['ê²½ì˜ìë³¸ì˜ì—…ì´ìµë¥ '] / 100
        
        # ë‚ ì§œë³„ë¡œ ë­í¬ ê³„ì‚°
        magic_scores = []
        for date in self.df['date'].unique():
            date_mask = self.df['date'] == date
            date_df = self.df.loc[date_mask].copy()
            
            if len(date_df) < 10:
                continue
            
            # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì‚¬ìš©
            valid_mask = date_df['earnings_yield'].notna() & date_df['roic'].notna()
            valid_df = date_df[valid_mask].copy()
            
            if len(valid_df) < 5:
                continue
            
            # ë­í¬ ê³„ì‚° (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            valid_df['ey_rank'] = valid_df['earnings_yield'].rank(ascending=False)
            valid_df['roic_rank'] = valid_df['roic'].rank(ascending=False)
            
            # ë­í¬ í•©ê³„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            valid_df['magic_rank_sum'] = valid_df['ey_rank'] + valid_df['roic_rank']
            valid_df['magic'] = -valid_df['magic_rank_sum']  # ë‚®ì€ ë­í¬ í•©ì´ ì¢‹ìŒ
            
            magic_scores.append(valid_df[['ticker_key', 'date', 'magic']])
        
        if magic_scores:
            magic_df = pd.concat(magic_scores)
            self.df = self.df.merge(magic_df, on=['ticker_key', 'date'], how='left')
        else:
            self.df['magic'] = 0
    
    def _compute_momentum(self):
        """ëª¨ë©˜í…€ (12-1) - ì—°ê°„ ìˆ˜ìµë¥  ì‚¬ìš©"""
        # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œì—ë§Œ ëª¨ë©˜í…€ ê³„ì‚°
        self.df['mom'] = self.df.groupby('ticker_key')['annual_ret'].apply(
            lambda x: x.shift(1).rolling(3).sum()  # 3ë…„ ëª¨ë©˜í…€
        ).reset_index(0, drop=True)
    
    def _compute_low_volatility(self):
        """ë‚®ì€ ë³€ë™ì„± - ì—°ê°„ ìˆ˜ìµë¥  ë³€ë™ì„± ì‚¬ìš©"""
        self.df['vol3y'] = self.df.groupby('ticker_key')['annual_ret'].apply(
            lambda x: x.rolling(3).std()  # 3ë…„ ë³€ë™ì„±
        ).reset_index(0, drop=True)
        self.df['lovol'] = -self.df['vol3y']
    
    def compute_signals(self):
        """3ë‹¨ê³„: 8ê°œ íŒ©í„° ì‹œê·¸ë„ ê³„ì‚°"""
        print("ğŸ¯ íŒ©í„° ì‹œê·¸ë„ ê³„ì‚° ì¤‘...")
        
        # ë°ì´í„° ì •ë ¬
        self.df = self.df.sort_values(['ticker_key', 'date']).reset_index(drop=True)
        
        # ë¨¼ì € ì—°ê°„ ë¦¬ë°¸ëŸ°ì‹± ë°ì´í„° ë° ìˆ˜ìµë¥  ê³„ì‚°
        self._compute_annual_returns()
        
        # 1. Magic Formula - Rank-based scoring
        self._compute_magic_formula()
        
        # 2. EV/EBITDA - ì‹¤ì œ ì»¬ëŸ¼ì— ì´ë¯¸ ê³„ì‚°ë˜ì–´ ìˆìŒ
        self.df['ev_ebitda'] = self.df['EV_EBITDAë°°ìˆ˜']
        self.df['ev_ebitda_signal'] = -self.df['ev_ebitda']  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        
        # 3. B/M (Book-to-Market) - ì´ìë³¸/ì‹œê°€ì´ì•¡
        self.df['book_value'] = self.df['ì´ìë³¸']
        self.df['market_value'] = self.df['mktcap']
        self.df['bm'] = self.df['book_value'] / self.df['market_value']
        
        # 4. 12-1 Momentum (using annual returns)
        self._compute_momentum()
        
        # 5. Piotroski F-Score (updated with accruals)
        self._compute_fscore()
        
        # 6. QMJ (Quality Minus Junk) - improved
        self._compute_qmj()
        
        # 7. Low Volatility (using annual returns)
        self._compute_low_volatility()
        
        # 8. SMB & HML (Fama-French 3-Factor) - separate factors
        self._compute_ff_factors()
        
        print("âœ… íŒ©í„° ì‹œê·¸ë„ ê³„ì‚° ì™„ë£Œ")
        return self
    
    def _compute_fscore(self):
        """Piotroski F-Score ê³„ì‚° - Updated with accruals signal"""
        # ê¸°ë³¸ ìˆ˜ìµì„± ì§€í‘œ - processed FS.csv ì»¬ëŸ¼ëª… ì‚¬ìš©
        self.df['f_roa'] = (self.df['ì´ìì‚°ìˆ˜ìµë¥ '] > 0).astype(int)
        self.df['f_cfo'] = (self.df['ì˜ì—…í˜„ê¸ˆíë¦„'] > 0).astype(int)
        
        # Accruals signal: (ì˜ì—…í˜„ê¸ˆíë¦„ / ì´ìì‚°) > (ì˜ì—…ì´ìµ / ì´ìì‚°)
        cfo_ta = self.df['ì˜ì—…í˜„ê¸ˆíë¦„'] / self.df['ì´ìì‚°']
        oi_ta = self.df['ì˜ì—…ì´ìµ'] / self.df['ì´ìì‚°']
        self.df['f_accrual'] = (cfo_ta > oi_ta).astype(int)
        
        # ë ˆë²„ë¦¬ì§€, ìœ ë™ì„±, ìê¸ˆì¡°ë‹¬ ì§€í‘œ
        self.df['f_debt'] = (self.df.groupby('ticker_key')['ë¶€ì±„ë¹„ìœ¨'].pct_change() < 0).astype(int)
        self.df['f_liquid'] = (self.df.groupby('ticker_key')['ìœ ë™ë¹„ìœ¨'].pct_change() > 0).astype(int)
        
        # ì‹ ì£¼ë°œí–‰ ì—¬ë¶€ - Updated: ë°œí–‰ì£¼ì‹ì´ìˆ˜ ì¦ê°€ìœ¨ <= 0
        shares_change = self.df.groupby('ticker_key')['ë°œí–‰ì£¼ì‹ì´ìˆ˜'].pct_change()
        self.df['f_shares'] = (shares_change <= 0).astype(int)
        
        # ìš´ì˜ íš¨ìœ¨ì„± ì§€í‘œ
        self.df['f_margin'] = (self.df.groupby('ticker_key')['ë§¤ì¶œì•¡ì´ì´ìµë¥ '].pct_change() > 0).astype(int)
        self.df['f_turn'] = (self.df.groupby('ticker_key')['ì´ìë³¸íšŒì „ë¥ '].pct_change() > 0).astype(int)
        
        # ROA ê°œì„  ì§€í‘œ
        self.df['f_roa_chg'] = (self.df.groupby('ticker_key')['ì´ìì‚°ìˆ˜ìµë¥ '].pct_change() > 0).astype(int)
        
        # F-Score í•©ê³„ (9ê°œ ì§€í‘œ)
        fscore_cols = ['f_roa', 'f_cfo', 'f_accrual', 'f_debt', 'f_liquid', 'f_shares', 'f_margin', 'f_turn', 'f_roa_chg']
        self.df['fscore'] = self.df[fscore_cols].sum(axis=1)
    
    def _compute_qmj(self):
        """QMJ (Quality Minus Junk) ê³„ì‚° - Improved with distinct measures"""
        # ìˆ˜ìµì„± ì§€í‘œë“¤
        profitability_cols = ['ìê¸°ìë³¸ìˆœì´ìµë¥ ', 'ì´ìì‚°ìˆ˜ìµë¥ ']
        
        # ì•ˆì •ì„± ì§€í‘œë“¤ - ì¶”ê°€: ë°°ë‹¹ë¹„ìœ¨, ì¥ê¸° ë ˆë²„ë¦¬ì§€
        safety_cols = ['ë¶€ì±„ë¹„ìœ¨', 'vol12m']
        
        # ì„±ì¥ì„± ì§€í‘œë“¤ - ì¤‘ë³µ ì œê±°, 5ë…„ ë§¤ì¶œ CAGR ëŒ€ì‹  ë§¤ì¶œì•¡ì¦ê°€ìœ¨ ì‚¬ìš©
        growth_cols = ['ë§¤ì¶œì•¡ì¦ê°€ìœ¨']  # ë§¤ì¶œì•¡ì´ì´ìµë¥  ì œê±°
        
        # ê° ê·¸ë£¹ë³„ë¡œ Z-score í‘œì¤€í™”
        quality_scores = []
        
        for date in self.df['date'].unique():
            date_mask = self.df['date'] == date
            date_df = self.df.loc[date_mask].copy()
            
            if len(date_df) < 10:
                continue
                
            # ìˆ˜ìµì„± (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            prof_score = 0
            for col in profitability_cols:
                if col in date_df.columns and date_df[col].notna().sum() > 5:
                    prof_score += stats.zscore(date_df[col].fillna(date_df[col].median()))
            
            # ì•ˆì •ì„± (ë¶€ì±„ë¹„ìœ¨, ë³€ë™ì„±ì€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            safety_score = 0
            for col in safety_cols:
                if col in date_df.columns and date_df[col].notna().sum() > 5:
                    safety_score -= stats.zscore(date_df[col].fillna(date_df[col].median()))
            
            # ë°°ë‹¹ë¹„ìœ¨ ì¶”ê°€ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            if 'ë°°ë‹¹ë¹„ìœ¨' in date_df.columns and date_df['ë°°ë‹¹ë¹„ìœ¨'].notna().sum() > 5:
                safety_score -= stats.zscore(date_df['ë°°ë‹¹ë¹„ìœ¨'].fillna(date_df['ë°°ë‹¹ë¹„ìœ¨'].median()))
            
            # ì„±ì¥ì„± (ì „ë…„ ëŒ€ë¹„ ì¦ê°€ìœ¨)
            growth_score = 0
            for col in growth_cols:
                if col in date_df.columns and date_df[col].notna().sum() > 5:
                    growth_score += stats.zscore(date_df[col].fillna(date_df[col].median()))
            
            date_df['qmj'] = (prof_score + safety_score + growth_score) / 3
            quality_scores.append(date_df[['ticker_key', 'date', 'qmj']])
        
        if quality_scores:
            qmj_df = pd.concat(quality_scores)
            self.df = self.df.merge(qmj_df, on=['ticker_key', 'date'], how='left')
        else:
            self.df['qmj'] = 0
    
    def _compute_ff_factors(self):
        """Fama-French SMB & HML íŒ©í„° ê³„ì‚° - ì—°ê°„ ë¦¬ë°¸ëŸ°ì‹±"""
        # ì—°ê°„ ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œë³„ë¡œ sizeì™€ value ê¸°ì¤€ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
        ff_returns = []
        
        # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œë§Œ ì‚¬ìš©
        rebalance_data = self.df[self.df['is_rebalance_date'] == True]
        annual_dates = rebalance_data['date'].unique()
        
        for rebal_date in annual_dates:
            annual_df = rebalance_data[rebalance_data['date'] == rebal_date].copy()
            
            if len(annual_df) < 20:
                continue
            
            # Sizeì™€ B/M ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (annual_ret ì‚¬ìš©)
            annual_df = annual_df.dropna(subset=['mktcap', 'bm', 'annual_ret'])
            
            if len(annual_df) < 6:
                continue
                
            # ì‹œê°€ì´ì•¡ ì¤‘ìœ„ìˆ˜ ê¸°ì¤€ ë¶„í• 
            size_median = annual_df['mktcap'].median()
            
            # B/M 30%, 70% ë¶„ìœ„ìˆ˜ ê¸°ì¤€ ë¶„í• 
            bm_30 = annual_df['bm'].quantile(0.3)
            bm_70 = annual_df['bm'].quantile(0.7)
            
            # 6ê°œ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
            portfolios = {
                'SL': annual_df[(annual_df['mktcap'] <= size_median) & (annual_df['bm'] <= bm_30)],
                'SM': annual_df[(annual_df['mktcap'] <= size_median) & (annual_df['bm'] > bm_30) & (annual_df['bm'] <= bm_70)],
                'SH': annual_df[(annual_df['mktcap'] <= size_median) & (annual_df['bm'] > bm_70)],
                'BL': annual_df[(annual_df['mktcap'] > size_median) & (annual_df['bm'] <= bm_30)],
                'BM': annual_df[(annual_df['mktcap'] > size_median) & (annual_df['bm'] > bm_30) & (annual_df['bm'] <= bm_70)],
                'BH': annual_df[(annual_df['mktcap'] > size_median) & (annual_df['bm'] > bm_70)]
            }
            
            # ê° í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚° (ë™ì¼ê°€ì¤‘)
            port_returns = {}
            for name, port in portfolios.items():
                if len(port) > 0:
                    port_returns[name] = port['annual_ret'].mean()
                else:
                    port_returns[name] = 0
            
            # SMBì™€ HML ê³„ì‚°
            if all(name in port_returns for name in ['SL', 'SM', 'SH', 'BL', 'BM', 'BH']):
                smb = (port_returns['SL'] + port_returns['SM'] + port_returns['SH']) / 3 - \
                      (port_returns['BL'] + port_returns['BM'] + port_returns['BH']) / 3
                
                hml = (port_returns['SH'] + port_returns['BH']) / 2 - \
                      (port_returns['SL'] + port_returns['BL']) / 2
                
                ff_returns.append({
                    'date': rebal_date,
                    'smb': smb,
                    'hml': hml,
                    'smb_hml': smb * hml  # SMBÃ—HML êµì°¨í•­ (ì˜µì…˜)
                })
        
        if ff_returns:
            ff_df = pd.DataFrame(ff_returns)
            
            # ì›ë³¸ ë°ì´í„°ì— ë³‘í•© - SMB, HML, SMBÃ—HML ëª¨ë‘ í¬í•¨
            self.df = self.df.merge(ff_df[['date', 'smb', 'hml', 'smb_hml']], on='date', how='left')
        else:
            self.df['smb'] = 0
            self.df['hml'] = 0
            self.df['smb_hml'] = 0
    
    def get_factor_returns(self, signal_col, universe_mask=None, top_pct=0.3):
        """4ë‹¨ê³„: íŒ©í„° ìˆ˜ìµë¥  ê³„ì‚° - ì—°ê°„ ë¦¬ë°¸ëŸ°ì‹± (4ì›” 1ì¼)"""
        if universe_mask is None:
            universe_mask = self.df.index
        
        # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œì—ë§Œ íŒ©í„° ê³„ì‚°
        tmp = self.df.loc[universe_mask].copy()
        tmp = tmp[tmp['is_rebalance_date'] == True]  # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œë§Œ
        tmp = tmp.dropna(subset=[signal_col, 'annual_ret'])
        
        factor_returns = []
        portfolio_holdings = []  # í„´ì˜¤ë²„ ê³„ì‚°ì„ ìœ„í•œ ë³´ìœ  ì¢…ëª©
        
        # ë…„ë„ë³„ë¡œ ê·¸ë£¹í™”
        tmp['year'] = tmp['date'].dt.year
        
        for year, grp in tmp.groupby('year'):
            if len(grp) < 10:
                continue
                
            n = max(1, int(len(grp) * top_pct))
            
            # Long: ìƒìœ„ 30%
            long_stocks = grp.nlargest(n, signal_col)
            long_ret = long_stocks['annual_ret'].mean()
            
            # Short: í•˜ìœ„ 30%  
            short_stocks = grp.nsmallest(n, signal_col)
            short_ret = short_stocks['annual_ret'].mean()
            
            # ëŒ€í‘œ ë‚ ì§œ (ê·¸ ë…„ë„ì˜ 4ì›” 1ì¼)
            rebalance_date = grp['date'].iloc[0]
            
            factor_returns.append({
                'date': rebalance_date,
                'long_ret': long_ret,
                'short_ret': short_ret,
                'factor_ret': long_ret - short_ret,
                'n_stocks': len(grp)
            })
            
            # í¬íŠ¸í´ë¦¬ì˜¤ ë³´ìœ  ì¢…ëª© ì €ì¥
            portfolio_holdings.append({
                'date': rebalance_date,
                'long_tickers': set(long_stocks['ticker_key']),
                'short_tickers': set(short_stocks['ticker_key'])
            })
        
        factor_df = pd.DataFrame(factor_returns).set_index('date')
        
        # í„´ì˜¤ë²„ ê³„ì‚° (ì—°ê°„ ë¦¬ë°¸ëŸ°ì‹±)
        if len(portfolio_holdings) > 1:
            turnovers = []
            for i in range(1, len(portfolio_holdings)):
                prev_long = portfolio_holdings[i-1]['long_tickers']
                curr_long = portfolio_holdings[i]['long_tickers']
                prev_short = portfolio_holdings[i-1]['short_tickers']
                curr_short = portfolio_holdings[i]['short_tickers']
                
                # ì „ì²´ ë³´ìœ  ì¢…ëª© ëŒ€ë¹„ ë³€ê²½ëœ ë¹„ìœ¨
                total_prev = len(prev_long) + len(prev_short)
                changed = len(prev_long.symmetric_difference(curr_long)) + len(prev_short.symmetric_difference(curr_short))
                turnover = changed / total_prev if total_prev > 0 else 0
                
                turnovers.append(turnover)
            
            factor_df['turnover'] = [np.nan] + turnovers
        else:
            factor_df['turnover'] = np.nan
        
        return factor_df
    
    def backtest(self):
        """5ë‹¨ê³„: ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ“ˆ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        # 2013ë…„ ì´í›„ ë°ì´í„°ë§Œ ì‚¬ìš© (2012ë…„ì€ warm-up)
        backtest_mask = self.df['date'] >= '2013-01-01'
        
        factor_signals = {
            'Magic Formula': 'magic',
            'EV/EBITDA': 'ev_ebitda_signal', 
            'Book-to-Market': 'bm',
            'Momentum (12-1)': 'mom',
            'Piotroski F-Score': 'fscore',
            'Quality (QMJ)': 'qmj',
            'Low Volatility': 'lovol',
            'SMB (Size)': 'smb',
            'HML (Value)': 'hml',
            'SMBÃ—HML': 'smb_hml'
        }
        
        for strategy_name, signal_col in factor_signals.items():
            print(f"  ğŸ”„ {strategy_name} ê³„ì‚° ì¤‘...")
            
            # ì „ì²´ ìœ ë‹ˆë²„ìŠ¤
            full_universe = backtest_mask
            full_returns = self.get_factor_returns(signal_col, full_universe)
            
            # ìš°ëŸ‰ê¸°ì—… ìœ ë‹ˆë²„ìŠ¤ (default == 0)
            quality_universe = backtest_mask & (self.df['default'] == 0)
            quality_returns = self.get_factor_returns(signal_col, quality_universe)
            
            self.factor_returns[f"{strategy_name}_Full"] = full_returns
            self.factor_returns[f"{strategy_name}_Quality"] = quality_returns
        
        print("âœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return self
    
    def calc_performance_stats(self):
        """6ë‹¨ê³„: ì„±ê³¼ì§€í‘œ ê³„ì‚°"""
        print("ğŸ“Š ì„±ê³¼ì§€í‘œ ê³„ì‚° ì¤‘...")
        
        for strategy_name, returns_df in self.factor_returns.items():
            if len(returns_df) == 0:
                continue
                
            ret_series = returns_df['factor_ret'].dropna()
            
            if len(ret_series) < 3:  # ìµœì†Œ 3ë…„ ë°ì´í„° í•„ìš”
                continue
            
            # ê¸°ë³¸ í†µê³„ - ì—°ê°„ ë¦¬ë°¸ëŸ°ì‹± ë°˜ì˜
            # ann_ret = ret_series.mean() * 12  # Removed: arithmetic annualized return
            ann_vol = ret_series.std()  # ì—°ê°„ ë°ì´í„°ì´ë¯€ë¡œ ë£¨íŠ¸ ì—†ì´ ì‚¬ìš©
            
            # CAGR (Compound Annual Growth Rate) calculation
            # CAGR represents compound growth rather than arithmetic average
            cum_ret = (1 + ret_series).cumprod()  # Portfolio value series
            start_value = cum_ret.iloc[0]
            end_value = cum_ret.iloc[-1]
            n_periods = len(cum_ret)  # number of data points (years)
            periods_per_year = 1  # annual data
            n_years = n_periods / periods_per_year
            
            if n_years > 0 and start_value > 0:
                cagr = (end_value / start_value) ** (1 / n_years) - 1
            else:
                cagr = 0
            
            # Updated metrics using CAGR instead of ann_ret
            sharpe = cagr / ann_vol if ann_vol > 0 else 0
            
            # ëˆ„ì ìˆ˜ìµë¥ ê³¼ ìµœëŒ€ë‚™í­
            running_max = cum_ret.cummax()
            drawdown = (cum_ret / running_max - 1)
            max_dd = drawdown.min()
            
            # ì •ë³´ë¹„ìœ¨ - ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ê³„ì‚° (ì‹œì¥ í‰ê·  ìˆ˜ìµë¥  ê°€ì •: 10% ì—°ê°„)
            benchmark_ret = 0.10  # ì—°ê°„ 10%
            excess_ret = ret_series - benchmark_ret
            tracking_error = excess_ret.std()  # ì—°ê°„ ë°ì´í„°
            info_ratio = excess_ret.mean() / tracking_error if tracking_error > 0 else 0
            
            # ì¹¼ë§ˆë¹„ìœ¨ - using CAGR
            calmar = cagr / abs(max_dd) if max_dd != 0 else 0
            
            # MÂ² ì¸¡ë„ (ì‹œì¥ ë³€ë™ì„± ëŒ€ë¹„ ì¡°ì •ìˆ˜ìµë¥ ) - using CAGR
            market_vol = 0.15  # ê°€ì •: ì‹œì¥ ì—°ë³€ë™ì„± 15%
            m2_measure = cagr * (market_vol / ann_vol) if ann_vol > 0 else 0
            
            # ìµœëŒ€ë‚™í­ ì§€ì†ê¸°ê°„
            dd_periods = []
            in_drawdown = False
            dd_start = None
            
            for i, dd_val in enumerate(drawdown):
                if dd_val < -0.001 and not in_drawdown:  # ë‚™í­ ì‹œì‘
                    in_drawdown = True
                    dd_start = i
                elif dd_val >= -0.001 and in_drawdown:  # ë‚™í­ íšŒë³µ
                    in_drawdown = False
                    if dd_start is not None:
                        dd_periods.append(i - dd_start)
            
            dd_duration = max(dd_periods) if dd_periods else 0
            
            # VaR & CVaR (95% ì‹ ë¢°ìˆ˜ì¤€)
            var_95 = np.percentile(ret_series, 5)
            cvar_95 = ret_series[ret_series <= var_95].mean()
            
            # ì‹¤ì œ í„´ì˜¤ë²„ìœ¨ ê³„ì‚°
            if 'turnover' in returns_df.columns:
                turnover = returns_df['turnover'].mean()
            else:
                turnover = 0.20  # ê¸°ë³¸ê°’
            
            # ìƒìŠ¹/í•˜ë½ ìº¡ì²˜ ë¹„ìœ¨ - ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ê³„ì‚° (ì—°ê°„ ê¸°ì¤€)
            benchmark_returns = pd.Series([benchmark_ret] * len(ret_series), index=ret_series.index)
            up_periods = ret_series > benchmark_ret  # ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ ìƒìŠ¹
            down_periods = ret_series <= benchmark_ret  # ë²¤ì¹˜ë§ˆí¬ ëŒ€ë¹„ í•˜ë½
            
            if up_periods.sum() > 0:
                up_capture = ret_series[up_periods].mean() / benchmark_returns[up_periods].mean()
            else:
                up_capture = 1.0
                
            if down_periods.sum() > 0:
                down_capture = ret_series[down_periods].mean() / benchmark_returns[down_periods].mean()
            else:
                down_capture = 1.0
            
            self.performance_stats[strategy_name] = {
                'CAGR': cagr,  # Updated from AnnRet to CAGR
                'AnnVol': ann_vol, 
                'Sharpe': sharpe,
                'MaxDD': max_dd,
                'IR': info_ratio,
                'Calmar': calmar,
                'M2': m2_measure,
                'DD_Duration': dd_duration,
                'Turnover': turnover,
                'UpCapture': up_capture,
                'DownCapture': down_capture,
                'VaR95': var_95,
                'CVaR95': cvar_95
            }
        
        print("âœ… ì„±ê³¼ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        return self
    
    def plot_results(self):
        """7ë‹¨ê³„: ì‹œê°í™”"""
        print("ğŸ“ˆ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        # 1) ëˆ„ì ìˆ˜ìµë¥  ì°¨íŠ¸
        self._plot_cumulative_returns()
        
        # 2) ì„±ê³¼ì§€í‘œ ë§‰ëŒ€ì°¨íŠ¸
        self._plot_performance_bars()
        
        # 3) íˆíŠ¸ë§µ
        self._plot_heatmap()
        
        # 4) ì›”ê°„ ìˆ˜ìµë¥  ë°•ìŠ¤í”Œë¡¯
        self._plot_monthly_boxplot()
        
        # 5) ë‚™í­ ê³¡ì„ 
        self._plot_drawdown_curves()
        
        print("âœ… ì‹œê°í™” ì™„ë£Œ")
        return self
    
    def _plot_cumulative_returns(self):
        """ëˆ„ì ìˆ˜ìµë¥  ì°¨íŠ¸"""
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('ì „ì²´ ìœ ë‹ˆë²„ìŠ¤', 'ìš°ëŸ‰ê¸°ì—… ìœ ë‹ˆë²„ìŠ¤'),
            vertical_spacing=0.1
        )
        
        colors = px.colors.qualitative.Set1
        
        for i, (strategy_name, returns_df) in enumerate(self.factor_returns.items()):
            if len(returns_df) == 0:
                continue
                
            cum_ret = (1 + returns_df['factor_ret']).cumprod()
            
            row = 1 if '_Full' in strategy_name else 2
            name = strategy_name.replace('_Full', '').replace('_Quality', '')
            
            fig.add_trace(
                go.Scatter(
                    x=cum_ret.index,
                    y=cum_ret.values,
                    name=name,
                    line=dict(color=colors[i % len(colors)]),
                    showlegend=(row == 1)
                ),
                row=row, col=1
            )
        
        fig.update_layout(
            title="íŒ©í„° ì „ëµë³„ ëˆ„ì ìˆ˜ìµë¥ ",
            font=dict(family='AppleGothic'),  # í•œê¸€ í°íŠ¸ ì„¤ì •
            height=800,
            hovermode='x unified'
        )
        
        fig.show()
        
    def _plot_performance_bars(self):
        """ì„±ê³¼ì§€í‘œ ë§‰ëŒ€ì°¨íŠ¸"""
        if not self.performance_stats:
            return
            
        stats_df = pd.DataFrame(self.performance_stats).T
        
        metrics = ['CAGR', 'Sharpe', 'Calmar', 'MaxDD']
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()
        
        for i, metric in enumerate(metrics):
            if metric in stats_df.columns:
                ax = axes[i]
                
                # Full vs Quality ë¶„ë¦¬
                full_data = stats_df[stats_df.index.str.contains('_Full')][metric]
                quality_data = stats_df[stats_df.index.str.contains('_Quality')][metric]
                
                x_labels = [name.replace('_Full', '') for name in full_data.index]
                
                x = np.arange(len(x_labels))
                width = 0.35
                
                ax.bar(x - width/2, full_data.values, width, label='ì „ì²´', alpha=0.8)
                ax.bar(x + width/2, quality_data.values, width, label='ìš°ëŸ‰ê¸°ì—…', alpha=0.8)
                
                ax.set_title(f'{metric}')
                ax.set_xticks(x)
                ax.set_xticklabels(x_labels, rotation=45, ha='right')
                ax.legend()
                ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'factor_performance_bars.png'), dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_heatmap(self):
        """ì„±ê³¼ì§€í‘œ íˆíŠ¸ë§µ"""
        if not self.performance_stats:
            return
            
        stats_df = pd.DataFrame(self.performance_stats).T
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = ['CAGR', 'AnnVol', 'Sharpe', 'MaxDD', 'IR', 'Calmar']
        heatmap_data = stats_df[numeric_cols].fillna(0)
        
        plt.figure(figsize=(12, 8))
        sns.heatmap(
            heatmap_data,
            annot=True,
            fmt='.3f',
            cmap='RdYlBu_r',
            center=0,
            cbar_kws={'label': 'ê°’'}
        )
        plt.title('íŒ©í„° ì „ëµë³„ ì„±ê³¼ì§€í‘œ íˆíŠ¸ë§µ')
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'factor_heatmap.png'), dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_monthly_boxplot(self):
        """ì›”ê°„ ìˆ˜ìµë¥  ë°•ìŠ¤í”Œë¡¯"""
        monthly_data = []
        
        for strategy_name, returns_df in self.factor_returns.items():
            if len(returns_df) == 0:
                continue
                
            for date, row in returns_df.iterrows():
                monthly_data.append({
                    'Strategy': strategy_name.replace('_Full', '').replace('_Quality', ''),
                    'Universe': 'Full' if '_Full' in strategy_name else 'Quality',
                    'Return': row['factor_ret'],
                    'Date': date
                })
        
        if not monthly_data:
            return
            
        monthly_df = pd.DataFrame(monthly_data)
        
        plt.figure(figsize=(15, 8))
        sns.boxplot(data=monthly_df, x='Strategy', y='Return', hue='Universe')
        plt.title('íŒ©í„°ë³„ ì›”ê°„ ìˆ˜ìµë¥  ë¶„í¬')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'monthly_returns_boxplot.png'), dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_drawdown_curves(self):
        """ë‚™í­ ê³¡ì„ """
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))
        
        colors = plt.cm.Set1(np.linspace(0, 1, 8))
        
        for i, (strategy_name, returns_df) in enumerate(self.factor_returns.items()):
            if len(returns_df) == 0:
                continue
                
            cum_ret = (1 + returns_df['factor_ret']).cumprod()
            drawdown = (cum_ret / cum_ret.cummax() - 1) * 100
            
            ax = ax1 if '_Full' in strategy_name else ax2
            name = strategy_name.replace('_Full', '').replace('_Quality', '')
            
            ax.fill_between(
                drawdown.index, 
                drawdown.values, 
                0, 
                alpha=0.6,
                color=colors[i % len(colors)],
                label=name
            )
        
        ax1.set_title('Drawdown Curves - ì „ì²´ ìœ ë‹ˆë²„ìŠ¤')
        ax1.set_ylabel('Drawdown (%)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        ax2.set_title('Drawdown Curves - ìš°ëŸ‰ê¸°ì—… ìœ ë‹ˆë²„ìŠ¤')
        ax2.set_ylabel('Drawdown (%)')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'drawdown_curves.png'), dpi=300, bbox_inches='tight')
        plt.show()
    
    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        # ì„±ê³¼ í†µê³„ ì €ì¥
        if self.performance_stats:
            stats_df = pd.DataFrame(self.performance_stats).T
            stats_df.to_csv(os.path.join(self.output_dir, 'factor_performance_stats.csv'), encoding='utf-8-sig')
            print("âœ… ì„±ê³¼í†µê³„ ì €ì¥: factor_performance_stats.csv")
        
        # íŒ©í„° ìˆ˜ìµë¥  ì €ì¥
        for strategy_name, returns_df in self.factor_returns.items():
            if len(returns_df) > 0:
                # íŒŒì¼ ì´ë¦„ì— ì‚¬ìš© ë¶ˆê°€ëŠ¥ ë¬¸ìê°€ ìˆì„ ê²½ìš° ëŒ€ì²´
                safe_name = strategy_name.replace('/', '_')
                filename = os.path.join(self.output_dir, f"factor_returns_{safe_name}.csv")
                returns_df.to_csv(filename, encoding='utf-8-sig')
        
        print("âœ… íŒ©í„° ìˆ˜ìµë¥  ì €ì¥ ì™„ë£Œ")
        
        # ìš”ì•½ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ“Š FACTOR BACKTESTING SUMMARY")
        print("="*60)
        
        if self.performance_stats:
            for strategy, stats in self.performance_stats.items():
                print(f"\nğŸ¯ {strategy}")
                print(f"   CAGR: {stats['CAGR']:.2%}")
                print(f"   ìƒ¤í”„ë¹„ìœ¨: {stats['Sharpe']:.3f}")
                print(f"   ìµœëŒ€ë‚™í­: {stats['MaxDD']:.2%}")
                print(f"   ì¹¼ë§ˆë¹„ìœ¨: {stats['Calmar']:.3f}")
        
        return self

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Factor Investing Backtesting ì‹œì‘")
    print("="*60)
    
    # ë°±í…ŒìŠ¤í„° ì´ˆê¸°í™” ë° ì‹¤í–‰
    backtester = FactorBacktester()
    
    backtester.load_data() \
              .preprocess() \
              .compute_signals() \
              .backtest() \
              .calc_performance_stats() \
              .plot_results() \
              .save_results()
    
    print("\nğŸ‰ ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return backtester

if __name__ == "__main__":
    # ì‹¤í–‰
    results = main()