"""
Factor Investing Backtesting Framework - Updated Version
FF3 í†µí•© ì „ëµ, B/M ì œê±°, DOL/DFL ì œê±° ë²„ì „
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
try:
    import plotly.graph_objects as go
    import plotly.express as px
    from plotly.subplots import make_subplots
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False
    print("Warning: plotly not available. Visualization will be limited.")

try:
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    print("Warning: scikit-learn not available. Some features may be limited.")

from scipy import stats
import warnings
import glob
import os
import argparse
try:
    from pykrx import stock, bond
    PYKRX_AVAILABLE = True
except ImportError:
    PYKRX_AVAILABLE = False
    print("Warning: pykrx not available. FF3 factor builder will use mock data.")
from datetime import datetime
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì • (OSë³„ ìë™ ê°ì§€)
import platform

if platform.system() == 'Darwin':  # macOS
    plt.rcParams['font.family'] = 'AppleGothic'
elif platform.system() == 'Windows':  # Windows
    plt.rcParams['font.family'] = 'Malgun Gothic'
else:  # Linux and others
    plt.rcParams['font.family'] = 'DejaVu Sans'
    
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('seaborn-v0_8')

class FactorBacktester:
    """íŒ©í„° íˆ¬ì ë°±í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ - Updated with FF3 Integration"""
    
    def __init__(self, data_path=None, output_dir=None, top_n=10, fscore_min_score=8, momentum_period=12):
        # ë‹¨ìˆœí•œ ê²½ë¡œ ì„¤ì • - í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€
        self.data_path = data_path or 'data/processed'
        self.df = None
        self.factor_returns = {}
        self.performance_stats = {}
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ì„¤ì •
        self.top_n = top_n  # ìƒìœ„ nê°œ ì¢…ëª© ì„ íƒ
        self.fscore_min_score = fscore_min_score  # F-score ìµœì†Œ ì ìˆ˜
        self.momentum_period = momentum_period  # ëª¨ë©˜í…€ ê¸°ê°„ (ê°œì›”)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì • - íŒŒë¼ë¯¸í„° ì¡°í•©ë³„ë¡œ í•˜ìœ„ í´ë” ìƒì„±
        base_output_dir = output_dir or 'outputs/backtesting'
        param_suffix = f"top{top_n}_f{fscore_min_score}_mom{momentum_period}m"
        self.output_dir = os.path.join(base_output_dir, param_suffix)
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {self.output_dir}")
        
    def load_data(self):
        """1ë‹¨ê³„: ë°ì´í„° ë¡œë”© ë° ë³‘í•©"""
        print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # 1) ì¬ë¬´ì œí‘œ ì›ë³¸ (FS2.csv) - data/processedì—ì„œ ì°¾ê¸°
        fs_path = os.path.join(self.data_path, 'FS2_default.csv')
        if not os.path.exists(fs_path):
            # ëŒ€ì•ˆ ê²½ë¡œë“¤ ì‹œë„
            alternative_paths = ['data/processed/FS2_default.csv', 'data/FS2_default.csv', 'FS2_default.csv']
            for alt_path in alternative_paths:
                if os.path.exists(alt_path):
                    fs_path = alt_path
                    break
            else:
                raise FileNotFoundError(f"FS2_default.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        df_fs = pd.read_csv(fs_path, encoding='utf-8-sig')
        # FS2_default.csvì˜ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ì œê±° (ì‹œê°€ì´ì•¡.csvì˜ ì •í™•í•œ ê°’ ì‚¬ìš© ìœ„í•´)
        if 'ì‹œê°€ì´ì•¡' in df_fs.columns:
            df_fs = df_fs.drop(columns=['ì‹œê°€ì´ì•¡'])
            print("âš ï¸  FS2_default.csvì˜ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ì œê±° (ì‹œê°€ì´ì•¡.csv ì‚¬ìš© ì˜ˆì •)")
        if 'ë¡œê·¸ì‹œê°€ì´ì•¡' in df_fs.columns:
            df_fs = df_fs.drop(columns=['ë¡œê·¸ì‹œê°€ì´ì•¡'])
            print("âš ï¸  FS2_default.csvì˜ ë¡œê·¸ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ì œê±°")
        print(f"âœ… ì¬ë¬´ì œí‘œ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df_fs):,}í–‰")
        
        # 2) ì—°ë„ë³„ ì£¼ê°€Â·ê±°ë˜ëŸ‰Â·ë°œí–‰ì£¼ì‹ìˆ˜Â·ì£¼ë‹¹ë°°ë‹¹ê¸ˆ (2012.csv ~ 2023.csv)
        price_files = []
        for data_dir in ['data/raw', 'data', '.']:
            pattern = os.path.join(data_dir, '20*.csv')
            found_files = sorted(glob.glob(pattern))
            if found_files:
                price_files = found_files
                break
        
        if not price_files:
            raise FileNotFoundError("ì—°ë„ë³„ ì£¼ê°€ ë°ì´í„° íŒŒì¼ë“¤(20XX.csv)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        price_dfs = []
        for f in price_files:
            df_temp = pd.read_csv(f, encoding='utf-8-sig')
            price_dfs.append(df_temp)
        
        df_price = pd.concat(price_dfs, ignore_index=True)
        print(f"âœ… ì£¼ê°€ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df_price):,}í–‰")
        
        # 3) ì‹œê°€ì´ì•¡ (ì‹œê°€ì´ì•¡.csv) - ìš°ì„ ì£¼ í¬í•¨í•œ ì •í™•í•œ ì‹œê°€ì´ì•¡
        mkt_path = None
        for data_dir in ['data/processed', 'data/raw', 'data', '.']:
            test_path = os.path.join(data_dir, 'ì‹œê°€ì´ì•¡.csv')
            if os.path.exists(test_path):
                mkt_path = test_path
                break
        
        if not mkt_path:
            raise FileNotFoundError("ì‹œê°€ì´ì•¡.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        df_mkt = pd.read_csv(mkt_path, encoding='utf-8-sig')
        print(f"âœ… ì‹œê°€ì´ì•¡ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df_mkt):,}í–‰")
        
        # ì»¬ëŸ¼ëª… í†µì¼ (íšŒê³„ë…„ë„ â†’ ì—°ë„) ë° ë°ì´í„° íƒ€ì… í†µì¼
        if 'íšŒê³„ë…„ë„' in df_fs.columns:
            df_fs['ì—°ë„'] = pd.to_numeric(df_fs['íšŒê³„ë…„ë„'], errors='coerce').astype('Int64')
        if 'íšŒê³„ë…„ë„' in df_price.columns:
            df_price['ì—°ë„'] = pd.to_numeric(df_price['íšŒê³„ë…„ë„'], errors='coerce').astype('Int64')
        if 'íšŒê³„ë…„ë„' in df_mkt.columns:
            df_mkt['ì—°ë„'] = pd.to_numeric(df_mkt['íšŒê³„ë…„ë„'], errors='coerce').astype('Int64')
        
        # 4) ë³‘í•© (ê±°ë˜ì†Œì½”ë“œ + ì—°ë„)
        self.df = (df_fs
                   .merge(df_price, how='left', on=['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„'])
                   .merge(df_mkt, how='left', on=['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„']))
        
        # 5) ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ í™•ì¸ ë° ê²°ì¸¡ì¹˜ ë³´ì™„
        if 'ì‹œê°€ì´ì•¡' in self.df.columns:
            print("âœ… ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ í™•ì¸ë¨")
            na_mask = self.df['ì‹œê°€ì´ì•¡'].isna()
            na_count = na_mask.sum()
            if na_count > 0:
                print(f"âš ï¸  ì‹œê°€ì´ì•¡ ê²°ì¸¡ì¹˜ {na_count:,}ê°œ ë°œê²¬")
                if 'ì¢…ê°€' in self.df.columns and 'ë°œí–‰ì£¼ì‹ì´ìˆ˜' in self.df.columns:
                    self.df.loc[na_mask, 'ì‹œê°€ì´ì•¡'] = self.df.loc[na_mask, 'ì¢…ê°€'] * self.df.loc[na_mask, 'ë°œí–‰ì£¼ì‹ì´ìˆ˜']
                    print(f"âœ… ê²°ì¸¡ì¹˜ {na_count:,}ê°œë¥¼ ì¢…ê°€ Ã— ë°œí–‰ì£¼ì‹ì´ìˆ˜ë¡œ ë³´ì™„")
        else:
            print("âŒ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            return self
        
        # ì •ë ¬
        self.df = self.df.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„']).reset_index(drop=True)
        print(f"âœ… ë°ì´í„° ë³‘í•© ì™„ë£Œ: {len(self.df):,}í–‰")
        
        return self
    
    def compute_features(self):
        """2ë‹¨ê³„: Balance-Sheet Flow Convention & íŒ©í„° íŠ¹ì„± ê³„ì‚°"""
        print("ğŸ”„ íŠ¹ì„± ê³„ì‚° ì¤‘...")
        
        # B/S í•­ëª©ë“¤ì˜ í‰ê· ê°’ ê³„ì‚° (ë‹¹ê¸°ë§ + ì „ê¸°ë§) / 2
        bs_cols = ['ì´ìì‚°','ì´ë¶€ì±„','ì´ìë³¸','ìœ ë™ìì‚°','ìœ ë™ë¶€ì±„',
                   'ë‹¨ê¸°ì°¨ì…ê¸ˆ','ì¥ê¸°ì°¨ì…ê¸ˆ','ìœ í˜•ìì‚°','ë¬´í˜•ìì‚°',
                   'ì¬ê³ ìì‚°','í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°','ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ(ê¸ˆìœµê¸°ê´€ì˜ˆì¹˜ê¸ˆ)']
        
        for c in bs_cols:
            if c in self.df.columns:
                self.df[f'avg_{c}'] = (self.df[c] + self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')[c].shift(1)) / 2
        
        # ì´ì´ìë¹„ìš© = ì´ìë¹„ìš© (already in FS2)
        if 'ì´ìë¹„ìš©' in self.df.columns:
            self.df['ì´ì´ìë¹„ìš©'] = self.df['ì´ìë¹„ìš©']
        
        # ê¸°ë³¸ ê³„ì‚°ìš© ì»¬ëŸ¼ë“¤
        if 'ë§¤ì¶œì•¡' in self.df.columns:
            self.df['ë§¤ì¶œì•¡ì¦ê°€ìœ¨'] = self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ë§¤ì¶œì•¡'].pct_change()
        if 'ì˜ì—…ì´ìµ' in self.df.columns:
            self.df['ì˜ì—…ì´ìµì¦ê°€ìœ¨'] = self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì˜ì—…ì´ìµ'].pct_change()
        
        print("âœ… íŠ¹ì„± ê³„ì‚° ì™„ë£Œ")
        return self
    
    def compute_factor_signals(self):
        """3ë‹¨ê³„: íŒ©í„° ì‹œê·¸ë„ ê³„ì‚° (ì—…ë°ì´íŠ¸ëœ ë²„ì „)"""
        print("ğŸ¯ íŒ©í„° ì‹œê·¸ë„ ê³„ì‚° ì¤‘...")
        
        # ë°ì´í„° ì •ë ¬
        self.df = self.df.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„']).reset_index(drop=True)
        
        # default ì»¬ëŸ¼ í™•ì¸ ë° ê²€ì¦
        if 'default' not in self.df.columns:
            print("  âŒ 'default' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            print("  ğŸ’¡ ë¶€ì‹¤/ì •ìƒ ê¸°ì—… êµ¬ë¶„ ë¶„ì„ì„ ìœ„í•´ default ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print("  ğŸ’¡ ëŒ€ì•ˆ: ì¬ë¬´ë¹„ìœ¨ ê¸°ë°˜ìœ¼ë¡œ ê¸°ì—…ì„ ë¶„ë¥˜í•˜ê² ìŠµë‹ˆë‹¤.")
            
            # ì¬ë¬´ë¹„ìœ¨ ê¸°ë°˜ ë¶„ë¥˜ (ì˜ˆ: ë¶€ì±„ë¹„ìœ¨ì´ ë†’ê³  ìˆ˜ìµì„±ì´ ë‚®ì€ ê¸°ì—…ì„ ìœ„í—˜ê¸°ì—…ìœ¼ë¡œ ë¶„ë¥˜)
            self._create_risk_classification()
        else:
            print("  âœ… 'default' ì»¬ëŸ¼ ë°œê²¬")
            
        # ë¶€ì‹¤/ì •ìƒ ê¸°ì—… í†µê³„
        total_count = len(self.df)
        default_count = (self.df['default'] == 1).sum()
        normal_count = total_count - default_count
        
        print(f"  ğŸ“Š ë°ì´í„° êµ¬ì„±:")
        print(f"     - ì „ì²´: {total_count:,}ê°œ ê´€ì¸¡ì¹˜")
        print(f"     - ë¶€ì‹¤ê¸°ì—…: {default_count:,}ê°œ ({default_count/total_count*100:.1f}%)")
        print(f"     - ì •ìƒê¸°ì—…: {normal_count:,}ê°œ ({normal_count/total_count*100:.1f}%)")
        
        # ë¶€ì‹¤ê¸°ì—… ë°ì´í„° ì¶©ë¶„ì„± ê²€ì¦
        if default_count == 0:
            print("  âš ï¸ ë¶€ì‹¤ê¸°ì—… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤! ë¶€ì‹¤/ì •ìƒ ë¹„êµ ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
            print("  ğŸ’¡ ì „ì²´ê¸°ì—… ëŒ€ìƒìœ¼ë¡œë§Œ ë°±í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.")
        elif default_count < 50:
            print(f"  âš ï¸ ë¶€ì‹¤ê¸°ì—… ìˆ˜ê°€ ì ìŠµë‹ˆë‹¤ ({default_count}ê°œ). í†µê³„ì  ìœ ì˜ì„±ì´ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        # ì—°ë„ë³„ ë¶€ì‹¤ê¸°ì—… ë¶„í¬ í™•ì¸
        yearly_defaults = self.df[self.df['default'] == 1].groupby('ì—°ë„').size()
        if len(yearly_defaults) > 0:
            print(f"  ğŸ“… ì—°ë„ë³„ ë¶€ì‹¤ê¸°ì—… ë¶„í¬:")
            for year, count in yearly_defaults.items():
                print(f"     - {year}ë…„: {count}ê°œ")
        
        # íŒ©í„° ì‹œê·¸ë„ ê³„ì‚°
        print("  ğŸ”„ íŒ©í„° ì‹œê·¸ë„ ê³„ì‚° ì‹œì‘...")
        
        # 1. Magic Formula (ê·¸ë¦°ë¸”ë¼íŠ¸)
        self._compute_magic_formula()
        
        # 2. EV/EBITDA
        self._compute_ev_ebitda()
        
        # 3. Momentum (customizable period)
        self._compute_momentum()
        
        # 4. Piotroski F-Score
        self._compute_fscore()
        
        # 5. QMJ (Quality Minus Junk)
        self._compute_qmj()
        
        # 6. Low Volatility
        self._compute_low_volatility()
        
        # 7. BM ê³„ì‚° (FF3ì—ì„œ ì‚¬ìš©)
        self._compute_book_to_market()
        
        # 8. Fama-French 3Factor (í†µí•© ì „ëµ)
        self._compute_ff3_factors()
        
        print("  âœ… íŒ©í„° ì‹œê·¸ë„ ê³„ì‚° ì™„ë£Œ")
        
        return self
        
    def _create_risk_classification(self):
        """default ì»¬ëŸ¼ì´ ì—†ì„ ë•Œ ì¬ë¬´ë¹„ìœ¨ ê¸°ë°˜ìœ¼ë¡œ ìœ„í—˜ê¸°ì—… ë¶„ë¥˜"""
        print("  ğŸ”„ ì¬ë¬´ë¹„ìœ¨ ê¸°ë°˜ ìœ„í—˜ê¸°ì—… ë¶„ë¥˜ ì¤‘...")
        
        # ìœ„í—˜ ì§€í‘œë“¤ í™•ì¸
        risk_indicators = []
        
        # 1. ë¶€ì±„ë¹„ìœ¨
        if 'ë¶€ì±„ë¹„ìœ¨' in self.df.columns:
            risk_indicators.append('ë¶€ì±„ë¹„ìœ¨')
        
        # 2. ìˆ˜ìµì„± ì§€í‘œ
        profitability_cols = ['ROE', 'ìê¸°ìë³¸ìˆœì´ìµë¥ ', 'ROA', 'ì´ìì‚°ìˆ˜ìµë¥ ', 'ì˜ì—…ì´ìµë¥ ']
        available_profit_col = None
        for col in profitability_cols:
            if col in self.df.columns:
                available_profit_col = col
                break
        
        if available_profit_col:
            risk_indicators.append(available_profit_col)
        
        # 3. ìœ ë™ì„± ì§€í‘œ
        if 'ìœ ë™ë¹„ìœ¨' in self.df.columns:
            risk_indicators.append('ìœ ë™ë¹„ìœ¨')
        elif 'ìœ ë™ìì‚°' in self.df.columns and 'ìœ ë™ë¶€ì±„' in self.df.columns:
            # ìœ ë™ë¹„ìœ¨ ê³„ì‚°
            liabilities = pd.to_numeric(self.df['ìœ ë™ë¶€ì±„'], errors='coerce').replace(0, np.nan)
            self.df['ìœ ë™ë¹„ìœ¨'] = pd.to_numeric(self.df['ìœ ë™ìì‚°'], errors='coerce') / liabilities
            risk_indicators.append('ìœ ë™ë¹„ìœ¨')
        
        if len(risk_indicators) == 0:
            print("    âŒ ìœ„í—˜ë¶„ë¥˜ë¥¼ ìœ„í•œ ì¬ë¬´ì§€í‘œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ëª¨ë“  ê¸°ì—…ì„ ì •ìƒìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
            self.df['default'] = 0
            return
        
        print(f"    ğŸ“Š ì‚¬ìš© ì§€í‘œ: {risk_indicators}")
        
        # ì—°ë„ë³„ë¡œ ìœ„í—˜ê¸°ì—… ë¶„ë¥˜ (ìƒìœ„/í•˜ìœ„ 20%ë¡œ ë¶„ë¥˜)
        self.df['default'] = 0  # ê¸°ë³¸ê°’
        
        for year in self.df['ì—°ë„'].unique():
            year_mask = self.df['ì—°ë„'] == year
            year_data = self.df[year_mask].copy()
            
            if len(year_data) < 20:  # ìµœì†Œ 20ê°œ ê¸°ì—… í•„ìš”
                continue
            
            risk_score = 0
            valid_indicators = 0
            
            # ë¶€ì±„ë¹„ìœ¨ (ë†’ì„ìˆ˜ë¡ ìœ„í—˜)
            if 'ë¶€ì±„ë¹„ìœ¨' in risk_indicators:
                debt_ratio = pd.to_numeric(year_data['ë¶€ì±„ë¹„ìœ¨'], errors='coerce')
                if debt_ratio.notna().sum() > 5:
                    debt_percentile = debt_ratio.rank(pct=True)
                    risk_score += debt_percentile
                    valid_indicators += 1
            
            # ìˆ˜ìµì„± (ë‚®ì„ìˆ˜ë¡ ìœ„í—˜)
            if available_profit_col in risk_indicators:
                profit_ratio = pd.to_numeric(year_data[available_profit_col], errors='coerce')
                if profit_ratio.notna().sum() > 5:
                    profit_percentile = profit_ratio.rank(pct=True, ascending=False)  # ë‚®ì„ìˆ˜ë¡ ë†’ì€ ìˆœìœ„
                    risk_score += profit_percentile
                    valid_indicators += 1
            
            # ìœ ë™ë¹„ìœ¨ (ë‚®ì„ìˆ˜ë¡ ìœ„í—˜)
            if 'ìœ ë™ë¹„ìœ¨' in risk_indicators:
                liquid_ratio = pd.to_numeric(year_data['ìœ ë™ë¹„ìœ¨'], errors='coerce')
                if liquid_ratio.notna().sum() > 5:
                    liquid_percentile = liquid_ratio.rank(pct=True, ascending=False)  # ë‚®ì„ìˆ˜ë¡ ë†’ì€ ìˆœìœ„
                    risk_score += liquid_percentile
                    valid_indicators += 1
            
            if valid_indicators > 0:
                risk_score = risk_score / valid_indicators
                # ìƒìœ„ 20%ë¥¼ ìœ„í—˜ê¸°ì—…ìœ¼ë¡œ ë¶„ë¥˜
                risk_threshold = risk_score.quantile(0.8)
                high_risk_mask = risk_score >= risk_threshold
                self.df.loc[year_mask & high_risk_mask, 'default'] = 1
        
        final_default_count = (self.df['default'] == 1).sum()
        print(f"    âœ… ì¬ë¬´ë¹„ìœ¨ ê¸°ë°˜ ë¶„ë¥˜ ì™„ë£Œ: {final_default_count}ê°œ ê¸°ì—…ì„ ìœ„í—˜ê¸°ì—…ìœ¼ë¡œ ë¶„ë¥˜")
    
    def _compute_magic_formula(self):
        """Magic Formula (ê·¸ë¦°ë¸”ë¼íŠ¸)"""
        # Earnings Yield = EBIT / EV
        if 'EBIT' in self.df.columns and 'EV' in self.df.columns:
            self.df['earnings_yield'] = self.df['EBIT'] / self.df['EV']
        elif 'ì˜ì—…ì´ìµ' in self.df.columns and 'ì‹œê°€ì´ì•¡' in self.df.columns:
            # EV = ì‹œê°€ì´ì•¡ + ì´ë¶€ì±„ - (í˜„ê¸ˆ + ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ)
            cash_equiv = self.df.get('í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°', 0) + self.df.get('ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ(ê¸ˆìœµê¸°ê´€ì˜ˆì¹˜ê¸ˆ)', 0)
            ev = self.df['ì‹œê°€ì´ì•¡'] + self.df.get('ì´ë¶€ì±„', 0) - cash_equiv
            ev = ev.replace(0, np.nan)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
            self.df['earnings_yield'] = self.df['ì˜ì—…ì´ìµ'] / ev
        else:
            self.df['earnings_yield'] = np.nan
        
        # ROIC = EBIT / (ìˆœìš´ì „ìë³¸ + ìˆœìœ í˜•ìì‚°)
        if 'ê²½ì˜ìë³¸ì˜ì—…ì´ìµë¥ ' in self.df.columns:
            self.df['roic'] = pd.to_numeric(self.df['ê²½ì˜ìë³¸ì˜ì—…ì´ìµë¥ '], errors='coerce') / 100
        elif 'EBIT' in self.df.columns and 'ìˆœìš´ì „ìë³¸' in self.df.columns and 'ìˆœìœ í˜•ìì‚°' in self.df.columns:
            invested_capital = self.df['ìˆœìš´ì „ìë³¸'] + self.df['ìˆœìœ í˜•ìì‚°']
            invested_capital = invested_capital.replace(0, np.nan)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
            self.df['roic'] = self.df['EBIT'] / invested_capital
        elif 'ì˜ì—…ì´ìµ' in self.df.columns and 'ì´ìì‚°' in self.df.columns:
            # ëŒ€ì•ˆ: ROA ê¸°ë°˜ ROIC ê·¼ì‚¬ê°’ ì‚¬ìš©
            total_assets = pd.to_numeric(self.df['ì´ìì‚°'], errors='coerce')
            total_assets = total_assets.replace(0, np.nan)
            self.df['roic'] = pd.to_numeric(self.df['ì˜ì—…ì´ìµ'], errors='coerce') / total_assets
        else:
            self.df['roic'] = np.nan
        
        # ì—°ë„ë³„ ë­í‚¹ ê³„ì‚°
        magic_scores = []
        for year in self.df['ì—°ë„'].unique():
            year_df = self.df[self.df['ì—°ë„'] == year].copy()
            
            if len(year_df) < 10:
                continue
            
            valid_mask = year_df['earnings_yield'].notna() & year_df['roic'].notna()
            valid_df = year_df[valid_mask].copy()
            
            if len(valid_df) < 5:
                continue
            
            # ë­í‚¹ ê³„ì‚° (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            valid_df['ey_rank'] = valid_df['earnings_yield'].rank(ascending=False)
            valid_df['roic_rank'] = valid_df['roic'].rank(ascending=False)
            
            # Magic Formula Rank = ë‘ ë­í‚¹ì˜ í•© (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            valid_df['MF_Rank'] = valid_df['ey_rank'] + valid_df['roic_rank']
            valid_df['magic_signal'] = -valid_df['MF_Rank']  # ë‚®ì€ ë­í¬ê°€ ì¢‹ìŒ â†’ ìŒìˆ˜ ë¶€í˜¸
            
            magic_scores.append(valid_df[['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„', 'magic_signal']])
        
        if magic_scores:
            magic_df = pd.concat(magic_scores)
            self.df = self.df.merge(magic_df, on=['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„'], how='left')
        else:
            self.df['magic_signal'] = 0
    
    def _compute_ev_ebitda(self):
        """EV/EBITDA"""
        # EV = ì‹œê°€ì´ì•¡ + ì´ë¶€ì±„ - (í˜„ê¸ˆ + ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ)
        cash_equiv = self.df.get('í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°', 0) + self.df.get('ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ(ê¸ˆìœµê¸°ê´€ì˜ˆì¹˜ê¸ˆ)', 0)
        ev = self.df['ì‹œê°€ì´ì•¡'] + self.df.get('ì´ë¶€ì±„', 0) - cash_equiv
        
        # EBITDA = EBIT + ê°ê°€ìƒê°ë¹„ + ë¬´í˜•ìì‚°ìƒê°ë¹„
        if 'EBIT' in self.df.columns:
            ebit = self.df['EBIT']
        else:
            ebit = self.df.get('ì˜ì—…ì´ìµ', 0)
        
        ebitda = ebit + self.df.get('ê°ê°€ìƒê°ë¹„', 0) + self.df.get('ë¬´í˜•ìì‚°ìƒê°ë¹„', 0)
        
        self.df['EV_EBITDA'] = ev / ebitda
        self.df['ev_ebitda_signal'] = -self.df['EV_EBITDA']  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
    
    def _compute_book_to_market(self):
        """Book-to-Market (BM) - FF3ì—ì„œë§Œ ì‚¬ìš©"""
        self.df['bm'] = self.df['ì´ìë³¸'] / self.df['ì‹œê°€ì´ì•¡']  # ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
    
    def _compute_momentum(self):
        """Momentum (customizable period) - ê°œì„ ëœ ë²„ì „ with ì‹¤ì œ ì¼ë³„ ë°ì´í„°"""
        print(f"  ğŸ”„ ëª¨ë©˜í…€ ê³„ì‚° ({self.momentum_period}ê°œì›” ê¸°ê°„)")
        
        # ì‹¤ì œ ì¼ë³„ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ì—¬ ì •í™•í•œ ëª¨ë©˜í…€ ê³„ì‚°
        try:
            momentum_data = self._load_daily_momentum_data()
            if momentum_data is not None and len(momentum_data) > 0:
                print(f"    ğŸ“Š ì‹¤ì œ ì¼ë³„ ë°ì´í„° ê¸°ë°˜ {self.momentum_period}ê°œì›” ëª¨ë©˜í…€ ê³„ì‚°")
                self._compute_daily_momentum(momentum_data)
                return
        except Exception as e:
            print(f"    âš ï¸ ì¼ë³„ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        
        # Fallback: ì—°ê°„ ë°ì´í„° ê¸°ë°˜ ê·¼ì‚¬ ëª¨ë©˜í…€ ê³„ì‚°
        print(f"    ğŸ“Š ì—°ê°„ ë°ì´í„° ê¸°ë°˜ ëª¨ë©˜í…€ ê³„ì‚°")
        
        # ëª¨ë©˜í…€ ê¸°ê°„ì„ ì—°ë„ ë‹¨ìœ„ë¡œ ë³€í™˜ (ë” ì •í™•í•œ ë¡œì§)
        if self.momentum_period <= 6:
            # 6ê°œì›” ì´í•˜: ë‹¹ë…„ë„ vs ì „ë…„ë„
            shift_periods = 1
            period_desc = f"{self.momentum_period}ê°œì›”(1ë…„ì „ ëŒ€ë¹„)"
        elif self.momentum_period <= 18:
            # 6-18ê°œì›”: 1ë…„ ì „ ëŒ€ë¹„
            shift_periods = 1
            period_desc = f"{self.momentum_period}ê°œì›”(1ë…„ì „ ëŒ€ë¹„)"
        elif self.momentum_period <= 30:
            # 18-30ê°œì›”: 2ë…„ ì „ ëŒ€ë¹„
            shift_periods = 2
            period_desc = f"{self.momentum_period}ê°œì›”(2ë…„ì „ ëŒ€ë¹„)"
        else:
            # 30ê°œì›” ì´ìƒ: í•´ë‹¹ ì—°ë„ ìˆ˜ë§Œí¼ ê³¼ê±°
            shift_periods = max(2, self.momentum_period // 12)
            period_desc = f"{self.momentum_period}ê°œì›”({shift_periods}ë…„ì „ ëŒ€ë¹„)"
        
        print(f"    ğŸ“Š ì‹¤ì œ ì ìš©: {period_desc}")
        
            # ì¢…ê°€ ê¸°ë°˜ ìˆ˜ìµë¥  ê³„ì‚°
        price_col = None
        for col in ['ì¢…ê°€', 'ì‹œê°€ì´ì•¡', 'market_cap']:
            if col in self.df.columns:
                price_col = col
                break
        
        if price_col is None:
            print("    âŒ ê°€ê²© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.df['mom'] = 0
            return
        
        # ê³¼ê±° ëŒ€ë¹„ ìˆ˜ìµë¥  ê³„ì‚°
        self.df = self.df.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„'])
        price_lag = self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')[price_col].shift(shift_periods)
        self.df['mom'] = (self.df[price_col] / price_lag - 1)
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        self.df['mom'] = self.df['mom'].fillna(0)
        
        # í†µê³„ ì¶œë ¥
        valid_momentum = self.df['mom'].dropna()
        if len(valid_momentum) > 0:
            print(f"    ğŸ“ˆ ëª¨ë©˜í…€ í†µê³„: í‰ê·  {valid_momentum.mean():.4f}, "
                  f"ì¤‘ì•™ê°’ {valid_momentum.median():.4f}, "
                  f"í‘œì¤€í¸ì°¨ {valid_momentum.std():.4f}")
        else:
            print("    âš ï¸ ìœ íš¨í•œ ëª¨ë©˜í…€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def _load_daily_momentum_data(self):
        """ì‹¤ì œ ì¼ë³„ ì£¼ê°€ ë°ì´í„° ë¡œë”© (ëª¨ë©˜í…€ ê³„ì‚°ìš©)"""
        try:
            # ì—°ë„ë³„ ì£¼ê°€ íŒŒì¼ë“¤ ì°¾ê¸°
            price_files = []
            for data_dir in ['data/raw', 'data', '.']:
                pattern = os.path.join(data_dir, '20*.csv')
                found_files = sorted(glob.glob(pattern))
                if found_files:
                    price_files = found_files
                    break
            
            if not price_files:
                return None
            
            # í•„ìš”í•œ ì—°ë„ë§Œ ë¡œë”© (ì„±ëŠ¥ ìµœì í™”)
            df_list = []
            for file_path in price_files:
                try:
                    df_temp = pd.read_csv(file_path, encoding='utf-8-sig')
                    
                    # ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ê²Œ ë§¤í•‘
                    column_mapping = {
                        'date_cols': ['ë§¤ë§¤ë…„ì›”ì¼', 'ë‚ ì§œ', 'date', 'Date'],
                        'price_cols': ['ì¢…ê°€(ì›)', 'ì¢…ê°€', 'close', 'Close'],
                        'code_cols': ['ê±°ë˜ì†Œì½”ë“œ', 'code', 'ticker']
                    }
                    
                    # í•„ìš”í•œ ì»¬ëŸ¼ ì°¾ê¸°
                    date_col = None
                    price_col = None
                    code_col = None
                    
                    for col in column_mapping['date_cols']:
                        if col in df_temp.columns:
                            date_col = col
                            break
                    
                    for col in column_mapping['price_cols']:
                        if col in df_temp.columns:
                            price_col = col
                            break
                    
                    for col in column_mapping['code_cols']:
                        if col in df_temp.columns:
                            code_col = col
                            break
                    
                    if date_col and price_col and code_col:
                        df_selected = df_temp[[code_col, date_col, price_col]].copy()
                        
                        # ì»¬ëŸ¼ëª… í‘œì¤€í™”
                        df_selected.columns = ['ê±°ë˜ì†Œì½”ë“œ', 'date_str', 'ì¢…ê°€']
                        
                        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬ (ë§¤ë§¤ë…„ì›”ì¼ì€ 2012/01/02 í˜•íƒœ)
                        df_selected['date'] = pd.to_datetime(df_selected['date_str'], errors='coerce')
                        
                        # ì¢…ê°€ ì»¬ëŸ¼ ìˆ«ì ë³€í™˜
                        df_selected['ì¢…ê°€'] = pd.to_numeric(df_selected['ì¢…ê°€'], errors='coerce')
                        
                        # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì„ íƒ
                        df_selected = df_selected.dropna(subset=['date', 'ì¢…ê°€'])
                        df_selected = df_selected[df_selected['ì¢…ê°€'] > 0]  # 0 ì´í•˜ ê°€ê²© ì œì™¸
                        
                        if len(df_selected) > 0:
                            df_list.append(df_selected[['ê±°ë˜ì†Œì½”ë“œ', 'date', 'ì¢…ê°€']])
                            
                except Exception as e:
                    print(f"    âš ï¸ {file_path} ë¡œë”© ì‹¤íŒ¨: {e}")
                    continue
            
            if df_list:
                daily_data = pd.concat(df_list, ignore_index=True)
                daily_data = daily_data.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'date']).reset_index(drop=True)
                print(f"    âœ… ì¼ë³„ ë°ì´í„° ë¡œë”© ì„±ê³µ: {len(daily_data):,}í–‰")
                return daily_data
            else:
                return None
                
        except Exception as e:
            print(f"    âŒ ì¼ë³„ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def _compute_daily_momentum(self, daily_data):
        """ì¼ë³„ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì •í™•í•œ ëª¨ë©˜í…€ ê³„ì‚°"""
        try:
            # ì—°ë„ë³„ ëª¨ë©˜í…€ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
            momentum_results = {}
            
            for year in self.df['ì—°ë„'].unique():
                if pd.isna(year):
                    continue
                    
                year = int(year)
                
                # í•´ë‹¹ ì—°ë„ 3ì›” ë§ ê¸°ì¤€ì¼ (íšŒê³„ë…„ë„ ê¸°ì¤€)
                current_date = pd.Timestamp(f"{year}-03-31")
                # Nê°œì›” ì „ ê¸°ì¤€ì¼
                past_date = current_date - pd.DateOffset(months=self.momentum_period)
                
                # ê° ì¢…ëª©ë³„ ëª¨ë©˜í…€ ê³„ì‚°
                year_momentum = {}
                
                for code in self.df[self.df['ì—°ë„'] == year]['ê±°ë˜ì†Œì½”ë“œ'].unique():
                    try:
                        stock_data = daily_data[daily_data['ê±°ë˜ì†Œì½”ë“œ'] == code].copy()
                        
                        if len(stock_data) < 2:
                            continue
                        
                        # í˜„ì¬ ì‹œì  ê°€ê²© (ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œ)
                        current_prices = stock_data[stock_data['date'] <= current_date]
                        if len(current_prices) == 0:
                            continue
                        current_price = current_prices.iloc[-1]['ì¢…ê°€']
                        
                        # ê³¼ê±° ì‹œì  ê°€ê²© (Nê°œì›” ì „ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œ)
                        past_prices = stock_data[stock_data['date'] <= past_date]
                        if len(past_prices) == 0:
                            continue
                        past_price = past_prices.iloc[-1]['ì¢…ê°€']
                        
                        # ëª¨ë©˜í…€ ê³„ì‚° (ìˆ˜ìµë¥ )
                        if past_price > 0:
                            momentum = (current_price / past_price) - 1
                            year_momentum[code] = momentum
                            
                    except Exception as e:
                        continue
                
                momentum_results[year] = year_momentum
                
            # ê²°ê³¼ë¥¼ ì›ë³¸ DataFrameì— ë³‘í•©
            self.df['mom'] = 0.0
            
            for _, row in self.df.iterrows():
                year = row['ì—°ë„']
                code = row['ê±°ë˜ì†Œì½”ë“œ']
                
                if year in momentum_results and code in momentum_results[year]:
                    self.df.loc[self.df.index == row.name, 'mom'] = momentum_results[year][code]
            
            # í†µê³„ ì¶œë ¥
            valid_momentum = self.df[self.df['mom'] != 0]['mom']
            if len(valid_momentum) > 0:
                print(f"    ğŸ“ˆ ì¼ë³„ ëª¨ë©˜í…€ í†µê³„: í‰ê·  {valid_momentum.mean():.4f}, "
                      f"ì¤‘ì•™ê°’ {valid_momentum.median():.4f}, "
                      f"í‘œì¤€í¸ì°¨ {valid_momentum.std():.4f}")
                print(f"    ğŸ“Š ìœ íš¨í•œ ëª¨ë©˜í…€ ê³„ì‚°: {len(valid_momentum):,}ê°œ ({len(valid_momentum)/len(self.df)*100:.1f}%)")
            else:
                print("    âš ï¸ ìœ íš¨í•œ ì¼ë³„ ëª¨ë©˜í…€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"    âŒ ì¼ë³„ ëª¨ë©˜í…€ ê³„ì‚° ì‹¤íŒ¨: {e}")
            # Fallback to 0
            self.df['mom'] = 0
    
    def _compute_fscore(self):
        """Piotroski F-Score (0~9ì )"""
        # 1. ROA > 0
        if 'ROA' in self.df.columns:
            roa_col = 'ROA'
        elif 'ì´ìì‚°ìˆ˜ìµë¥ ' in self.df.columns:
            roa_col = 'ì´ìì‚°ìˆ˜ìµë¥ '
        else:
            # ROA ì§ì ‘ ê³„ì‚°: ë‹¹ê¸°ìˆœì´ìµ / ì´ìì‚°
            if 'ë‹¹ê¸°ìˆœì´ìµ' in self.df.columns and 'ì´ìì‚°' in self.df.columns:
                total_assets = pd.to_numeric(self.df['ì´ìì‚°'], errors='coerce').replace(0, np.nan)
                self.df['ROA'] = pd.to_numeric(self.df['ë‹¹ê¸°ìˆœì´ìµ'], errors='coerce') / total_assets
                roa_col = 'ROA'
            else:
                self.df['f_roa'] = 0
                roa_col = None
        
        if roa_col:
            self.df['f_roa'] = (pd.to_numeric(self.df[roa_col], errors='coerce') > 0).astype(int)
        
        # 2. CFO > 0
        cfo_col = 'ì˜ì—…í˜„ê¸ˆíë¦„' if 'ì˜ì—…í˜„ê¸ˆíë¦„' in self.df.columns else 'ì˜ì—…CF'
        if cfo_col in self.df.columns:
            self.df['f_cfo'] = (self.df[cfo_col] > 0).astype(int)
        else:
            self.df['f_cfo'] = 0
        
        # 3. Î”ROA
        if roa_col:
            self.df['f_delta_roa'] = (self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')[roa_col].diff() > 0).astype(int)
        else:
            self.df['f_delta_roa'] = 0
        
        # 4. CFO > ROA
        if cfo_col in self.df.columns and roa_col:
            total_assets = self.df.get('avg_ì´ìì‚°', self.df.get('ì´ìì‚°', 1))
            total_assets = pd.to_numeric(total_assets, errors='coerce').replace(0, np.nan)
            cfo_ta = pd.to_numeric(self.df[cfo_col], errors='coerce') / total_assets
            roa_ratio = pd.to_numeric(self.df[roa_col], errors='coerce')
            # ROAê°€ ì´ë¯¸ ë¹„ìœ¨ì´ë©´ ê·¸ëŒ€ë¡œ, í¼ì„¼íŠ¸ë©´ 100ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
            if roa_ratio.max() > 1:  # í¼ì„¼íŠ¸ë¡œ ì¶”ì •
                roa_ratio = roa_ratio / 100
            self.df['f_cfo_roa'] = (cfo_ta > roa_ratio).astype(int)
        else:
            self.df['f_cfo_roa'] = 0
        
        # 5. Î”ë¶€ì±„
        self.df['f_debt'] = (self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì´ë¶€ì±„'].diff() < 0).astype(int)
        
        # 6. Î”ìœ ë™ë¹„ìœ¨
        if 'ìœ ë™ë¹„ìœ¨' in self.df.columns:
            self.df['f_liquid'] = (self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ìœ ë™ë¹„ìœ¨'].diff() > 0).astype(int)
        elif 'ìœ ë™ìì‚°' in self.df.columns and 'ìœ ë™ë¶€ì±„' in self.df.columns:
            # ìœ ë™ë¹„ìœ¨ = ìœ ë™ìì‚° / ìœ ë™ë¶€ì±„
            liabilities = pd.to_numeric(self.df['ìœ ë™ë¶€ì±„'], errors='coerce').replace(0, np.nan)
            current_ratio = pd.to_numeric(self.df['ìœ ë™ìì‚°'], errors='coerce') / liabilities
            self.df['f_liquid'] = (current_ratio.groupby(self.df['ê±°ë˜ì†Œì½”ë“œ']).diff() > 0).astype(int)
        else:
            # ìœ ë™ìì‚°ì´ ì—†ìœ¼ë©´ í˜„ê¸ˆ+ì¬ê³ ìì‚°ìœ¼ë¡œ ê·¼ì‚¬
            if 'í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°' in self.df.columns and 'ì¬ê³ ìì‚°' in self.df.columns and 'ìœ ë™ë¶€ì±„' in self.df.columns:
                liquid_assets = (pd.to_numeric(self.df['í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°'], errors='coerce').fillna(0) + 
                               pd.to_numeric(self.df['ì¬ê³ ìì‚°'], errors='coerce').fillna(0))
                liabilities = pd.to_numeric(self.df['ìœ ë™ë¶€ì±„'], errors='coerce').replace(0, np.nan)
                approx_ratio = liquid_assets / liabilities
                self.df['f_liquid'] = (approx_ratio.groupby(self.df['ê±°ë˜ì†Œì½”ë“œ']).diff() > 0).astype(int)
            else:
                self.df['f_liquid'] = 0
        
        # 7. ì‹ ì£¼ë°œí–‰ (ë‚©ì…ìë³¸ê¸ˆ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨, ì²« ì—°ë„ëŠ” ì‹ ì£¼ë°œí–‰ìœ¼ë¡œ ê°„ì£¼)
        if 'ìë³¸ê¸ˆ' in self.df.columns:
            capital_change = self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ìë³¸ê¸ˆ'].diff()
            # ì²« ì—°ë„(diffê°€ NaNì¸ ê²½ìš°)ëŠ” ì‹ ì£¼ë°œí–‰ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ 0ì  ë¶€ì—¬
            # ë‚©ì…ìë³¸ê¸ˆì´ ì¦ê°€í•˜ì§€ ì•Šì€ ê²½ìš°(ê°ì†Œí•˜ê±°ë‚˜ ë³€í™”ì—†ìŒ)ì— 1ì  ë¶€ì—¬
            self.df['f_shares'] = ((capital_change <= 0) & (~capital_change.isna())).astype(int)
        else:
            self.df['f_shares'] = 0
        
        # 8. Î”ë§ˆì§„
        if 'ë§¤ì¶œì´ì´ìµë¥ ' in self.df.columns:
            self.df['f_margin'] = (self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ë§¤ì¶œì´ì´ìµë¥ '].diff() > 0).astype(int)
        else:
            self.df['f_margin'] = 0
        
        # 9. Î”íšŒì „ìœ¨
        if 'ì´ìì‚°íšŒì „ìœ¨' in self.df.columns:
            self.df['f_turnover'] = (self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì´ìì‚°íšŒì „ìœ¨'].diff() > 0).astype(int)
        else:
            self.df['f_turnover'] = 0
        
        # F-Score í•©ê³„
        fscore_cols = ['f_roa', 'f_cfo', 'f_delta_roa', 'f_cfo_roa', 'f_debt', 
                       'f_liquid', 'f_shares', 'f_margin', 'f_turnover']
        available_cols = [col for col in fscore_cols if col in self.df.columns]
        self.df['fscore'] = self.df[available_cols].sum(axis=1)
    
    def _compute_qmj(self):
        """QMJ (Quality Minus Junk)"""
        # ìˆ˜ìµì„± ì§€í‘œë“¤
        profit_cols = ['ROE', 'ìê¸°ìë³¸ìˆœì´ìµë¥ ', 'ROA', 'ì´ìì‚°ìˆ˜ìµë¥ ']
        available_profit_cols = [col for col in profit_cols if col in self.df.columns]
        
        # ì•ˆì •ì„± ì§€í‘œë“¤ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        safety_cols = ['ë¶€ì±„ë¹„ìœ¨', 'ë¶€ì±„ìë³¸ë¹„ìœ¨']
        available_safety_cols = [col for col in safety_cols if col in self.df.columns]
        
        # ì„±ì¥ì„± ì§€í‘œë“¤
        growth_cols = ['ë§¤ì¶œì•¡ì¦ê°€ìœ¨', 'ì˜ì—…ì´ìµì¦ê°€ìœ¨']
        available_growth_cols = [col for col in growth_cols if col in self.df.columns]
        
        # ì—°ë„ë³„ Z-score í‘œì¤€í™”
        qmj_scores = []
        for year in self.df['ì—°ë„'].unique():
            year_df = self.df[self.df['ì—°ë„'] == year].copy()
            
            if len(year_df) < 10:
                continue
            
            # ìˆ˜ìµì„± ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            profit_z = 0
            for col in available_profit_cols:
                if year_df[col].notna().sum() > 5:
                    profit_z += stats.zscore(year_df[col].fillna(year_df[col].median()))
            
            # ì•ˆì •ì„± ì ìˆ˜ (ë¶€ì±„ë¹„ìœ¨ ë“±ì€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            safety_z = 0
            for col in available_safety_cols:
                if year_df[col].notna().sum() > 5:
                    safety_z -= stats.zscore(year_df[col].fillna(year_df[col].median()))
            
            # ì„±ì¥ì„± ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
            growth_z = 0
            for col in available_growth_cols:
                if year_df[col].notna().sum() > 5:
                    growth_z += stats.zscore(year_df[col].fillna(year_df[col].median()))
            
            year_df['qmj'] = (profit_z + safety_z + growth_z) / 3
            qmj_scores.append(year_df[['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„', 'qmj']])
        
        if qmj_scores:
            qmj_df = pd.concat(qmj_scores)
            self.df = self.df.merge(qmj_df, on=['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„'], how='left')
        else:
            self.df['qmj'] = 0
    
    def _compute_low_volatility(self):
        """Low Volatility"""
        # ê³¼ê±° 3ë…„ê°„ ìˆ˜ìµë¥  ë³€ë™ì„± ê³„ì‚°
        if 'ì£¼ê°€ìˆ˜ìµë¥ ' in self.df.columns:
            ret_col = 'ì£¼ê°€ìˆ˜ìµë¥ '
        else:
            # ì¢…ê°€ ê¸°ë°˜ ìˆ˜ìµë¥  ê³„ì‚°
            price_col = 'ì¢…ê°€' if 'ì¢…ê°€' in self.df.columns else 'ì‹œê°€ì´ì•¡'
            self.df['returns'] = self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')[price_col].pct_change()
            ret_col = 'returns'
        
        # 36ê°œì›”(3ë…„) ë³€ë™ì„± ê³„ì‚° (ì—°ê°„ ë°ì´í„°ì´ë¯€ë¡œ 3ë…„)
        self.df['vol_3y'] = self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')[ret_col].rolling(3).std().reset_index(0, drop=True)
        self.df['lowvol'] = -self.df['vol_3y']  # ë³€ë™ì„± ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


    def _build_market_factor(self, start="20000103"):
        """
        â–MKT_RF (ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„) ì›”Â·ì—° ì‹œê³„ì—´ ìƒì„±
        â€¢ KOSPI ê°€ê²©ì§€ìˆ˜ ì¢…ê°€ â†’ ì›”ë§ ìˆ˜ìµë¥  (Yahoo Finance ë˜ëŠ” pykrx)
        â€¢ ë¬´ìœ„í—˜ìˆ˜ìµë¥  â†’ ì›”í‰ê·  (í•œêµ­ êµ­ê³ ì±„ 3ê°œì›” ë˜ëŠ” ê³ ì •ê°’)
        â€¢ ì›”ì´ˆê³¼ìˆ˜ìµë¥  â†’ 4/1 ~ ë‹¤ìŒ 3/31 ëˆ„ì  â†’ ì—° MKT_RF
        """
        try:
            import yfinance as yf
            
            # ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ datetime í˜•íƒœë¡œ ë³€í™˜
            start_dt = pd.to_datetime(start, format='%Y%m%d')
            end_dt = pd.Timestamp.today()
            
            print(f"  ğŸ“Š ì‹œì¥ íŒ©í„° ê³„ì‚°: {start_dt.strftime('%Y-%m-%d')} ~ {end_dt.strftime('%Y-%m-%d')}")

            # â”€â”€ 1. KOSPI ë°ì´í„° ê°€ì ¸ì˜¤ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            kospi_success = False
            try:
                # Yahoo Financeë¡œ KOSPI ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (^KS11)
                kospi_data = yf.download('^KS11', start=start_dt, end=end_dt, progress=False)
                if not kospi_data.empty and len(kospi_data) > 0:
                    # Multi-level columns ì²˜ë¦¬
                    if isinstance(kospi_data.columns, pd.MultiIndex):
                        kospi_close = kospi_data['Close'].iloc[:, 0]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì„ íƒ
                    else:
                        kospi_close = kospi_data['Close']
                    
                    # ì›”ë§ ë°ì´í„°ë¡œ ë¦¬ìƒ˜í”Œë§
                    kospi_monthly = kospi_close.resample("M").last()
                    mkt_ret_m = kospi_monthly.pct_change().dropna()
                    kospi_success = True
                    print(f"  âœ… Yahoo Finance KOSPI ë°ì´í„° ì„±ê³µ: {len(mkt_ret_m)}ê°œì›”")
                else:
                    raise ValueError("Yahoo Financeì—ì„œ ë¹ˆ ë°ì´í„° ë°˜í™˜")
                    
            except Exception as e:
                print(f"  âš ï¸ Yahoo Finance KOSPI ì‹¤íŒ¨: {e}")
                
                # pykrx ì‹œë„
                try:
                    kospi = (stock.get_index_ohlcv(start, end_dt.strftime("%Y%m%d"), "1001")["ì¢…ê°€"]
                            .resample("M").last())
                    mkt_ret_m = kospi.pct_change().dropna()
                    kospi_success = True
                    print(f"  âœ… pykrx KOSPI ë°ì´í„° ì„±ê³µ: {len(mkt_ret_m)}ê°œì›”")
                except Exception as e2:
                    print(f"  âš ï¸ pykrx KOSPIë„ ì‹¤íŒ¨: {e2}")

            # KOSPI ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ ì‹œ Mock ë°ì´í„° ìƒì„±
            if not kospi_success:
                print("  ğŸ’¡ Mock KOSPI ë°ì´í„°ë¡œ ëŒ€ì²´")
                date_range = pd.date_range(start=start_dt, end=end_dt, freq='M')
                np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
                # ì—° 8% ìˆ˜ìµë¥ , ì›” ë³€ë™ì„± 4%ë¡œ ê°€ì •í•œ ê°€ìƒ KOSPI ë°ì´í„°
                monthly_returns = np.random.normal(0.08/12, 0.04, len(date_range))
                mkt_ret_m = pd.Series(monthly_returns, index=date_range)

            # â”€â”€ 2. ë¬´ìœ„í—˜ìˆ˜ìµë¥  ë°ì´í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            rf_success = False
            try:
                # pykrxë¡œ CD(91ì¼) ì‹œë„
                cd91 = (bond.get_otc_treasury_yields(start, end_dt.strftime("%Y%m%d"), "CD(91ì¼)")["ìˆ˜ìµë¥ "]
                       .resample("M").mean() / 100)
                if not cd91.empty and len(cd91) > 0:
                    rf_m = cd91.reindex(mkt_ret_m.index).fillna(method="ffill")
                    rf_success = True
                    print(f"  âœ… pykrx CD(91ì¼) ë°ì´í„° ì„±ê³µ: {len(cd91)}ê°œì›”")
                else:
                    raise ValueError("CD(91ì¼) ë¹ˆ ë°ì´í„°")
                    
            except Exception as e:
                print(f"  âš ï¸ CD(91ì¼) ë°ì´í„° ì‹¤íŒ¨: {e}")

            # ë¬´ìœ„í—˜ìˆ˜ìµë¥  ì‹¤íŒ¨ ì‹œ ê³ ì •ê°’ ì‚¬ìš©
            if not rf_success:
                print("  ğŸ’¡ ê³ ì • ë¬´ìœ„í—˜ìˆ˜ìµë¥  ì‚¬ìš© (ì—° 2.5%)")
                # í•œêµ­ì˜ ì—­ì‚¬ì  í‰ê·  ë‹¨ê¸°ê¸ˆë¦¬ ê³ ë ¤ (ì—° 2.5%)
                rf_m = pd.Series(0.025/12, index=mkt_ret_m.index)

            # â”€â”€ 3. ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            mkt_rf_m = (mkt_ret_m - rf_m).dropna()

            # 4/1 ~ ë‹¤ìŒ í•´ 3/31 ëˆ„ì  (PeriodIndex freq='A-APR')
            mkt_rf_y = ((1 + mkt_rf_m).groupby(
                pd.PeriodIndex(mkt_rf_m.index, freq="A-APR")).prod() - 1)
            
            print(f"  âœ… ì—°ê°„ ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„ ê³„ì‚° ì™„ë£Œ: {len(mkt_rf_y)}ë…„")
            return mkt_rf_y.rename("MKT_RF")
            
        except Exception as e:
            print(f"  âŒ ì‹œì¥ íŒ©í„° ê³„ì‚° ì „ì²´ ì‹¤íŒ¨: {e}")
            print("  ğŸ’¡ ì™„ì „ Mock ë°ì´í„°ë¡œ ëŒ€ì²´")
            # ì™„ì „ Mock ë°ì´í„° ìƒì„±
            years = range(2000, pd.Timestamp.today().year + 1)
            periods = [pd.Period(f"{year}-04", freq="A-APR") for year in years]
            np.random.seed(42)
            # í•œêµ­ ì£¼ì‹ì‹œì¥ ì—­ì‚¬ì  í‰ê·  (ì—° 6% ìˆ˜ìµë¥ , 15% ë³€ë™ì„±)
            mock_returns = np.random.normal(0.06, 0.15, len(periods))
            return pd.Series(mock_returns, index=periods, name="MKT_RF")


    def _compute_ff3_factors(self):
        """
        â–ì§„ì§œ Fama-French 3 factor(ì—°Â·APR) ê³„ì‚°
        â€“ SMB, HML : 2Ã—3 í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ìŠ¤í”„ë ˆë“œ(ë™ì¼ê°€ì¤‘)
        â€“ MKT_RF   : _build_market_factor() ê²°ê³¼
        â†’ self.ff_factors  (index = Period['YYYY-APR'])
        """
        try:
            print("  ğŸ”„ FF3 íŒ©í„° ê³„ì‚° ì¤‘...")
            
            # â”€â”€ 1. ì‹œì¥ íŒ©í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            mkt_rf_y = self._build_market_factor()

            # â”€â”€ 2. SMBÂ·HML (ì—° 4/1 ë¦¬ë°¸ëŸ°ìŠ¤) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            factor_rows = []
            rebalance_years = sorted(self.df['ì—°ë„'].unique())

            for yr in rebalance_years:
                snap = self.df[self.df['ì—°ë„'] == yr - 1].copy()   # ì „ë…„ë„ ì¬ë¬´ì •ë³´(3ì›” ë§ ê°€ì •)
                if snap[['ì‹œê°€ì´ì•¡', 'bm']].isna().any(axis=None) or len(snap) < 6:
                    continue

                # â‘  SizeÂ·BM ì»·
                size_median = snap['ì‹œê°€ì´ì•¡'].median()
                bm30, bm70 = snap['bm'].quantile([.3, .7])

                # â‘¡ 6ê°œ í¬íŠ¸ë¼ë²¨
                size_grp = np.where(snap['ì‹œê°€ì´ì•¡'] <= size_median, 'S', 'B')
                bm_grp   = np.where(snap['bm'] <= bm30, 'L',
                                    np.where(snap['bm'] > bm70, 'H', 'M'))
                snap['grp'] = [a+b for a, b in zip(size_grp, bm_grp)]

                # â‘¢ ë‹¤ìŒ 12ê°œì›”(í•´ë‹¹ íšŒê³„ì—°ë„) ìˆ˜ìµë¥  â–¸ R_{g,yr}
                hold_ret = (self.df.loc[self.df['ì—°ë„'] == yr,
                                       ['ê±°ë˜ì†Œì½”ë“œ', 'ì£¼ê°€ìˆ˜ìµë¥ ']]
                           .set_index('ê±°ë˜ì†Œì½”ë“œ')['ì£¼ê°€ìˆ˜ìµë¥ '])
                snap = snap.join(hold_ret, on='ê±°ë˜ì†Œì½”ë“œ').dropna(subset=['ì£¼ê°€ìˆ˜ìµë¥ '])
                if len(snap) < 6:               # í¬íŠ¸ë³„ ìµœì†Œ 1ì¢…ëª© í™•ë³´
                    continue

                port_ret = snap.groupby('grp')['ì£¼ê°€ìˆ˜ìµë¥ '].mean()

                # í•„ìš”í•œ í¬íŠ¸í´ë¦¬ì˜¤ê°€ ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                required_portfolios = ['SL', 'SM', 'SH', 'BL', 'BM', 'BH']
                missing_portfolios = [p for p in required_portfolios if p not in port_ret.index]
                
                if missing_portfolios:
                    print(f"    âš ï¸ {yr}ë…„: í•„ìš”í•œ í¬íŠ¸í´ë¦¬ì˜¤ ëˆ„ë½ {missing_portfolios}, ê±´ë„ˆëœ€")
                    continue

                SMB = port_ret[['SL', 'SM', 'SH']].mean() - port_ret[['BL', 'BM', 'BH']].mean()
                HML = port_ret[['SH', 'BH']].mean() - port_ret[['SL', 'BL']].mean()

                factor_rows.append({'ì—°ë„': yr, 'SMB': SMB, 'HML': HML})

            if factor_rows:
                smb_hml_y = (pd.DataFrame(factor_rows)
                            .set_index(pd.PeriodIndex([r['ì—°ë„'] for r in factor_rows],
                                                     freq="A-APR")))

                # â”€â”€ 3. ì„¸ íŒ©í„° í•©ì¹˜ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                self.ff_factors = pd.concat([mkt_rf_y, smb_hml_y], axis=1).dropna()
                print(f"  âœ… FF3 íŒ©í„° ê³„ì‚° ì™„ë£Œ: {len(self.ff_factors)}ê°œ ì—°ë„")
            else:
                print("  âš ï¸ SMB/HML íŒ©í„° ê³„ì‚° ì‹¤íŒ¨: ìœ íš¨í•œ í¬íŠ¸í´ë¦¬ì˜¤ ì—†ìŒ")
                # Mock FF3 íŒ©í„° ìƒì„±
                years = sorted(self.df['ì—°ë„'].unique())
                periods = [pd.Period(f"{year}-04", freq="A-APR") for year in years]
                np.random.seed(42)
                mock_data = {
                    'MKT_RF': np.random.normal(0.06, 0.15, len(periods)),
                    'SMB': np.random.normal(0.02, 0.10, len(periods)),
                    'HML': np.random.normal(0.03, 0.12, len(periods))
                }
                self.ff_factors = pd.DataFrame(mock_data, index=periods)
                print("  ğŸ’¡ Mock FF3 íŒ©í„°ë¡œ ëŒ€ì²´")
                
        except Exception as e:
            print(f"  âŒ FF3 íŒ©í„° ê³„ì‚° ì‹¤íŒ¨: {e}")
            print("  ğŸ’¡ Mock FF3 íŒ©í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            # ì™„ì „ Mock FF3 íŒ©í„° ìƒì„±
            years = sorted(self.df['ì—°ë„'].unique()) if hasattr(self, 'df') and self.df is not None else range(2013, 2024)
            periods = [pd.Period(f"{year}-04", freq="A-APR") for year in years]
            np.random.seed(42)
            mock_data = {
                'MKT_RF': np.random.normal(0.06, 0.15, len(periods)),
                'SMB': np.random.normal(0.02, 0.10, len(periods)),
                'HML': np.random.normal(0.03, 0.12, len(periods))
            }
            self.ff_factors = pd.DataFrame(mock_data, index=periods)
            
        # FF3 ì‹œê·¸ë„ ìƒì„± (ê°„ë‹¨í•œ ë™ì¼ê°€ì¤‘ ì¡°í•©)
        if hasattr(self, 'ff_factors') and len(self.ff_factors) > 0:
            # ê° ì—°ë„ì˜ FF3 íŒ©í„°ë¥¼ ê¸°ì—… ë°ì´í„°ì™€ ë§¤ì¹­
            ff3_signals = []
            for year in self.df['ì—°ë„'].unique():
                year_period = pd.Period(f"{year}-04", freq="A-APR")
                if year_period in self.ff_factors.index:
                    year_data = self.df[self.df['ì—°ë„'] == year].copy()
                    if len(year_data) > 0:
                        # ê°„ë‹¨í•œ FF3 ì‹œê·¸ë„: SMB + HML (ì‘ì€ê¸°ì—… + ê°€ì¹˜ì£¼ ì„ í˜¸)
                        ff3_score = self.ff_factors.loc[year_period, 'SMB'] + self.ff_factors.loc[year_period, 'HML']
                        year_data['ff3_signal'] = ff3_score
                        ff3_signals.append(year_data[['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„', 'ff3_signal']])
            
            if ff3_signals:
                ff3_df = pd.concat(ff3_signals)
                self.df = self.df.merge(ff3_df, on=['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„'], how='left')
            else:
                self.df['ff3_signal'] = 0
        else:
            self.df['ff3_signal'] = 0


    
    def build_signal(self, factor_cols, weights=None, winsorize_pct=0.005, 
                    sector_map=None, direction_map=None):
        """SIGNAL BUILDER - ë©€í‹°íŒ©í„° ì‹œê·¸ë„ êµ¬ì„±"""
        print(f"Building composite signal from factors: {factor_cols}")
        
        if weights is None:
            weights = {col: 1.0 for col in factor_cols}
        
        if direction_map is None:
            direction_map = {col: 1 for col in factor_cols}  # 1: ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ, -1: ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        
        signals_by_year = []
        
        for year in self.df['ì—°ë„'].unique():
            year_data = self.df[self.df['ì—°ë„'] == year].copy()
            
            if len(year_data) < 20:
                continue
            
            composite_signal = pd.Series(0, index=year_data.index)
            valid_factors = 0
            
            for factor_col in factor_cols:
                if factor_col not in year_data.columns:
                    continue
                
                factor_values = pd.to_numeric(year_data[factor_col], errors='coerce')
                
                if factor_values.notna().sum() < 5:
                    continue
                
                # Winsorization
                lower_bound = factor_values.quantile(winsorize_pct)
                upper_bound = factor_values.quantile(1 - winsorize_pct)
                factor_values = factor_values.clip(lower_bound, upper_bound)
                
                # Z-score standardization
                factor_zscore = (factor_values - factor_values.mean()) / factor_values.std()
                
                # Direction adjustment
                factor_zscore *= direction_map.get(factor_col, 1)
                
                # Weight and add to composite
                weight = weights.get(factor_col, 1.0)
                composite_signal += factor_zscore.fillna(0) * weight
                valid_factors += 1
            
            if valid_factors > 0:
                composite_signal /= valid_factors  # Normalize by number of factors
                
                # Convert to percentile (0~1)
                composite_percentile = composite_signal.rank(pct=True)
                
                # Apply sector adjustment if provided
                if sector_map is not None and 'sector' in year_data.columns:
                    for sector, adjustment in sector_map.items():
                        sector_mask = year_data['sector'] == sector
                        composite_percentile[sector_mask] *= adjustment
                
                # Create MultiIndex Series
                signal_series = pd.Series(
                    composite_percentile.values,
                    index=pd.MultiIndex.from_tuples(
                        [(pd.to_datetime(f'{year}-04-01'), ticker) for ticker in year_data['ê±°ë˜ì†Œì½”ë“œ']],
                        names=['date', 'ticker']
                    )
                )
                signals_by_year.append(signal_series)
        
        if signals_by_year:
            return pd.concat(signals_by_year).sort_index()
        else:
            return pd.Series(dtype=float, name='signal')
    
    def construct_long_portfolio(self, df, signal_col, date, top_n=None, signal_df=None):
        """Long-Only Top-N Equal-Weight í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±"""
        if top_n is None:
            top_n = self.top_n
            
        universe = df[df['rebal_date'] == date].copy()
        
        # íŒ©í„°ë³„ íŠ¹ìˆ˜ í•„í„°ë§ ë¡œì§
        if signal_col == 'fscore':
            # F-Scoreì˜ ê²½ìš°: ìµœì†Œ ì ìˆ˜ ì´ìƒë§Œ ì„ íƒ
            universe = universe[universe['fscore'] >= self.fscore_min_score]
            # F-Scoreì—ì„œëŠ” ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ëª¨ë“  ì¢…ëª©ì„ ì„ íƒ (top_n ì œí•œ ì—†ìŒ)
            if len(universe) == 0:
                return pd.Series(dtype=float)
            winners = universe.sort_values(signal_col, ascending=False)
            n = len(winners)
            print(f"  F-Score {self.fscore_min_score}ì  ì´ìƒ: {n}ê°œ ì¢…ëª© ì„ íƒ (ìš”ì²­: {top_n}ê°œ)")
        else:
            # ë‹¤ë¥¸ íŒ©í„°ë“¤: ìƒìœ„ top_nê°œ ì¢…ëª© ì„ íƒ
            if len(universe) == 0:
                return pd.Series(dtype=float)
            
            # íŒ©í„° ê°’ì´ ë†’ì„ìˆ˜ë¡ ì¢‹ì€ì§€ ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ì§€ íŒë‹¨
            ascending = False
            if signal_col in ['pbr', 'per', 'ev_ebitda', 'debt_to_equity']:
                ascending = True  # ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ íŒ©í„°ë“¤
                
            winners = universe.sort_values(signal_col, ascending=ascending).head(top_n)
            n = len(winners)
        
        if n == 0:
            return pd.Series(dtype=float)
        
        # Equal weight
        return pd.Series(1/n, index=winners.index)
    
    def backtest(self, signal_df=None, price_df=None, top_n=30):
        """BACKTEST LOGIC with signal_df support"""
        if signal_df is not None:
            return self._backtest_with_signal(signal_df, price_df, top_n)
        else:
            return self._backtest_original()
    
    def _backtest_with_signal(self, signal_df, price_df, top_n):
        """Backtest using external signal_df"""
        print("ğŸ“ˆ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ (External Signal)...")
        
        portfolio_returns = []
        rebal_dates = sorted(signal_df.index.get_level_values('date').unique())
        
        for date in rebal_dates:
            # Get signal for this date (use t-1 to prevent look-ahead bias)
            prev_date = date - pd.DateOffset(years=1)
            if prev_date not in signal_df.index.get_level_values('date'):
                continue
                
            date_signals = signal_df.xs(prev_date, level='date').sort_values(ascending=False)
            top_stocks = date_signals.head(top_n)
            
            if len(top_stocks) == 0:
                continue
            
            # Equal weight portfolio
            weights = pd.Series(1/len(top_stocks), index=top_stocks.index)
            
            # Calculate portfolio return (simplified - using price_df if provided)
            if price_df is not None:
                returns = price_df.loc[date, top_stocks.index] if date in price_df.index else 0
                port_ret = (weights * returns).sum() if hasattr(returns, 'sum') else 0
            else:
                port_ret = 0  # Placeholder
            
            portfolio_returns.append({
                'date': date,
                'return': port_ret,
                'n_stocks': len(top_stocks)
            })
        
        if portfolio_returns:
            ret_df = pd.DataFrame(portfolio_returns).set_index('date')
            self.factor_returns['Signal_Strategy'] = ret_df
        
        return self
    
    def _backtest_original(self):
        """4ë‹¨ê³„: ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ - ë¶€ì‹¤ê¸°ì—… vs ì •ìƒê¸°ì—… êµ¬ë¶„"""
        print("ğŸ“ˆ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ ì„¤ì • (4ì›” 1ì¼ ê¸°ì¤€)
        self.df['rebal_date'] = pd.to_datetime(self.df['ì—°ë„'].astype(str) + '-04-01')
        
        # ë‹¤ìŒí•´ ìˆ˜ìµë¥  ê³„ì‚° (t+1 ìˆ˜ìµë¥ )
        self.df = self.df.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„'])
        if 'ì£¼ê°€ìˆ˜ìµë¥ ' in self.df.columns:
            self.df['next_ret'] = self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì£¼ê°€ìˆ˜ìµë¥ '].shift(-1)
        else:
            # ì¢…ê°€ ê¸°ì¤€ ìˆ˜ìµë¥ 
            price_col = 'ì¢…ê°€' if 'ì¢…ê°€' in self.df.columns else 'ì‹œê°€ì´ì•¡'
            self.df['next_ret'] = self.df.groupby('ê±°ë˜ì†Œì½”ë“œ')[price_col].pct_change(periods=-1)
        
        # 2013ë…„ ì´í›„ ë°ì´í„°ë§Œ ì‚¬ìš©
        backtest_data = self.df[self.df['ì—°ë„'] >= 2013].copy()
        
        # ë¶€ì‹¤/ì •ìƒ ê¸°ì—… êµ¬ë¶„
        default_data = backtest_data[backtest_data['default'] == 1].copy()
        normal_data = backtest_data[backtest_data['default'] == 0].copy()
        
        print(f"  ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ëŒ€ìƒ:")
        print(f"     - ë¶€ì‹¤ê¸°ì—…: {len(default_data):,}ê°œ ê´€ì¸¡ì¹˜")
        print(f"     - ì •ìƒê¸°ì—…: {len(normal_data):,}ê°œ ê´€ì¸¡ì¹˜")
        print(f"     - ì „ì²´ê¸°ì—…: {len(backtest_data):,}ê°œ ê´€ì¸¡ì¹˜")
        
        # ë°±í…ŒìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì¦
        if len(default_data) == 0:
            print("  âš ï¸ ë¶€ì‹¤ê¸°ì—… ë°ì´í„°ê°€ ì—†ì–´ ë¶€ì‹¤ê¸°ì—… ë°±í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        if len(normal_data) == 0:
            print("  âš ï¸ ì •ìƒê¸°ì—… ë°ì´í„°ê°€ ì—†ì–´ ì •ìƒê¸°ì—… ë°±í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        if len(default_data) == len(backtest_data):
            print("  âš ï¸ ëª¨ë“  ê¸°ì—…ì´ ë¶€ì‹¤ê¸°ì—…ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
        if len(normal_data) == len(backtest_data):
            print("  âš ï¸ ëª¨ë“  ê¸°ì—…ì´ ì •ìƒê¸°ì—…ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤. êµ¬ë¶„ ë¶„ì„ì´ ì˜ë¯¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŒ©í„° ì‹œê·¸ë„ ë§¤í•‘ (ì—…ë°ì´íŠ¸ëœ ë²„ì „)
        factor_signals = {
            'Magic Formula': 'magic_signal',
            'EV/EBITDA': 'ev_ebitda_signal',
            f'Momentum {self.momentum_period}m': 'mom',
            'F-score': 'fscore',
            'QMJ': 'qmj',
            'LowVol': 'lowvol',
            'FF3 Strategy': 'ff3_signal'
        }
        
        # ê° íŒ©í„°ë³„ë¡œ ë¶€ì‹¤ê¸°ì—…, ì •ìƒê¸°ì—…, ì „ì²´ê¸°ì—… ë°±í…ŒìŠ¤íŠ¸
        for strategy_name, signal_col in factor_signals.items():
            if signal_col not in backtest_data.columns:
                print(f"  âš ï¸ {strategy_name} ì‹œê·¸ë„ ì»¬ëŸ¼ '{signal_col}' ì—†ìŒ, ê±´ë„ˆëœ€")
                continue
                
            print(f"  ğŸ”„ {strategy_name} ë°±í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            # 1) ì •ìƒê¸°ì—… ë°±í…ŒìŠ¤íŠ¸ (ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ)
            if len(normal_data) > 50:  # ìµœì†Œ 50ê°œ ê´€ì¸¡ì¹˜ í•„ìš”
                self._run_group_backtest(normal_data, signal_col, f"{strategy_name}_ì •ìƒê¸°ì—…")
            else:
                print(f"    âš ï¸ ì •ìƒê¸°ì—… ë°ì´í„° ë¶€ì¡± ({len(normal_data)}ê°œ), ê±´ë„ˆëœ€")
            
            # 2) ë¶€ì‹¤ê¸°ì—… ë°±í…ŒìŠ¤íŠ¸ SKIPPED - ì •ìƒê¸°ì—…, ì „ì²´ê¸°ì—…ë§Œ ë¶„ì„
            # if len(default_data) > 50:  # ìµœì†Œ 50ê°œ ê´€ì¸¡ì¹˜ í•„ìš”
            #     self._run_group_backtest(default_data, signal_col, f"{strategy_name}_ë¶€ì‹¤ê¸°ì—…")
            # else:
            #     print(f"    âš ï¸ ë¶€ì‹¤ê¸°ì—… ë°ì´í„° ë¶€ì¡± ({len(default_data)}ê°œ), ê±´ë„ˆëœ€")
            
            # 3) ì „ì²´ê¸°ì—… ë°±í…ŒìŠ¤íŠ¸ (í•­ìƒ ì‹¤í–‰)
            self._run_group_backtest(backtest_data, signal_col, f"{strategy_name}_ì „ì²´ê¸°ì—…")
            
            # 4) êµ¬ë¶„ ë¶„ì„ì´ ì˜ë¯¸ìˆëŠ”ì§€ í™•ì¸
            if len(normal_data) > 0 and len(default_data) > 0:
                normal_ratio = len(normal_data) / len(backtest_data)
                default_ratio = len(default_data) / len(backtest_data)
                if min(normal_ratio, default_ratio) < 0.05:  # ì–´ëŠ í•œ ê·¸ë£¹ì´ 5% ë¯¸ë§Œì´ë©´ ê²½ê³ 
                    print(f"    âš ï¸ ê·¸ë£¹ ê°„ ë¶ˆê· í˜• ì‹¬í•¨ (ì •ìƒ:{normal_ratio:.1%}, ë¶€ì‹¤:{default_ratio:.1%})")
        
        print("âœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return self
    
    def _run_group_backtest(self, data, signal_col, strategy_name):
        """ê·¸ë£¹ë³„ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        portfolio_returns = []
        rebal_dates = sorted(data['rebal_date'].unique())
        
        for date in rebal_dates:
            # í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
            weights = self.construct_long_portfolio(data, signal_col, date)
            
            if len(weights) == 0:
                continue
            
            # ë‹¤ìŒ ê¸°ê°„ ìˆ˜ìµë¥  ê³„ì‚°
            date_data = data[data['rebal_date'] == date]
            next_returns = date_data.loc[weights.index, 'next_ret']
            
            # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  = weight * returnì˜ í•©
            port_ret = (weights * next_returns).sum()
            
            portfolio_returns.append({
                'date': date,
                'return': port_ret,
                'n_stocks': len(weights)
            })
        
        if portfolio_returns:
            ret_df = pd.DataFrame(portfolio_returns).set_index('date')
            self.factor_returns[strategy_name] = ret_df
    
    def calc_performance_stats(self):
        """5ë‹¨ê³„: ì„±ê³¼ì§€í‘œ ê³„ì‚°"""
        print("ğŸ“Š ì„±ê³¼ì§€í‘œ ê³„ì‚° ì¤‘...")
        
        for strategy_name, returns_df in self.factor_returns.items():
            if len(returns_df) == 0:
                continue
            
            ret_series = returns_df['return'].dropna()
            
            if len(ret_series) < 3:
                continue
            
            # CAGR ê³„ì‚°
            cum_ret = (1 + ret_series).cumprod()
            n_years = len(cum_ret)
            if n_years > 0 and cum_ret.iloc[0] > 0:
                cagr = (cum_ret.iloc[-1] / cum_ret.iloc[0]) ** (1 / n_years) - 1
            else:
                cagr = 0
            
            # ì—°ê°„ ë³€ë™ì„±
            ann_vol = ret_series.std()
            
            # ìƒ¤í”„ ë¹„ìœ¨
            sharpe = cagr / ann_vol if ann_vol > 0 else 0
            
            # ìµœëŒ€ ë‚™í­
            running_max = cum_ret.cummax()
            drawdown = (cum_ret / running_max - 1)
            max_dd = drawdown.min()
            
            # ì¹¼ë§ˆ ë¹„ìœ¨
            calmar = cagr / abs(max_dd) if max_dd != 0 else 0
            
            # ìµœì¢… ëˆ„ì ìˆ˜ìµë¥  (ìƒˆë¡œ ì¶”ê°€)
            final_cum_return = cum_ret.iloc[-1] - 1  # ëˆ„ì ìˆ˜ìµë¥  (%)
            
            self.performance_stats[strategy_name] = {
                'CAGR': cagr,
                'CumulativeReturn': final_cum_return,  # ëˆ„ì ìˆ˜ìµë¥  ì¶”ê°€
                'AnnVol': ann_vol,
                'Sharpe': sharpe,
                'MaxDD': max_dd,
                'Calmar': calmar
            }
        
        # ì„±ê³¼ì§€í‘œ ì¶œë ¥ (ìƒˆë¡œ ì¶”ê°€)
        if self.performance_stats:
            print("\n" + "="*80)
            print("ğŸ“Š ì„±ê³¼ì§€í‘œ ìš”ì•½")
            print("="*80)
            
            stats_df = pd.DataFrame(self.performance_stats).T
            
            # ì½˜ì†” ì¶œë ¥ìš©: CAGRê³¼ CumulativeReturnì„ %ë¡œ í‘œì‹œí•˜ê³  ìƒ‰ìƒ ì¶”ê°€
            stats_df_display = stats_df.copy()
            
            # CAGRê³¼ CumulativeReturnì„ ìƒ‰ìƒê³¼ ë¶€í˜¸ë¡œ í¬ë§·íŒ…
            for col in ['CAGR', 'CumulativeReturn']:
                if col in stats_df_display.columns:
                    formatted_values = []
                    for val in stats_df_display[col] * 100:
                        if val > 0:
                            formatted_values.append(f"\033[91m+{val:.2f}%\033[0m")  # ë¹¨ê°„ìƒ‰ + ì–‘ìˆ˜
                        elif val < 0:
                            formatted_values.append(f"\033[94m{val:.2f}%\033[0m")   # íŒŒë€ìƒ‰ + ìŒìˆ˜
                        else:
                            formatted_values.append(f"{val:.2f}%")  # íšŒìƒ‰ + 0
                    stats_df_display[col] = formatted_values
            
            # ì»¬ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë³€ê²½
            column_mapping = {
                'CAGR': 'CAGR(%)',
                'CumulativeReturn': 'ëˆ„ì ìˆ˜ìµë¥ (%)',
                'AnnVol': 'ì—°ê°„ë³€ë™ì„±',
                'Sharpe': 'ìƒ¤í”„ë¹„ìœ¨',
                'MaxDD': 'ìµœëŒ€ë‚™í­',
                'Calmar': 'ì¹¼ë§ˆë¹„ìœ¨'
            }
            stats_df_display = stats_df_display.rename(columns=column_mapping)
            
            # ìˆ«ì ì»¬ëŸ¼ë“¤ë§Œ ë°˜ì˜¬ë¦¼ (ì´ë¯¸ í¬ë§·ëœ ì»¬ëŸ¼ ì œì™¸)
            numeric_cols = ['ì—°ê°„ë³€ë™ì„±', 'ìƒ¤í”„ë¹„ìœ¨', 'ìµœëŒ€ë‚™í­', 'ì¹¼ë§ˆë¹„ìœ¨']
            for col in numeric_cols:
                if col in stats_df_display.columns:
                    stats_df_display[col] = stats_df_display[col].round(3)
            
            print(stats_df_display)
            
            # ì •ìƒê¸°ì—… vs ì „ì²´ê¸°ì—… ë¹„êµ ë¶„ì„
            self._print_performance_comparison(stats_df_display)
        
        print("âœ… ì„±ê³¼ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        return self
    
    def _print_performance_comparison(self, stats_df_display):
        """ì •ìƒê¸°ì—… vs ì „ì²´ê¸°ì—… ì„±ê³¼ ë¹„êµ ë¶„ì„"""
        print("\n" + "="*80)
        print("ğŸ” ì •ìƒê¸°ì—… vs ì „ì²´ê¸°ì—… ì„±ê³¼ ë¹„êµ")
        print("="*80)
        
        # ì „ëµë³„ë¡œ ì •ìƒê¸°ì—…ê³¼ ì „ì²´ê¸°ì—… ë¹„êµ
        normal_strategies = [idx for idx in stats_df_display.index if '_ì •ìƒê¸°ì—…' in idx]
        
        if not normal_strategies:
            print("   ì •ìƒê¸°ì—… ì „ëµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        comparison_data = []
        
        for normal_strategy in normal_strategies:
            factor_name = normal_strategy.replace('_ì •ìƒê¸°ì—…', '')
            all_strategy = f"{factor_name}_ì „ì²´ê¸°ì—…"
            
            if all_strategy in stats_df_display.index:
                normal_stats = stats_df_display.loc[normal_strategy]
                all_stats = stats_df_display.loc[all_strategy]
                
                # ë¬¸ìì—´ì—ì„œ ìˆ«ì ì¶”ì¶œ (CAGR(%)ì—ì„œ %ì™€ + ì œê±°)
                def extract_numeric(val_str):
                    if isinstance(val_str, str):
                        # +43.64% í˜•íƒœì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
                        import re
                        numbers = re.findall(r'[-+]?\d*\.?\d+', val_str)
                        return float(numbers[0]) if numbers else 0
                    return float(val_str)
                
                normal_cagr = extract_numeric(normal_stats['CAGR(%)'])
                all_cagr = extract_numeric(all_stats['CAGR(%)'])
                normal_sharpe = extract_numeric(normal_stats['ìƒ¤í”„ë¹„ìœ¨'])
                all_sharpe = extract_numeric(all_stats['ìƒ¤í”„ë¹„ìœ¨'])
                
                # ì£¼ìš” ì§€í‘œ ë¹„êµ
                cagr_diff = normal_cagr - all_cagr
                sharpe_diff = normal_sharpe - all_sharpe
                
                comparison_data.append({
                    'ì „ëµ': factor_name,
                    'ì •ìƒê¸°ì—…_CAGR(%)': f"{normal_cagr:+.2f}%",
                    'ì „ì²´ê¸°ì—…_CAGR(%)': f"{all_cagr:+.2f}%",
                    'CAGR_ì°¨ì´(%)': f"{cagr_diff:+.2f}%p",
                    'ì •ìƒê¸°ì—…_ìƒ¤í”„': f"{normal_sharpe:.3f}",
                    'ì „ì²´ê¸°ì—…_ìƒ¤í”„': f"{all_sharpe:.3f}",
                    'ìƒ¤í”„_ì°¨ì´': f"{sharpe_diff:+.3f}"
                })
        
        if comparison_data:
            comparison_df = pd.DataFrame(comparison_data)
            print(comparison_df)
            
            # ìš”ì•½ ë¶„ì„ì„ ìœ„í•œ ìˆ«ì ë°ì´í„° ìˆ˜ì§‘
            numeric_data = []
            for normal_strategy in normal_strategies:
                factor_name = normal_strategy.replace('_ì •ìƒê¸°ì—…', '')
                all_strategy = f"{factor_name}_ì „ì²´ê¸°ì—…"
                
                if all_strategy in stats_df_display.index:
                    normal_stats = stats_df_display.loc[normal_strategy]
                    all_stats = stats_df_display.loc[all_strategy]
                    
                    def extract_numeric(val_str):
                        if isinstance(val_str, str):
                            import re
                            numbers = re.findall(r'[-+]?\d*\.?\d+', val_str)
                            return float(numbers[0]) if numbers else 0
                        return float(val_str)
                    
                    normal_cagr = extract_numeric(normal_stats['CAGR(%)'])
                    all_cagr = extract_numeric(all_stats['CAGR(%)'])
                    normal_sharpe = extract_numeric(normal_stats['ìƒ¤í”„ë¹„ìœ¨'])
                    all_sharpe = extract_numeric(all_stats['ìƒ¤í”„ë¹„ìœ¨'])
                    
                    numeric_data.append({
                        'ì „ëµ': factor_name,
                        'CAGR_ì°¨ì´': normal_cagr - all_cagr,
                        'ìƒ¤í”„_ì°¨ì´': normal_sharpe - all_sharpe
                    })
            
            if numeric_data:
                numeric_df = pd.DataFrame(numeric_data)
                
                # ìš”ì•½ ë¶„ì„
                print(f"\nğŸ“ˆ ë¶„ì„ ê²°ê³¼:")
                avg_cagr_diff = numeric_df['CAGR_ì°¨ì´'].mean()
                avg_sharpe_diff = numeric_df['ìƒ¤í”„_ì°¨ì´'].mean()
                
                print(f"   í‰ê·  CAGR ì°¨ì´: {avg_cagr_diff:.2f}%p ({'ì •ìƒê¸°ì—… ìš°ì„¸' if avg_cagr_diff > 0 else 'ì „ì²´ê¸°ì—… ìš°ì„¸'})")
                print(f"   í‰ê·  ìƒ¤í”„ë¹„ìœ¨ ì°¨ì´: {avg_sharpe_diff:.3f} ({'ì •ìƒê¸°ì—… ìš°ì„¸' if avg_sharpe_diff > 0 else 'ì „ì²´ê¸°ì—… ìš°ì„¸'})")
                
                # ê°€ì¥ í° ì°¨ì´ë¥¼ ë³´ì´ëŠ” ì „ëµ
                if len(numeric_df) > 0:
                    max_cagr_diff_idx = numeric_df['CAGR_ì°¨ì´'].abs().idxmax()
                    max_sharpe_diff_idx = numeric_df['ìƒ¤í”„_ì°¨ì´'].abs().idxmax()
                    
                    best_cagr_strategy = numeric_df.loc[max_cagr_diff_idx]
                    best_sharpe_strategy = numeric_df.loc[max_sharpe_diff_idx]
            
                    print(f"   CAGR ì°¨ì´ ìµœëŒ€: {best_cagr_strategy['ì „ëµ']} ({best_cagr_strategy['CAGR_ì°¨ì´']:.2f}%p)")
            print(f"   ìƒ¤í”„ë¹„ìœ¨ ì°¨ì´ ìµœëŒ€: {best_sharpe_strategy['ì „ëµ']} ({best_sharpe_strategy['ìƒ¤í”„_ì°¨ì´']:.3f})")
    
    def _generate_comparison_html(self, stats_df):
        """ì •ìƒê¸°ì—… vs ì „ì²´ê¸°ì—… ë¹„êµí‘œ HTML ìƒì„±"""
        normal_strategies = [idx for idx in stats_df.index if '_ì •ìƒê¸°ì—…' in idx]
        
        if not normal_strategies:
            return ""
        
        comparison_data = []
        
        for normal_strategy in normal_strategies:
            factor_name = normal_strategy.replace('_ì •ìƒê¸°ì—…', '')
            all_strategy = f"{factor_name}_ì „ì²´ê¸°ì—…"
            
            if all_strategy in stats_df.index:
                normal_stats = stats_df.loc[normal_strategy]
                all_stats = stats_df.loc[all_strategy]
                
                # %ë¡œ ë³€í™˜
                normal_cagr = normal_stats['CAGR'] * 100
                all_cagr = all_stats['CAGR'] * 100
                cagr_diff = normal_cagr - all_cagr
                sharpe_diff = normal_stats['Sharpe'] - all_stats['Sharpe']
                
                comparison_data.append({
                    'ì „ëµ': factor_name,
                    'ì •ìƒê¸°ì—…_CAGR(%)': f"{normal_cagr:.2f}%",
                    'ì „ì²´ê¸°ì—…_CAGR(%)': f"{all_cagr:.2f}%",
                    'CAGR_ì°¨ì´': f"{cagr_diff:+.2f}%p",
                    'ì •ìƒê¸°ì—…_ìƒ¤í”„': f"{normal_stats['Sharpe']:.3f}",
                    'ì „ì²´ê¸°ì—…_ìƒ¤í”„': f"{all_stats['Sharpe']:.3f}",
                    'ìƒ¤í”„_ì°¨ì´': f"{sharpe_diff:+.3f}"
                })
        
        if not comparison_data:
            return ""
        
        comparison_df = pd.DataFrame(comparison_data)
        
        return f"""
        <div style="margin-top: 30px;">
            <h3 style="color: #333; font-family: Arial, sans-serif;">ğŸ” ì •ìƒê¸°ì—… vs ì „ì²´ê¸°ì—… ì„±ê³¼ ë¹„êµ</h3>
            {comparison_df.to_html(classes='table table-striped', table_id='comparison-table', escape=False, index=False)}
        </div>
        """
    
    def plot_results(self):
        """6ë‹¨ê³„: ì‹œê°í™”"""
        print("ğŸ“ˆ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        if not self.factor_returns:
            print("  âš ï¸ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return self
        
        if not PLOTLY_AVAILABLE:
            return self._plot_results_matplotlib()
        else:
            return self._plot_results_plotly()
    
    def _plot_results_matplotlib(self):
        """Matplotlibì„ ì‚¬ìš©í•œ ì‹œê°í™” (plotly ëŒ€ì•ˆ)"""
        print("  ğŸ“Š Matplotlibì„ ì‚¬ìš©í•œ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        # ì •ìƒê¸°ì—… vs ì „ì²´ê¸°ì—… ë¹„êµ ì°¨íŠ¸ ìƒì„±
        factor_groups = {}
        for strategy_name in self.factor_returns.keys():
            if '_ì •ìƒê¸°ì—…' in strategy_name:
                factor_name = strategy_name.replace('_ì •ìƒê¸°ì—…', '')
                if factor_name not in factor_groups:
                    factor_groups[factor_name] = {}
                factor_groups[factor_name]['ì •ìƒê¸°ì—…'] = strategy_name
            elif '_ì „ì²´ê¸°ì—…' in strategy_name:
                factor_name = strategy_name.replace('_ì „ì²´ê¸°ì—…', '')
                if factor_name not in factor_groups:
                    factor_groups[factor_name] = {}
                factor_groups[factor_name]['ì „ì²´ê¸°ì—…'] = strategy_name
        
        n_factors = len(factor_groups)
        if n_factors == 0:
            print("  âš ï¸ í”Œë¡¯í•  íŒ©í„° ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤.")
            return self
        
        # ì„œë¸Œí”Œë¡¯ ìƒì„±
        cols = 2
        rows = (n_factors + cols - 1) // cols
        
        fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))
        if rows == 1 and cols == 1:
            axes = [axes]
        elif rows == 1 or cols == 1:
            axes = axes.flatten()
        else:
            axes = axes.flatten()
        
        # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
        for i in range(n_factors, len(axes)):
            axes[i].set_visible(False)
        
        colors = {'ì •ìƒê¸°ì—…': 'blue', 'ì „ì²´ê¸°ì—…': 'gray'}
        
        for i, (factor_name, group_strategies) in enumerate(factor_groups.items()):
            ax = axes[i]
            
            # ê° ê·¸ë£¹ë³„ ëˆ„ì ìˆ˜ìµë¥  ì°¨íŠ¸ ì¶”ê°€
            for group_name, strategy_name in group_strategies.items():
                if strategy_name in self.factor_returns:
                    returns_df = self.factor_returns[strategy_name]
                    if len(returns_df) > 0:
                        cum_ret = (1 + returns_df['return']).cumprod()
                        ax.plot(cum_ret.index, cum_ret.values, 
                               label=f"{group_name}", 
                               color=colors.get(group_name, 'black'),
                               linewidth=2)
            
            ax.axhline(y=1, color='black', linestyle='--', alpha=0.5, label='ê¸°ì¤€ì„  (0%)')
            ax.set_title(factor_name)
            ax.set_xlabel('ì—°ë„')
            ax.set_ylabel('ëˆ„ì ìˆ˜ìµë¥ ')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # íŒŒì¼ ì €ì¥
        output_path = os.path.join(self.output_dir, 'factor_performance_charts.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"  ğŸ“Š ì°¨íŠ¸ ì €ì¥: {output_path}")
        
        # plt.show() ì£¼ì„ ì²˜ë¦¬ - ì½˜ì†” ì¶œë ¥ ë°©ì§€
        # plt.show()
        plt.close()  # ë©”ëª¨ë¦¬ ì •ë¦¬
        
        return self
    
    def _plot_results_plotly(self):
        """Plotlyë¥¼ ì‚¬ìš©í•œ ì‹œê°í™”"""
        # ì •ìƒê¸°ì—… vs ì „ì²´ê¸°ì—… ë¹„êµ ì°¨íŠ¸ ìƒì„±
        factor_groups = {}
        for strategy_name in self.factor_returns.keys():
            if '_ì •ìƒê¸°ì—…' in strategy_name:
                factor_name = strategy_name.replace('_ì •ìƒê¸°ì—…', '')
                if factor_name not in factor_groups:
                    factor_groups[factor_name] = {}
                factor_groups[factor_name]['ì •ìƒê¸°ì—…'] = strategy_name
            elif '_ì „ì²´ê¸°ì—…' in strategy_name:
                factor_name = strategy_name.replace('_ì „ì²´ê¸°ì—…', '')
                if factor_name not in factor_groups:
                    factor_groups[factor_name] = {}
                factor_groups[factor_name]['ì „ì²´ê¸°ì—…'] = strategy_name
        
        n_factors = len(factor_groups)
        if n_factors == 0:
            return self
        
        cols = 2
        rows = (n_factors + cols - 1) // cols
        
        # ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig = make_subplots(
            rows=rows, 
            cols=cols,
            subplot_titles=list(factor_groups.keys()),
            vertical_spacing=0.08,
            horizontal_spacing=0.1
        )
        
        colors = {'ì •ìƒê¸°ì—…': 'blue', 'ì „ì²´ê¸°ì—…': 'gray'}
        
        for i, (factor_name, group_strategies) in enumerate(factor_groups.items()):
            row = (i // cols) + 1
            col = (i % cols) + 1
            
            # ê° ê·¸ë£¹ë³„ ëˆ„ì ìˆ˜ìµë¥  ì°¨íŠ¸ ì¶”ê°€
            for group_name, strategy_name in group_strategies.items():
                if strategy_name in self.factor_returns:
                    returns_df = self.factor_returns[strategy_name]
                    if len(returns_df) > 0:
                        cum_ret = (1 + returns_df['return']).cumprod()
                        
                        fig.add_trace(
                            go.Scatter(
                                x=cum_ret.index,
                                y=cum_ret.values,
                                name=f"{factor_name}_{group_name}",
                                line=dict(color=colors.get(group_name, 'black'), width=2),
                                showlegend=(i == 0)
                            ),
                            row=row, col=col
                        )
        
        # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
        fig.update_layout(
            title="íŒ©í„°ë³„ ì •ìƒê¸°ì—… vs ì „ì²´ê¸°ì—… ëˆ„ì ìˆ˜ìµë¥  ë¹„êµ (FF3 í†µí•© ë²„ì „)",
            font=dict(family='AppleGothic'),
            height=350 * rows,
            showlegend=True
        )
        
        # yì¶• ì œëª© ì—…ë°ì´íŠ¸
        fig.update_yaxes(title_text="ëˆ„ì ìˆ˜ìµë¥ ")
        
        # íŒŒì¼ ì €ì¥
        output_path = os.path.join(self.output_dir, 'factor_performance_charts.html')
        fig.write_html(output_path)
        
        # ì„±ê³¼ì§€í‘œ í…Œì´ë¸”ì„ HTMLì— ì¶”ê°€
        if self.performance_stats:
            import pandas as pd
            stats_df = pd.DataFrame(self.performance_stats).T
            
            # CAGRê³¼ CumulativeReturnì„ %ë¡œ ë³€í™˜
            stats_df_formatted = stats_df.copy()
            if 'CAGR' in stats_df_formatted.columns:
                stats_df_formatted['CAGR'] = (stats_df_formatted['CAGR'] * 100).round(2).astype(str) + '%'
            if 'CumulativeReturn' in stats_df_formatted.columns:
                stats_df_formatted['CumulativeReturn'] = (stats_df_formatted['CumulativeReturn'] * 100).round(2).astype(str) + '%'
            
            # HTML íŒŒì¼ ì½ê¸°
            with open(output_path, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # ì»¬ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë³€ê²½ (HTMLìš©)
            column_mapping = {
                'CAGR': 'CAGR',
                'CumulativeReturn': 'ëˆ„ì ìˆ˜ìµë¥ ',
                'AnnVol': 'ì—°ê°„ë³€ë™ì„±',
                'Sharpe': 'ìƒ¤í”„ë¹„ìœ¨',
                'MaxDD': 'ìµœëŒ€ë‚™í­',
                'Calmar': 'ì¹¼ë§ˆë¹„ìœ¨'
            }
            stats_df_formatted = stats_df_formatted.rename(columns=column_mapping)
            
            # ì •ìƒê¸°ì—… vs ì „ì²´ê¸°ì—… ë¹„êµí‘œ ìƒì„±
            comparison_html = self._generate_comparison_html(stats_df)
            
            # ì„±ê³¼ì§€í‘œ í…Œì´ë¸” HTML ìƒì„±
            stats_table_html = f"""
            <div style="margin-top: 50px; padding: 20px; background-color: #f8f9fa; border-radius: 10px;">
                <h2 style="color: #333; font-family: Arial, sans-serif;">ğŸ“Š ì„±ê³¼ì§€í‘œ ìš”ì•½</h2>
                {stats_df_formatted.to_html(classes='table table-striped', table_id='performance-table', escape=False)}
                
                {comparison_html}
                <style>
                    #performance-table {{
                        width: 100%;
                        border-collapse: collapse;
                        margin-top: 15px;
                        font-family: Arial, sans-serif;
                    }}
                    #performance-table th, #performance-table td {{
                        padding: 8px 12px;
                        text-align: right;
                        border: 1px solid #ddd;
                    }}
                    #performance-table th {{
                        background-color: #e9ecef;
                        font-weight: bold;
                    }}
                    #performance-table tr:nth-child(even) {{
                        background-color: #f8f9fa;
                    }}
                </style>
            </div>
            """
            
            # HTMLì— í…Œì´ë¸” ì¶”ê°€
            html_content = html_content.replace('</body>', f'{stats_table_html}</body>')
            
            # ìˆ˜ì •ëœ HTML ì €ì¥
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
        
        print(f"  ğŸ“Š ì°¨íŠ¸ ë° ì„±ê³¼ì§€í‘œ ì €ì¥: {output_path}")
        
        # fig.show() ì£¼ì„ ì²˜ë¦¬ - ì½˜ì†”ì— HTML ì½”ë“œ ì¶œë ¥ ë°©ì§€
        # fig.show()
        
        print("âœ… ì‹œê°í™” ì™„ë£Œ")
        return self
    
    def save_results(self):
        """7ë‹¨ê³„: ê²°ê³¼ ì €ì¥"""
        print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        # í”¼ì²˜ ë°ì´í„° ì €ì¥ (FS2_features.csv) - data/processedì— ì €ì¥
        os.makedirs('data/processed', exist_ok=True)
        feature_output_path = 'data/processed/FS2_backtesting.csv'
        self.df.to_csv(feature_output_path, encoding='utf-8', index=False)
        print(f"âœ… í”¼ì²˜ ë°ì´í„° ì €ì¥: {feature_output_path}")
        
        # ì„±ê³¼ í†µê³„ ì €ì¥
        if self.performance_stats:
            stats_df = pd.DataFrame(self.performance_stats).T
            stats_output_path = os.path.join(self.output_dir, 'factor_performance_stats.csv')
            stats_df.to_csv(stats_output_path, encoding='utf-8-sig')
            print(f"âœ… ì„±ê³¼í†µê³„ ì €ì¥: {stats_output_path}")
        
        # íŒ©í„° ìˆ˜ìµë¥  ì €ì¥
        for strategy_name, returns_df in self.factor_returns.items():
            if len(returns_df) > 0:
                safe_name = strategy_name.replace('/', '_').replace(' ', '_')
                filename = os.path.join(self.output_dir, f"factor_returns_{safe_name}.csv")
                returns_df.to_csv(filename, encoding='utf-8-sig')
        
        print("âœ… íŒ©í„° ìˆ˜ìµë¥  ì €ì¥ ì™„ë£Œ")
        
        # ìš”ì•½ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ“Š FACTOR BACKTESTING SUMMARY (Updated Version)")
        print("="*60)
        print("ğŸ¯ ì „ëµ êµ¬ì„± (7ê°œ):")
        print("   1. Magic Formula")
        print("   2. EV/EBITDA") 
        print("   3. Momentum")
        print("   4. F-score")
        print("   5. QMJ")
        print("   6. Low Volatility")
        print("   7. FF3 Strategy (í†µí•©) â­")
        
        if self.performance_stats:
            print("\nğŸ“ˆ ì„±ê³¼ ìš”ì•½:")
            for strategy, stats in self.performance_stats.items():
                if 'FF3' in strategy:
                    print(f"\nğŸ¯ {strategy}")
                    print(f"   CAGR: {stats['CAGR']:.2%}")
                    print(f"   ìƒ¤í”„ë¹„ìœ¨: {stats['Sharpe']:.3f}")
                    print(f"   ìµœëŒ€ë‚™í­: {stats['MaxDD']:.2%}")
                    print(f"   ì¹¼ë§ˆë¹„ìœ¨: {stats['Calmar']:.3f}")
        
        return self

    def build_ff3_factors(self, start_date, end_date, smb_series, hml_series):
        """FF-3 FACTOR BUILDER (monthly â†’ annual)"""
        print(f"Building FF3 factors from {start_date} to {end_date}")
        
        # Convert dates for pykrx API calls
        start_dt = pd.to_datetime(start_date)
        end_dt = pd.to_datetime(end_date)
        
        if PYKRX_AVAILABLE:
            # KOSPI price index (monthly close)
            kospi_data = stock.get_index_ohlcv(
                start_dt.strftime('%Y%m%d'), 
                end_dt.strftime('%Y%m%d'), 
                "1001"
            )["ì¢…ê°€"]
            
            # CD(91ì¼) daily yields
            cd_data = bond.get_otc_treasury_yields(
                start_dt.strftime('%Y%m%d'),
                end_dt.strftime('%Y%m%d'), 
                "CD(91ì¼)"
            )["ìˆ˜ìµë¥ "] / 100
        else:
            # Mock data for testing when pykrx is not available
            print("Using mock data for testing (pykrx not available)")
            date_range = pd.date_range(start_dt, end_dt, freq='M')
            kospi_data = pd.Series(
                np.random.normal(0.01, 0.05, len(date_range)) * 100 + 2000,
                index=date_range
            )
            cd_data = pd.Series(
                np.random.normal(0.02, 0.01, len(date_range)),
                index=date_range
            )
        
        # Convert to monthly data (end of month)
        kospi_monthly = kospi_data.resample('M').last().pct_change()
        cd_monthly = cd_data.resample('M').last()
        
        # Align all series to same monthly index
        common_idx = kospi_monthly.index.intersection(cd_monthly.index)
        common_idx = common_idx.intersection(smb_series.index)
        common_idx = common_idx.intersection(hml_series.index)
        
        kospi_monthly = kospi_monthly.reindex(common_idx)
        cd_monthly = cd_monthly.reindex(common_idx)
        smb_monthly = smb_series.reindex(common_idx)
        hml_monthly = hml_series.reindex(common_idx)
        
        # Create annual periods (Apr-Mar)
        monthly_df = pd.DataFrame({
            'MKT': kospi_monthly,
            'RF': cd_monthly,
            'SMB': smb_monthly,
            'HML': hml_monthly
        })
        
        # Group by annual periods (Apr-Mar)
        monthly_df.index = pd.to_datetime(monthly_df.index)
        annual_groups = monthly_df.groupby(pd.Grouper(freq='A-APR'))
        
        # Calculate annual cumulative returns
        annual_factors = []
        for period, group in annual_groups:
            if len(group) >= 6:  # Minimum 6 months of data
                mkt_annual = (1 + group['MKT'].fillna(0)).prod() - 1
                rf_annual = (1 + group['RF'].fillna(0)).prod() - 1
                smb_annual = (1 + group['SMB'].fillna(0)).prod() - 1
                hml_annual = (1 + group['HML'].fillna(0)).prod() - 1
                
                annual_factors.append({
                    'period': period,
                    'MKT_RF': mkt_annual - rf_annual,
                    'SMB': smb_annual,
                    'HML': hml_annual
                })
        
        ff3_df = pd.DataFrame(annual_factors).set_index('period')
        ff3_df.index = pd.PeriodIndex(ff3_df.index, freq='A-APR')
        
        return ff3_df

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='Factor Backtesting - Updated Version with FF3 Integration')
    parser.add_argument('--data_path', type=str, default='data/processed', 
                       help='Data directory path (default: data/processed)')
    parser.add_argument('--output_dir', type=str, default='outputs/backtesting',
                       help='Output directory path (default: outputs/backtesting)')
    parser.add_argument('--top_n', '-t', type=int, default=10,
                       help='Number of top stocks to select (default: 10)')
    parser.add_argument('--fscore_min_score', '-f', type=int, default=8,
                       help='Minimum F-Score for selection (default: 8)')
    parser.add_argument('--momentum_period', '-m', type=int, default=12,
                       help='Momentum period in months (default: 12)')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ Factor Investing Backtesting ì‹œì‘ (Updated with FF3 Integration)")
    print(f"ğŸ“Š F-Score ìµœì†Œ ì ìˆ˜: {args.fscore_min_score}ì ")
    print(f"ğŸ“ˆ ëª¨ë©˜í…€ ê¸°ê°„: {args.momentum_period}ê°œì›”")
    print("="*60)
    
    # ë°±í…ŒìŠ¤í„° ì´ˆê¸°í™” ë° ì‹¤í–‰
    backtester = FactorBacktester(
        data_path=args.data_path, 
        output_dir=args.output_dir,
        top_n=args.top_n,
        fscore_min_score=args.fscore_min_score,
        momentum_period=args.momentum_period
    )
    
    backtester.load_data() \
              .compute_features() \
              .compute_factor_signals() \
              .backtest() \
              .calc_performance_stats() \
              .plot_results() \
              .save_results()
    
    print("\nğŸ‰ ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return backtester

def example_ff3():
    """FF3 íŒ©í„° ì‚¬ìš© ì˜ˆì‹œ"""
    print("FF3 Factor Builder Example")
    
    # ì˜ˆì‹œ: ì›”ê°„ SMB, HML ì‹œë¦¬ì¦ˆ ë¡œë“œ (CSV íŒŒì¼ì—ì„œ)
    try:
        sm = pd.read_csv('smb.csv', index_col=0).iloc[:, 0]  # squeeze=True ëŒ€ì‹ 
        hm = pd.read_csv('hml.csv', index_col=0).iloc[:, 0]  # squeeze=True ëŒ€ì‹ 
        
        # FF3 íŒ©í„° êµ¬ì¶•
        backtester = FactorBacktester()
        ff3 = backtester.build_ff3_factors("2000-01", "2025-06", sm, hm)
        print(ff3.tail())
    except FileNotFoundError:
        print("SMB/HML CSV files not found. Please provide monthly factor series.")

if __name__ == "__main__":
    results = main()