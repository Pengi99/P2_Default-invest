"""
Final Models í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œê¸°
=====================================

final_models ë””ë ‰í† ë¦¬ì˜ joblib ëª¨ë¸ íŒŒì¼ë“¤ì—ì„œ 
í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON íŒŒì¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.
"""

import joblib
import json
import pandas as pd
from pathlib import Path
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')


def extract_model_hyperparameters(model_path):
    """ëª¨ë¸ íŒŒì¼ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ"""
    try:
        # ëª¨ë¸ ë¡œë“œ
        model = joblib.load(model_path)
        
        # ì•™ìƒë¸” ëª¨ë¸ì¸ ê²½ìš°
        if hasattr(model, 'models') and hasattr(model, 'weights'):
            return {
                'model_type': 'ensemble',
                'ensemble_info': {
                    'num_models': len(model.models) if hasattr(model, 'models') else 0,
                    'weights': model.weights.tolist() if hasattr(model, 'weights') else [],
                    'weight_metric': getattr(model, 'weight_metric', 'unknown'),
                    'data_types': getattr(model, 'data_types', []),
                    'model_types': getattr(model, 'model_types', [])
                }
            }
        
        # ê°œë³„ ëª¨ë¸ì¸ ê²½ìš°
        model_params = {}
        
        # XGBoost ëª¨ë¸
        if hasattr(model, 'get_params') and 'xgb' in str(type(model)).lower():
            params = model.get_params()
            model_params = {
                'model_type': 'xgboost',
                'hyperparameters': {k: v for k, v in params.items() if v is not None}
            }
        
        # RandomForest ëª¨ë¸
        elif hasattr(model, 'n_estimators') and 'forest' in str(type(model)).lower():
            params = model.get_params()
            model_params = {
                'model_type': 'random_forest',
                'hyperparameters': {k: v for k, v in params.items() if v is not None}
            }
        
        # LogisticRegression ëª¨ë¸
        elif hasattr(model, 'C') and 'logistic' in str(type(model)).lower():
            params = model.get_params()
            model_params = {
                'model_type': 'logistic_regression',
                'hyperparameters': {k: v for k, v in params.items() if v is not None}
            }
        
        # ì¼ë°˜ì ì¸ sklearn ëª¨ë¸
        elif hasattr(model, 'get_params'):
            params = model.get_params()
            model_params = {
                'model_type': str(type(model).__name__),
                'hyperparameters': {k: v for k, v in params.items() if v is not None}
            }
        
        else:
            model_params = {
                'model_type': str(type(model).__name__),
                'hyperparameters': {}
            }
        
        # ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
        if hasattr(model, 'feature_importances_'):
            model_params['has_feature_importance'] = True
            model_params['n_features'] = len(model.feature_importances_)
        
        if hasattr(model, 'classes_'):
            model_params['n_classes'] = len(model.classes_)
            
        return model_params
        
    except Exception as e:
        return {
            'model_type': 'unknown',
            'error': str(e),
            'hyperparameters': {}
        }


def clean_hyperparameters(params):
    """JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ íŒŒë¼ë¯¸í„° ì •ë¦¬"""
    cleaned = {}
    
    for key, value in params.items():
        if value is None:
            cleaned[key] = None
        elif isinstance(value, (int, float, str, bool)):
            cleaned[key] = value
        elif isinstance(value, (list, tuple)):
            try:
                cleaned[key] = list(value)
            except:
                cleaned[key] = str(value)
        elif hasattr(value, 'tolist'):  # numpy arrays
            try:
                cleaned[key] = value.tolist()
            except:
                cleaned[key] = str(value)
        else:
            cleaned[key] = str(value)
    
    return cleaned


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” Final Models í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì‹œì‘")
    
    # final_models ë””ë ‰í† ë¦¬ ê²½ë¡œ
    models_dir = Path("/Users/jojongho/KDT/P2_Default-invest/final_models")
    
    if not models_dir.exists():
        print(f"âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {models_dir}")
        return
    
    # ëª¨ë¸ íŒŒì¼ ëª©ë¡
    model_files = list(models_dir.glob("*.joblib"))
    print(f"ğŸ“ ë°œê²¬ëœ ëª¨ë¸ íŒŒì¼: {len(model_files)}ê°œ")
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    all_hyperparameters = {}
    model_summary = defaultdict(list)
    
    for model_file in model_files:
        print(f"ğŸ” ì²˜ë¦¬ì¤‘: {model_file.name}")
        
        # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
        filename = model_file.stem
        if "__" in filename:
            data_type, model_info = filename.split("__", 1)
            model_type = model_info.replace("_model", "")
        else:
            data_type = "unknown"
            model_type = filename.replace("_model", "")
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        params = extract_model_hyperparameters(model_file)
        
        # JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ì •ë¦¬
        if 'hyperparameters' in params:
            params['hyperparameters'] = clean_hyperparameters(params['hyperparameters'])
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        params['file_info'] = {
            'filename': model_file.name,
            'data_type': data_type,
            'model_name': model_type,
            'file_size_mb': round(model_file.stat().st_size / (1024 * 1024), 2)
        }
        
        # ê²°ê³¼ ì €ì¥
        model_key = f"{data_type}__{model_type}"
        all_hyperparameters[model_key] = params
        
        # ìš”ì•½ ì •ë³´ ìˆ˜ì§‘
        model_summary[params['model_type']].append({
            'data_type': data_type,
            'model_name': model_type,
            'file_size_mb': params['file_info']['file_size_mb']
        })
        
        print(f"   âœ… {params['model_type']} ì™„ë£Œ")
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    output_file = "final_models_hyperparameters.json"
    
    # ë©”íƒ€ë°ì´í„° ì¶”ê°€
    final_output = {
        'metadata': {
            'total_models': len(model_files),
            'extraction_date': pd.Timestamp.now().isoformat(),
            'models_directory': str(models_dir),
            'model_types': list(model_summary.keys())
        },
        'model_summary': dict(model_summary),
        'detailed_hyperparameters': all_hyperparameters
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_output, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì™„ë£Œ!")
    print(f"ğŸ“„ ì €ì¥ íŒŒì¼: {output_file}")
    
    # ìš”ì•½ ì¶œë ¥
    print(f"\nğŸ“Š ëª¨ë¸ ìš”ì•½:")
    for model_type, models in model_summary.items():
        print(f"  {model_type}: {len(models)}ê°œ")
        for model in models:
            print(f"    - {model['data_type']}__{model['model_name']} ({model['file_size_mb']}MB)")
    
    # ê°„ë‹¨í•œ í†µê³„
    total_size = sum(model['file_size_mb'] for models in model_summary.values() for model in models)
    print(f"\nğŸ’¾ ì´ ëª¨ë¸ íŒŒì¼ í¬ê¸°: {total_size:.2f}MB")
    
    return output_file


if __name__ == "__main__":
    main()