"""
Focused debugging script for -97% returns issue
"""

import pandas as pd
import numpy as np
import os

def analyze_data_files():
    """Analyze the raw data files for potential issues"""
    print("ğŸ” ì›ë³¸ ë°ì´í„° íŒŒì¼ ë¶„ì„...")
    
    # Check processed data
    processed_file = "data/processed/FS2_no_default.csv"
    if os.path.exists(processed_file):
        df = pd.read_csv(processed_file)
        print(f"\nğŸ“Š FS2_no_default.csv:")
        print(f"   - í–‰ ìˆ˜: {len(df):,}")
        print(f"   - ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
        print(f"   - ë‚ ì§œ ë²”ìœ„: {df['date'].min()} ~ {df['date'].max()}" if 'date' in df.columns else "   - ë‚ ì§œ ì»¬ëŸ¼ ì—†ìŒ")
        
        # Check for key financial metrics
        financial_cols = ['ì´ìì‚°', 'ë‹¹ê¸°ìˆœì´ìµ', 'ì˜ì—…í™œë™ìœ¼ë¡œì¸í•œí˜„ê¸ˆíë¦„', 'ì‹œê°€ì´ì•¡']
        for col in financial_cols:
            if col in df.columns:
                col_stats = df[col].describe()
                print(f"   - {col}: ìµœì†Œ={col_stats['min']:,.0f}, ìµœëŒ€={col_stats['max']:,.0f}")
                
                # Check for negative or zero values in key metrics
                if col in ['ì´ìì‚°', 'ì‹œê°€ì´ì•¡']:
                    invalid_count = (df[col] <= 0).sum()
                    if invalid_count > 0:
                        print(f"     âš ï¸ {col}ì—ì„œ 0 ì´í•˜ ê°’ {invalid_count}ê°œ ë°œê²¬")
        
        # Check recent data availability
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'])
            recent_data = df[df['date'] >= '2023-01-01']
            print(f"   - 2023ë…„ ì´í›„ ë°ì´í„°: {len(recent_data):,}í–‰")
            
            if len(recent_data) == 0:
                print("     ğŸš¨ ìµœê·¼ ë°ì´í„° ë¶€ì¡± - ë°±í…ŒìŠ¤íŒ… ê¸°ê°„ ë¬¸ì œ ê°€ëŠ¥ì„±")
    
    else:
        print(f"âŒ {processed_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

def analyze_price_files():
    """Analyze price data files"""
    print("\nğŸ” ê°€ê²© ë°ì´í„° íŒŒì¼ ë¶„ì„...")
    
    price_files = [
        "data/final/merged_daily_data_2020_2023.csv",
        "data/final/merged_daily_data_2024.csv"
    ]
    
    total_records = 0
    date_ranges = []
    
    for file_path in price_files:
        if os.path.exists(file_path):
            df = pd.read_csv(file_path)
            total_records += len(df)
            
            print(f"\nğŸ“Š {os.path.basename(file_path)}:")
            print(f"   - í–‰ ìˆ˜: {len(df):,}")
            print(f"   - ê³ ìœ  ì¢…ëª© ìˆ˜: {df['ê±°ë˜ì†Œì½”ë“œ'].nunique()}" if 'ê±°ë˜ì†Œì½”ë“œ' in df.columns else "   - ê±°ë˜ì†Œì½”ë“œ ì»¬ëŸ¼ ì—†ìŒ")
            
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
                date_ranges.append((df['date'].min(), df['date'].max()))
                print(f"   - ë‚ ì§œ ë²”ìœ„: {df['date'].min().date()} ~ {df['date'].max().date()}")
            
            # Check price columns
            price_cols = ['ì¢…ê°€', 'ì‹œê°€ì´ì•¡', 'ì¼ê°„_ì‹œê°€ì´ì•¡']
            for col in price_cols:
                if col in df.columns:
                    valid_prices = df[df[col] > 0][col]
                    if len(valid_prices) > 0:
                        print(f"   - {col}: ìµœì†Œ={valid_prices.min():,.0f}, ìµœëŒ€={valid_prices.max():,.0f}")
                        
                        # Check for extreme price changes
                        df_sorted = df.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'date'])
                        df_sorted['price_change'] = df_sorted.groupby('ê±°ë˜ì†Œì½”ë“œ')[col].pct_change()
                        extreme_changes = df_sorted[df_sorted['price_change'].abs() > 0.5]
                        
                        if len(extreme_changes) > 0:
                            print(f"     âš ï¸ ì¼ì¼ 50% ì´ìƒ ê°€ê²© ë³€í™”: {len(extreme_changes)}ê±´")
                    
                    zero_prices = (df[col] <= 0).sum()
                    if zero_prices > 0:
                        print(f"     âš ï¸ {col}ì—ì„œ 0 ì´í•˜ ê°€ê²©: {zero_prices}ê±´")
        else:
            print(f"âŒ {file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    print(f"\nğŸ“ˆ ê°€ê²© ë°ì´í„° ì´ê³„:")
    print(f"   - ì´ ë ˆì½”ë“œ: {total_records:,}")
    if date_ranges:
        all_start = min(d[0] for d in date_ranges)
        all_end = max(d[1] for d in date_ranges)
        print(f"   - ì „ì²´ ë‚ ì§œ ë²”ìœ„: {all_start.date()} ~ {all_end.date()}")

def check_optimization_issues():
    """Check for issues introduced by optimizations"""
    print("\nğŸ” ìµœì í™” ê´€ë ¨ ì´ìŠˆ ì²´í¬...")
    
    # Check if optimized libraries are available
    try:
        import polars as pl
        print("âœ… Polars ì‚¬ìš© ê°€ëŠ¥")
    except ImportError:
        print("âŒ Polars ë¶ˆê°€ - Pandas ì‚¬ìš©")
    
    try:
        from numba import jit
        print("âœ… Numba ì‚¬ìš© ê°€ëŠ¥")
    except ImportError:
        print("âŒ Numba ë¶ˆê°€ - ìˆœìˆ˜ Python ì‚¬ìš©")
    
    try:
        import dask
        print("âœ… Dask ì‚¬ìš© ê°€ëŠ¥")
    except ImportError:
        print("âŒ Dask ë¶ˆê°€")

def identify_likely_issues():
    """ìµœì‹  ìµœì í™” ì´í›„ ê°€ëŠ¥í•œ ë¬¸ì œì ë“¤"""
    print("\nğŸš¨ ê°€ëŠ¥í•œ ë¬¸ì œì ë“¤:")
    print("1. Polars ë³€í™˜ ì‹œ ë°ì´í„° íƒ€ì… ë³€ê²½ ë˜ëŠ” ì†ì‹¤")
    print("2. Numba JIT ëª¨ë©˜í…€ ê³„ì‚°ì—ì„œ ìˆ˜ì¹˜ ì˜¤ë¥˜")
    print("3. ë²¡í„°í™”ëœ ê°€ê²© ì¡°íšŒì—ì„œ ì¸ë±ì‹± ì˜¤ë¥˜")
    print("4. ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œ ë°ì´í„° ë¶„í• /ë³‘í•© ë¬¸ì œ")
    print("5. í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹± ë¡œì§ ì˜¤ë¥˜")
    print("6. ê±°ë˜ë¹„ìš© ê³¼ë‹¤ ì ìš©")
    print("7. í¬ì§€ì…˜ í¬ê¸° ê³„ì‚° ì˜¤ë¥˜")

if __name__ == "__main__":
    print("ğŸ”¬ -97% ìˆ˜ìµë¥  ë¬¸ì œ ì§‘ì¤‘ ë¶„ì„")
    print("=" * 50)
    
    analyze_data_files()
    analyze_price_files()
    check_optimization_issues()
    identify_likely_issues()
    
    print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. ìµœì í™” ì´ì „ ë°±ì—… ë²„ì „ê³¼ ê²°ê³¼ ë¹„êµ")
    print("2. ê° ìµœì í™” ë‹¨ê³„ë³„ ê°œë³„ í…ŒìŠ¤íŠ¸")
    print("3. ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ë””ë²„ê¹…")
    print("4. í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™” ì¶”ì ")