# 모델링 파이프라인 설정 파일
# ===================================

# 실험 정보
experiment:
  name: "default_modeling_run"
  version: "1.0.0"
  description: "한국 기업 부실예측 모델링 파이프라인"

# 로깅 설정
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  save_to_file: true

# 데이터 설정
data:
  input_path: "data/final"  # 전처리된 데이터가 있는 디렉토리
  files:
    X_train: "X_train.csv"
    X_val: "X_val.csv"  
    X_test: "X_test.csv"
    y_train: "y_train.csv"
    y_val: "y_val.csv"
    y_test: "y_test.csv"

# 샘플링 전략 설정
sampling:
  data_types:
    normal:
      enabled: true
      description: "원본 데이터 (샘플링 없음)"
    
    smote:
      enabled: true
      description: "BorderlineSMOTE 오버샘플링"
      sampling_strategy: 0.1  # 부실 클래스 비율 목표 (양성 2%, 원래 0.7%에서 증가)
      k_neighbors: 5
      m_neighbors: 10
      kind: "borderline-1"  # borderline-1, borderline-2, svm
      random_state: 42
    
    undersampling:
      enabled: true
      description: "언더샘플링"
      method: "tomek"  # random, edited_nearest_neighbours, tomek (노이즈 제거)
      sampling_strategy: 0.5  # 정상 클래스 유지 비율 (정상 30% 유지)
      random_state: 42
    
    ctgan:
      enabled: false
      description: "CTGAN 기반 synthetic 데이터 생성"
      sampling_strategy: 0.1  # 부실 클래스 비율 목표
      ctgan:
        epochs: 300  # 학습 epoch 수
        batch_size: 500  # 배치 크기
        generator_dim: [256, 256]  # Generator 네트워크 차원
        discriminator_dim: [256, 256]  # Discriminator 네트워크 차원
    
    combined:
      enabled: true
      description: "SMOTE + 언더샘플링 조합"
      # SMOTE 설정
      smote:
        sampling_strategy: 0.05  # 부실 클래스 비율 목표 (원래 0.7% → 20%로 증가)
        k_neighbors: 5
        m_neighbors: 10 
        kind: "borderline-1"  # borderline-1, borderline-2, svm
      # 언더샘플링 설정  
      undersampling:
        method: "tomek"  # random, edited_nearest_neighbours, tomek
        sampling_strategy: 1  # 정상 클래스 유지 비율 (10% 유지)
        random_state: 42

# 특성 선택 설정
feature_selection:
  enabled: true
  method: "logistic_regression_cv"  # logistic_regression_cv, lasso_cv, permutation_importance, shap
  
  logistic_regression_cv:
    Cs: [0.01, 0.1, 1.0, 10.0]  # 정규화 강도의 역수 (C 값들)
    cv_folds: 5
    penalty: "l1"  # l1 (Lasso), l2 (Ridge), elasticnet
    solver: "saga"  # l1 penalty를 위해서는 liblinear 또는 saga 사용
    max_iter: 10000
    threshold: "0.000001"  # median, mean, 또는 숫자값 (계수 임계값)
    scoring: "f1"  # roc_auc, f1, average_precision 등
  
  # 기존 lasso_cv (연속 회귀용, 참고용으로 유지)
  lasso_cv:
    alphas: [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]
    cv_folds: 5
    threshold: "median"  # median, mean, 또는 숫자값
  
  # Permutation Importance 방법
  permutation_importance:
    base_estimator: "random_forest"  # random_forest, logistic_regression, xgboost
    n_repeats: 10  # 순열 반복 횟수 (높을수록 정확하지만 느림)
    random_state: 42
    threshold: "median"  # median, mean, 또는 숫자값 (중요도 임계값)
    max_features: null  # 최대 특성 수 제한 (null이면 제한 없음)
    scoring: "f1"  # roc_auc, f1, average_precision 등
    # 기본 추정기별 파라미터
    estimator_params:
      random_forest:
        n_estimators: 100
        max_depth: 10
        min_samples_split: 5
        min_samples_leaf: 2
        class_weight: "balanced"
      logistic_regression:
        C: 1.0
        penalty: "l2"
        solver: "lbfgs"
        max_iter: 1000
        class_weight: "balanced"
      xgboost:
        n_estimators: 100
        max_depth: 6
        learning_rate: 0.1
        subsample: 0.8
        colsample_bytree: 0.8
  
  # SHAP 기반 특성 선택
  shap:
    base_estimator: "random_forest"  # random_forest, logistic_regression, xgboost
    explainer_type: "tree"  # auto, tree, linear, kernel, permutation
    threshold: "median"  # median, mean, 또는 숫자값 (SHAP 값 임계값)
    max_features: 10  # 최대 특성 수 제한 (null이면 제한 없음)
    sample_size: 20000  # SHAP 계산용 샘플 크기 (속도 개선용)
    # 기본 추정기별 파라미터
    estimator_params:
      random_forest:
        n_estimators: 300
        max_depth: 8
        min_samples_split: 5
        min_samples_leaf: 3
        class_weight: "balanced"
      logistic_regression:
        C: 1.0
        penalty: "l2"
        solver: "lbfgs"
        max_iter: 1000
        class_weight: "balanced"
      xgboost:
        n_estimators: 100
        max_depth: 6
        learning_rate: 0.1
        subsample: 0.8
        colsample_bytree: 0.8

# 모델 설정
models:
  # 최적화 메트릭 설정
  optimization:
    primary_metric: "f1"  # roc_auc, f1, average_precision, balanced_accuracy
    description: "하이퍼파라미터 최적화 시 사용할 주요 메트릭"
  
  logistic_regression:
    enabled: true
    class_weight: null  # class_weight 제거로 Precision 개선 (극심한 불균형 데이터에서 오히려 성능 저하)
    penalty: ["l2"]
    l2_solvers: ["newton-cg", "lbfgs", "sage", "liblinear"]  # 가장 안정적인 solver들만 사용
    C_range: [0.01, 100]  # 수렴 안정성을 위해 범위 축소
    max_iter_range: [100, 10000]  # 충분한 반복 횟수 보장
    l1_ratio_range: [0.1, 0.9]  # elasticnet용
    n_trials: 20  # trial 수 감소로 빠른 수렴
  
  random_forest:
    enabled: true
    class_weight: null  # class_weight 제거로 Precision 개선 (극심한 불균형 데이터에서 오히려 성능 저하)
    n_estimators_range: [200, 1000]
    max_depth_range: [3, 20]
    min_samples_split_range: [2, 20]
    min_samples_leaf_range: [1, 10]
    max_features_range: [0.1, 1.0]
    n_trials: 20
  
  xgboost:
    enabled: true
    class_weight_mode: "scale_pos_weight"  # "scale_pos_weight" 또는 "sample_weight"
    scale_pos_weight: auto  # 적당한 가중치 사용 (auto는 102.11로 너무 극단적)
    n_estimators_range: [200, 800]
    max_depth_range: [3, 10]
    learning_rate_range: [0.005, 0.3]
    subsample_range: [0.6, 1.0]
    colsample_bytree_range: [0.6, 1.0]
    reg_alpha_range: [0.0, 10.0]
    reg_lambda_range: [1.0, 10.0]
    n_trials: 20

# Threshold 최적화 설정
threshold_optimization:
  enabled: true
  metric_priority: "f1"  # f1, precision, recall, balanced_accuracy
  search_range:
    low: 0.0005  # 최소 임계값
    high: 0.50   # 최대 임계값  
    n_grid: 3000  # 그리드 점 수

# 앙상블 설정
ensemble:
  enabled: true
  method: "weighted_average"  # simple_average, weighted_average, stacking
  auto_weight: true  # 검증 성능 기반 자동 가중치
  weight_metric: "average_precision"  # 앙상블 가중치 계산에 사용할 메트릭 (roc_auc, f1, average_precision)
  models: ["logistic_regression", "random_forest", "xgboost"]
  data_types: ["normal", "smote", "undersampling", "combined"]  # combined 비활성화 시
  threshold_optimization:
    enabled: true
    metric_priority: "f1"

# 출력 설정
output:
  base_dir: "outputs/modeling_runs"
  save_models: true
  save_results: true
  generate_visualizations: true
  report_format: ["txt", "html"]

# 성능 설정
performance:
  n_jobs: -1  # 병렬 처리 코어 수 (-1: 모든 코어)

# 랜덤 시드
random_state: 42

# 데이터 변환 설정 
# ==================================================================================
# 실행 순서: 1) 로그 변환 → 2) 스케일링 → 3) 샘플링
# 
# 분산 분석 결과 반영:
# - 극도 분산(CV > 50): 로그 변환 → RobustScaler
# - 높은 분산(CV 5-50): 로그 변환 또는 RobustScaler  
# - 낮은 분산(CV < 5): StandardScaler
# - 다중공선성 고려: VIF > 5인 변수는 별도 모니터링
# ==================================================================================
scaling:
  enabled: true
  
  # ==============================================================================
  # 1단계: 로그 변환 (스케일링 전에 먼저 적용)
  # 극도 분산(CV > 50) 및 왜도가 매우 높은 변수들 (분산 안정화 목적)
  # ==============================================================================
  column_groups:
    log:  # 로그 변환 적용 (1단계)
      - 총자산
      - 유동비율
      - 차입금의존도
      - 매출원가율
      - 세금과공과총비용비율
      - 누적감가상각률
      - 지급이자율
      - 매출채권비율
      - 매입채무재고자산비율
      - 매입채무회전률
      - 재고자산회전률
      - 매출채권회전률
      - PER최고
      - PBR최저
      - PCR최저
    # ==============================================================================
    # 2단계: 스케일링 (로그 변환 후 적용)
    # ==============================================================================
    
    robust:  # RobustScaler - 이상치에 강함 (로그 변환된 변수 + 높은 분산 변수)
      - 경영자본순이익률
      - 이자보상배율
      - 매출액증가율
      - 매출액총이익률
      - 총자본증가율
      - 유형자산증가율
      - 유동비율
      - 차입금의존도
      - 유동자산증가율
      - 자기자본증가율
      - 영업이익증가율
      - 순이익증가율
      - 총포괄이익증가율
      - 종업원수증가율
      - 경영자본영업이익률
      - 매출원가율
      - 금융손익비율
      - 금융비용부담률
      - 외환이익비율

      # 애매한 변수
      - 인건비비율

      - 세금과공과총비용비율
      - 금융비용총비용비율
      - 누적감가상각률
      - 이자부담률
      - 지급이자율
      - 매출채권비율
      - 매입채무재고자산비율
      - 순운전자본비율
      - 현금흐름부채비율
      - 현금흐름차입금비율
      - 현금흐름총자본비율
      - 현금흐름매출액비율
      - 영업이익이자보상배율
      - 매입채무회전률
      - 재고자산회전률
      - 매출채권회전률
      - 주당순이익
      - PER최고
      - PBR최저
      - PCR최저

      - 총자산
      - 영업현금흐름
      - EBITDA매출액비율

    standard:  # StandardScaler - 정규분포에 가까운 변수들 (분산 분석 Low Priority)

    minmax:  # MinMaxScaler - 매우 큰 범위를 가지지만 분포가 상대적으로 안정적인 변수들
      # 현재 해당 변수 없음 (필요 시 추가)