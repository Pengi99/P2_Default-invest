"""
ë¶€ì‹¤ ë¼ë²¨ë§
==========

ê¸°ëŠ¥:
1. FS_standardized.csvì™€ value_fail.csvë¥¼ ë§¤ì¹­í•˜ì—¬ ë¶€ì‹¤ ë¼ë²¨ë§
2. íì§€ì¼ì ê¸°ì¤€ìœ¼ë¡œ t-1ë…„ì— ë¶€ì‹¤ ë¼ë²¨ ë¶€ì—¬
3. ë¶€ì‹¤ ê¸°ì—…ì˜ ë‹¤ë¥¸ ë…„ë„ ë°ì´í„° ì œê±°
4. ê²°ê³¼ë¥¼ data/processed/FS2.csvë¡œ ì €ì¥

ì‚¬ìš©ë²•:
    python default_labeler.py
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
import logging
from datetime import datetime

class DefaultLabeler:
    """ë¶€ì‹¤ ë¼ë²¨ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 fs_file: str = "data/processed/FS2_features.csv",
                 value_fail_file: str = "data/raw/value_fail.csv"):
        """
        ì´ˆê¸°í™”
        
        Args:
            fs_file: FS2_features.csv íŒŒì¼ ê²½ë¡œ
            value_fail_file: value_fail.csv íŒŒì¼ ê²½ë¡œ
        """
        self.fs_file = fs_file
        self.value_fail_file = value_fail_file
        self.project_root = Path(__file__).parent.parent.parent
        
        # ë¡œê¹… ì„¤ì •
        self.logger = self._setup_logging()
        
        self.logger.info("DefaultLabeler ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger('DefaultLabeler')
        logger.setLevel(logging.INFO)
        
        # í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        
        return logger
    
    def load_data(self) -> tuple[pd.DataFrame, pd.DataFrame]:
        """ë°ì´í„° ë¡œë“œ"""
        self.logger.info("ë°ì´í„° ë¡œë“œ ì‹œì‘")
        
        # FS_standardized.csv ë¡œë“œ
        fs_path = self.project_root / self.fs_file
        if not fs_path.exists():
            raise FileNotFoundError(f"FS_standardized.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {fs_path}")
        
        fs_df = pd.read_csv(fs_path, dtype={'ê±°ë˜ì†Œì½”ë“œ': str})
        self.logger.info(f"FS_standardized.csv ë¡œë“œ: {fs_df.shape}")
        
        # value_fail.csv ë¡œë“œ
        value_fail_path = self.project_root / self.value_fail_file
        if not value_fail_path.exists():
            raise FileNotFoundError(f"value_fail.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {value_fail_path}")
        
        fail_df = pd.read_csv(value_fail_path, dtype={'ì¢…ëª©ì½”ë“œ': str})
        self.logger.info(f"value_fail.csv ë¡œë“œ: {fail_df.shape}")
        
        return fs_df, fail_df
    
    def create_default_labels(self, fs_df: pd.DataFrame, fail_df: pd.DataFrame) -> pd.DataFrame:
        """ë¶€ì‹¤ ë¼ë²¨ ìƒì„±"""
        self.logger.info("ë¶€ì‹¤ ë¼ë²¨ ìƒì„± ì‹œì‘")
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ê¸°ì—…ì€ ì •ìƒ(0)
        result_df = fs_df.copy()
        result_df['default'] = 0
        
        # íì§€ì¼ìì—ì„œ ì—°ë„ ì¶”ì¶œ
        fail_df['íì§€ë…„ë„'] = pd.to_datetime(fail_df['íì§€ì¼ì'], errors='coerce').dt.year
        
        # ë¶€ì‹¤ ê¸°ì—…ë“¤ë§Œ ë¨¼ì € ì²˜ë¦¬
        fail_companies = set()
        labeled_rows = []
        
        for _, fail_row in fail_df.iterrows():
            company_code = fail_row['ì¢…ëª©ì½”ë“œ']
            delisting_year = fail_row['íì§€ë…„ë„']
            
            if pd.isna(delisting_year):
                self.logger.warning(f"ê¸°ì—… {company_code}ì˜ íì§€ì¼ìê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                continue
            
            delisting_year = int(delisting_year)
            
            # í•´ë‹¹ ê¸°ì—…ì˜ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            company_data = result_df[result_df['ê±°ë˜ì†Œì½”ë“œ'] == company_code].copy()
            
            if company_data.empty:
                self.logger.warning(f"ê¸°ì—… {company_code}ì˜ ì¬ë¬´ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (íì§€: {delisting_year}ë…„)")
                continue
            
            # t-1, t-2, t-3ë…„ ìˆœì„œë¡œ ë°ì´í„° ì°¾ê¸°
            target_years = [delisting_year - i for i in range(1, 4)]
            labeled = False
            
            for target_year in target_years:
                # ì •ìˆ˜ íƒ€ì…ìœ¼ë¡œ ë¹„êµ (ìˆ˜ì •ëœ ë¶€ë¶„)
                target_data = company_data[company_data['ì—°ë„'] == target_year]
                
                if not target_data.empty:
                    # í•´ë‹¹ ë…„ë„ì— ë¶€ì‹¤ ë¼ë²¨ ë¶€ì—¬
                    target_idx = target_data.index[0]
                    result_df.loc[target_idx, 'default'] = 1
                    labeled_rows.append(target_idx)
                    labeled = True
                    
                    self.logger.info(f"ë¶€ì‹¤ ë¼ë²¨ ë¶€ì—¬: ê¸°ì—… {company_code}, {target_year}ë…„ (íì§€: {delisting_year}ë…„)")
                    break
            
            if labeled:
                fail_companies.add(company_code)
            else:
                self.logger.warning(f"ê¸°ì—… {company_code}ì˜ ë¶€ì‹¤ ë¼ë²¨ì„ ë¶€ì—¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (íì§€: {delisting_year}ë…„)")
        
        # ì •ìƒ ê¸°ì—…ë“¤ì˜ ëª¨ë“  ë°ì´í„° ì¶”ê°€
        normal_companies = set(result_df['ê±°ë˜ì†Œì½”ë“œ'].unique()) - fail_companies
        normal_rows = []
        
        for company_code in normal_companies:
            company_data = result_df[result_df['ê±°ë˜ì†Œì½”ë“œ'] == company_code]
            normal_rows.extend(company_data.index.tolist())
        
        # ìµœì¢… ë°ì´í„°: ë¶€ì‹¤ ê¸°ì—…ì˜ ë¼ë²¨ëœ í–‰ + ì •ìƒ ê¸°ì—…ì˜ ëª¨ë“  í–‰
        final_rows = labeled_rows + normal_rows
        final_df = result_df.loc[final_rows].copy().reset_index(drop=True)
        
        # ê²°ê³¼ í†µê³„
        total_companies = final_df['ê±°ë˜ì†Œì½”ë“œ'].nunique()
        default_companies = final_df[final_df['default'] == 1]['ê±°ë˜ì†Œì½”ë“œ'].nunique()
        normal_companies = total_companies - default_companies
        
        total_records = len(final_df)
        default_records = len(final_df[final_df['default'] == 1])
        normal_records = total_records - default_records
        
        self.logger.info(f"ë¼ë²¨ë§ ì™„ë£Œ:")
        self.logger.info(f"  - ì´ ê¸°ì—… ìˆ˜: {total_companies:,}ê°œ")
        self.logger.info(f"  - ë¶€ì‹¤ ê¸°ì—…: {default_companies:,}ê°œ ({default_companies/total_companies*100:.1f}%)")
        self.logger.info(f"  - ì •ìƒ ê¸°ì—…: {normal_companies:,}ê°œ ({normal_companies/total_companies*100:.1f}%)")
        self.logger.info(f"  - ì´ ë ˆì½”ë“œ: {total_records:,}ê°œ")
        self.logger.info(f"  - ë¶€ì‹¤ ë ˆì½”ë“œ: {default_records:,}ê°œ ({default_records/total_records*100:.1f}%)")
        self.logger.info(f"  - ì •ìƒ ë ˆì½”ë“œ: {normal_records:,}ê°œ ({normal_records/total_records*100:.1f}%)")
        
        return final_df
    
    def save_result(self, df: pd.DataFrame):
        """ê²°ê³¼ ì €ì¥"""
        output_dir = self.project_root / "data" / "processed"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_path = output_dir / "FS2_default.csv"
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        self.logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        self.logger.info(f"ìµœì¢… ë°ì´í„° í¬ê¸°: {df.shape}")
        
        # ì»¬ëŸ¼ ì •ë³´ ì¶œë ¥
        self.logger.info(f"ìµœì¢… ì»¬ëŸ¼ ëª©ë¡: {df.columns.tolist()}")
        
        return output_path
    
    def run_pipeline(self) -> str:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("=== ë¶€ì‹¤ ë¼ë²¨ë§ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===")
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            fs_df, fail_df = self.load_data()
            
            # 2. ë¶€ì‹¤ ë¼ë²¨ ìƒì„±
            labeled_df = self.create_default_labels(fs_df, fail_df)
            
            # 3. ê²°ê³¼ ì €ì¥
            output_path = self.save_result(labeled_df)
            
            self.logger.info("=== ë¶€ì‹¤ ë¼ë²¨ë§ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ===")
            
            return str(output_path)
            
        except Exception as e:
            self.logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ë¶€ì‹¤ ë¼ë²¨ë§')
    parser.add_argument(
        '--fs-file', '-f',
        type=str,
        default='data/processed/FS2_features.csv',
        help='FS2_features.csv íŒŒì¼ ê²½ë¡œ'
    )
    parser.add_argument(
        '--value-fail', '-v',
        type=str,
        default='data/raw/value_fail.csv',
        help='value_fail.csv íŒŒì¼ ê²½ë¡œ'
    )
    
    args = parser.parse_args()
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    labeler = DefaultLabeler(args.fs_file, args.value_fail)
    output_path = labeler.run_pipeline()
    
    print(f"\nâœ… ë¶€ì‹¤ ë¼ë²¨ë§ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_path}")
    
    # ì¶”ê°€ ì •ë³´
    print(f"\nğŸ’¡ ì°¸ê³ ì‚¬í•­:")
    print(f"   - ë¶€ì‹¤ ë¼ë²¨ë§ ê²°ê³¼ë¥¼ ë¡œê·¸ì—ì„œ í™•ì¸í•˜ì„¸ìš”")
    print(f"   - íì§€ì¼ìê°€ ì—†ëŠ” ê¸°ì—…ë“¤ì€ ìë™ìœ¼ë¡œ ì œì™¸ë©ë‹ˆë‹¤")


if __name__ == "__main__":
    main()