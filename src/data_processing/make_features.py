"""
í•œêµ­ ìƒì¥ê¸°ì—… ë¶€ë„ì˜ˆì¸¡ ë°ì´í„°ì…‹ì„ ìœ„í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸
==============================================================================

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì¬ë¬´ì œí‘œ ë°ì´í„°ì™€ ì‹œì¥ ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ ë¶€ë„ì˜ˆì¸¡ ëª¨ë¸ë§ì— 
ì í•©í•œ ë°ì´í„°ì…‹ì„ ë§Œë“¤ê¸° ìœ„í•œ ì¢…í•©ì ì¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì…ë ¥ íŒŒì¼:
- FS2.csv: ë§ˆìŠ¤í„° ì¬ë¬´ì œí‘œ íŒŒì¼
- 2012.csv ~ 2023.csv: ì—°ë„ë³„ ì£¼ê°€/ì‹œì¥ ë°ì´í„° íŒŒì¼
- ì‹œê°€ì´ì•¡.csv: ì‹œê°€ì´ì•¡ ë°ì´í„°

ì¶œë ¥:
- FS2_features.csv: ì—”ì§€ë‹ˆì–´ë§ëœ í”¼ì²˜ë“¤ì„ í¬í•¨í•œ ê²°í•© ë°ì´í„°ì…‹
"""

import pandas as pd
import numpy as np
import glob
import os
from pathlib import Path
import warnings

def safe_divide(numerator, denominator, default=np.nan, outlier_threshold=1000):
    """
    ì•ˆì „í•œ ë‚˜ëˆ—ì…ˆ í•¨ìˆ˜ - 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€ ë° ì´ìƒì¹˜ ì²˜ë¦¬
    
    Args:
        numerator: ë¶„ì
        denominator: ë¶„ëª¨
        default: ë¶„ëª¨ê°€ 0ì¼ ë•Œ ë°˜í™˜í•  ê¸°ë³¸ê°’
        outlier_threshold: ì´ìƒì¹˜ë¡œ ê°„ì£¼í•  ì ˆëŒ“ê°’ ì„ê³„ì¹˜
        
    Returns:
        ì•ˆì „í•˜ê²Œ ê³„ì‚°ëœ ë¹„ìœ¨ (ì´ìƒì¹˜ëŠ” NaN ì²˜ë¦¬)
    """
    # numpy ë°°ì—´ë¡œ ë³€í™˜
    num = np.asarray(numerator)
    den = np.asarray(denominator)
    
    # ë¶„ëª¨ê°€ 0ì´ê±°ë‚˜ ë§¤ìš° ì‘ì€ ê²½ìš° ì²˜ë¦¬
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", RuntimeWarning)
        result = np.where(
            (den == 0) | (np.abs(den) < 1e-10), 
            default, 
            num / den
        )
    
    # ì´ìƒì¹˜ ì²˜ë¦¬ (ì ˆëŒ“ê°’ì´ ì„ê³„ì¹˜ë³´ë‹¤ í° ê²½ìš°)
    result = np.where(np.abs(result) > outlier_threshold, np.nan, result)
    
    # inf, -inf ì²˜ë¦¬
    result = np.where(np.isinf(result), np.nan, result)
    
    return result

def validate_features(df):
    """
    í”¼ì²˜ í’ˆì§ˆ ê²€ì¦ ë° ë¦¬í¬íŠ¸ ìƒì„±
    
    Args:
        df: ê²€ì¦í•  DataFrame
        
    Returns:
        validation_report: ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print("í”¼ì²˜ í’ˆì§ˆ ê²€ì¦ ì¤‘...")
    
    validation_report = {
        'negative_assets': [],
        'extreme_ratios': [],
        'high_missing_rate': [],
        'suspicious_values': []
    }
    
    # 1. ìŒìˆ˜ê°€ ë˜ë©´ ì•ˆ ë˜ëŠ” ê°’ë“¤ ì²´í¬
    asset_cols = ['ì´ìì‚°', 'ìœ ë™ìì‚°', 'ë¹„ìœ ë™ìì‚°', 'ìœ í˜•ìì‚°', 'ë¬´í˜•ìì‚°', 
                  'ì¬ê³ ìì‚°', 'í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°', 'ì‹œê°€ì´ì•¡']
    
    for col in asset_cols:
        if col in df.columns:
            negative_count = (df[col] < 0).sum()
            if negative_count > 0:
                validation_report['negative_assets'].append({
                    'column': col,
                    'negative_count': negative_count,
                    'percentage': negative_count / len(df) * 100
                })
    
    # 2. ê·¹ë‹¨ì ì¸ ë¹„ìœ¨ ì²´í¬
    ratio_thresholds = {
        'ì´ìì‚°ìˆ˜ìµë¥ (ROA)': (-1, 1),        # -100% ~ 100%
        'ìê¸°ìë³¸ìˆ˜ìµë¥ (ROE)': (-3, 3),       # -300% ~ 300%
        'ë¶€ì±„ìì‚°ë¹„ìœ¨': (0, 2),               # 0% ~ 200%
        'ìœ ë™ë¹„ìœ¨': (0, 50),                  # 0 ~ 50ë°°
        'PER': (-1000, 1000),                # -1000 ~ 1000ë°°
        'PBR': (0, 100),                     # 0 ~ 100ë°°
        'ì´ìì‚°íšŒì „ìœ¨': (0, 10)               # 0 ~ 10íšŒ
    }
    
    for col, (min_val, max_val) in ratio_thresholds.items():
        if col in df.columns:
            out_of_range = ((df[col] < min_val) | (df[col] > max_val)).sum()
            if out_of_range > 0:
                validation_report['extreme_ratios'].append({
                    'column': col,
                    'out_of_range_count': out_of_range,
                    'percentage': out_of_range / len(df) * 100,
                    'range': (min_val, max_val)
                })
    
    # 3. ë†’ì€ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ ì²´í¬ (80% ì´ìƒ)
    missing_rates = df.isnull().sum() / len(df) * 100
    high_missing = missing_rates[missing_rates > 80]
    
    for col in high_missing.index:
        validation_report['high_missing_rate'].append({
            'column': col,
            'missing_percentage': high_missing[col]
        })
    
    # 4. ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê°’ë“¤ ì²´í¬
    suspicious_patterns = {
        'ì´ìì‚°ì´ 0ì¸ ê²½ìš°': (df.get('ì´ìì‚°', pd.Series()) == 0).sum(),
        'ë§¤ì¶œì•¡ì´ ìŒìˆ˜ì¸ ê²½ìš°': (df.get('ë§¤ì¶œì•¡', pd.Series()) < 0).sum(),
        'ì‹œê°€ì´ì•¡ì´ 0ì¸ ê²½ìš°': (df.get('ì‹œê°€ì´ì•¡', pd.Series()) == 0).sum()
    }
    
    for pattern, count in suspicious_patterns.items():
        if count > 0:
            validation_report['suspicious_values'].append({
                'pattern': pattern,
                'count': count,
                'percentage': count / len(df) * 100
            })
    
    # ê²€ì¦ ê²°ê³¼ ì¶œë ¥
    print("\n=== í”¼ì²˜ í’ˆì§ˆ ê²€ì¦ ê²°ê³¼ ===")
    
    if validation_report['negative_assets']:
        print("\nâš ï¸ ìŒìˆ˜ ìì‚° ë°œê²¬:")
        for item in validation_report['negative_assets']:
            print(f"  - {item['column']}: {item['negative_count']}ê°œ ({item['percentage']:.2f}%)")
    
    if validation_report['extreme_ratios']:
        print("\nâš ï¸ ê·¹ë‹¨ì ì¸ ë¹„ìœ¨ ë°œê²¬:")
        for item in validation_report['extreme_ratios']:
            print(f"  - {item['column']}: {item['out_of_range_count']}ê°œ ({item['percentage']:.2f}%) "
                  f"ë²”ìœ„ ì™¸: {item['range']}")
    
    if validation_report['high_missing_rate']:
        print("\nâš ï¸ ë†’ì€ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ (>80%):")
        for item in validation_report['high_missing_rate']:
            print(f"  - {item['column']}: {item['missing_percentage']:.2f}%")
    
    if validation_report['suspicious_values']:
        print("\nâš ï¸ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê°’ë“¤:")
        for item in validation_report['suspicious_values']:
            print(f"  - {item['pattern']}: {item['count']}ê°œ ({item['percentage']:.2f}%)")
    
    if not any(validation_report.values()):
        print("âœ… ëª¨ë“  í”¼ì²˜ê°€ í’ˆì§ˆ ê¸°ì¤€ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
    
    return validation_report



def load_and_merge_data():
    """
    ëª¨ë“  ì…ë ¥ ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë³‘í•©
    """
    print("ë°ì´í„° íŒŒì¼ ë¡œë”© ì¤‘...")
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
    current_dir = Path(__file__).parent
    project_root = current_dir.parent.parent  # src/data_processing -> src -> project_root
    
    # FS2.csv ë¡œë“œ
    fs2_path = project_root / "data" / "processed" / "FS2.csv"
    if fs2_path.exists():
        df = pd.read_csv(fs2_path, encoding='utf-8-sig')
    else:
        # ëŒ€ì•ˆ ê²½ë¡œ ì‹œë„
        fs2_path = project_root / "FS2.csv"
        df = pd.read_csv(fs2_path, encoding='utf-8-sig')
    
    # íšŒê³„ë…„ë„ë¥¼ ì—°ë„ë¡œ í†µì¼
    if 'íšŒê³„ë…„ë„' in df.columns:
        df = df.rename(columns={'íšŒê³„ë…„ë„': 'ì—°ë„'})
    
    # ê±°ë˜ì†Œì½”ë“œë¥¼ ë¬¸ìí˜•ìœ¼ë¡œ í†µì¼ (ë³‘í•© ë¬¸ì œ í•´ê²°)
    df['ê±°ë˜ì†Œì½”ë“œ'] = df['ê±°ë˜ì†Œì½”ë“œ'].astype(str)
    
    print(f"FS2.csv ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰")
    print(f"FS2 ì—°ë„ ë²”ìœ„: {df['ì—°ë„'].min()} ~ {df['ì—°ë„'].max()}")
    print(f"FS2 ê±°ë˜ì†Œì½”ë“œ ìƒ˜í”Œ: {df['ê±°ë˜ì†Œì½”ë“œ'].head().values}")
    
    # ì—°ë„ë³„ ì£¼ê°€ íŒŒì¼ ë¡œë“œ (2012.csv ~ 2023.csv)
    yearly_data = []
    data_dir = project_root / "data" / "raw"
    if not data_dir.exists():
        data_dir = project_root
    
    for year in range(2012, 2024):
        year_file = data_dir / f"{year}.csv"
        if year_file.exists():
            year_df = pd.read_csv(year_file, encoding='utf-8-sig')
            
            # ì‹¤ì œ ì»¬ëŸ¼ëª… í™•ì¸ ë° í‘œì¤€í™” (ì²« ë²ˆì§¸ íŒŒì¼ë§Œ ì¶œë ¥)
            if year == 2012:
                print(f"ì—°ë„ë³„ íŒŒì¼ ì»¬ëŸ¼: {list(year_df.columns)}")
                print(f"ì£¼ê°€ ë°ì´í„° íšŒê³„ë…„ë„ ìƒ˜í”Œ: {year_df['íšŒê³„ë…„ë„'].head().values}")
            
            # ê±°ë˜ì†Œì½”ë“œë¥¼ ë¬¸ìí˜•ìœ¼ë¡œ í†µì¼
            year_df['ê±°ë˜ì†Œì½”ë“œ'] = year_df['ê±°ë˜ì†Œì½”ë“œ'].astype(str)
            
            # ì»¬ëŸ¼ëª… ë§¤í•‘ (ì£¼ê°€ íŒŒì¼ì—ì„œ íšŒê³„ë…„ë„ëŠ” ì‹¤ì œë¡œëŠ” ê±°ë˜ì¼ìì„)
            column_mapping = {
                'ë§¤ë§¤ë…„ì›”ì¼': 'ì¼ì',
                'ì¢…ëª©ì½”ë“œ(ì¶•ì•½)': 'ì¢…ëª©ì½”ë“œ',
                'ì‹œê°€ì´ì•¡(ì›)': 'ì‹œê°€ì´ì•¡_temp',
                'ìƒì¥ì£¼ì‹ìˆ˜(ì£¼)': 'ìƒì¥ì£¼ì‹ìˆ˜',
                'ì¢…ê°€(ì›)': 'ì¢…ê°€',
                'ê±°ë˜ëŸ‰(ì£¼)': 'ê±°ë˜ëŸ‰'
                # íšŒê³„ë…„ë„ëŠ” ê±°ë˜ì¼ìì´ë¯€ë¡œ ì œì™¸
            }
            
            # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë§¤í•‘
            available_mapping = {old: new for old, new in column_mapping.items() if old in year_df.columns}
            year_df = year_df.rename(columns=available_mapping)
            
            # ì¼ì ì»¬ëŸ¼ ì„¤ì • (ë§¤ë§¤ë…„ì›”ì¼ ë˜ëŠ” íšŒê³„ë…„ë„ ì‚¬ìš©)
            if 'ì¼ì' not in year_df.columns:
                if 'ë§¤ë§¤ë…„ì›”ì¼' in year_df.columns:
                    year_df['ì¼ì'] = year_df['ë§¤ë§¤ë…„ì›”ì¼']
                elif 'íšŒê³„ë…„ë„' in year_df.columns:
                    year_df['ì¼ì'] = year_df['íšŒê³„ë…„ë„']
                else:
                    year_df['ì¼ì'] = pd.to_datetime(f'{year}-12-31')
            
            # íŒŒì¼ëª…ì—ì„œ ì—°ë„ ì¶”ì¶œ (ê°€ì¥ ì¤‘ìš”!)
            year_df['ì—°ë„'] = year
            
            # ì—°ë§ ë°ì´í„° ì¶”ì¶œ (ë§ˆì§€ë§‰ ê±°ë˜ì¼)
            year_df['ì¼ì'] = pd.to_datetime(year_df['ì¼ì'])
            
            # ê±°ë˜ì†Œì½”ë“œë³„ë¡œ ë§ˆì§€ë§‰ ê±°ë˜ì¼ ë°ì´í„° ì„ íƒ
            if 'ê±°ë˜ì†Œì½”ë“œ' in year_df.columns:
                year_end_df = year_df.loc[year_df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì¼ì'].idxmax()].copy()
            else:
                # ê±°ë˜ì†Œì½”ë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ë‚ ì§œë§Œ ì„ íƒ
                max_date = year_df['ì¼ì'].max()
                year_end_df = year_df[year_df['ì¼ì'] == max_date].copy()
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ ì„ íƒ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
            price_cols = ['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„', 'ì¢…ê°€', 'ê±°ë˜ëŸ‰', 'ìƒì¥ì£¼ì‹ìˆ˜']
            available_cols = [col for col in price_cols if col in year_end_df.columns]
            
            # ì£¼ë‹¹ë°°ë‹¹ê¸ˆì´ ìˆë‹¤ë©´ ì¶”ê°€
            if 'ì£¼ë‹¹ë°°ë‹¹ê¸ˆ' in year_end_df.columns:
                available_cols.append('ì£¼ë‹¹ë°°ë‹¹ê¸ˆ')
            
            if available_cols and len(year_end_df) > 0:
                yearly_data.append(year_end_df[available_cols])
                print(f"{year}.csv ë¡œë“œ ì™„ë£Œ: {len(year_end_df)} ê¸°ì—…")
                
                # ì²« ë²ˆì§¸ ì—°ë„ì—ì„œ ë°ì´í„° í™•ì¸
                if year == 2012:
                    print(f"  ê±°ë˜ì†Œì½”ë“œ ìƒ˜í”Œ: {year_end_df['ê±°ë˜ì†Œì½”ë“œ'].head().values}")
                    print(f"  ì—°ë„ í™•ì¸: {year_end_df['ì—°ë„'].unique()}")
    
    # ëª¨ë“  ì—°ë„ë³„ ë°ì´í„° ê²°í•©
    if yearly_data:
        price_df = pd.concat(yearly_data, ignore_index=True)
        
        # ë°ì´í„° íƒ€ì… í†µì¼
        price_df['ì—°ë„'] = pd.to_numeric(price_df['ì—°ë„'], errors='coerce').astype('Int64')
        df['ì—°ë„'] = pd.to_numeric(df['ì—°ë„'], errors='coerce').astype('Int64')
        
        print(f"ê²°í•©ëœ ì£¼ê°€ ë°ì´í„°: {len(price_df)} í–‰")
        print(f"ì£¼ê°€ ë°ì´í„° ì—°ë„ ë²”ìœ„: {price_df['ì—°ë„'].min()} ~ {price_df['ì—°ë„'].max()}")
        
        # ë³‘í•© ì „ ê³µí†µ í‚¤ í™•ì¸
        fs2_keys = set(df[['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„']].apply(tuple, axis=1))
        price_keys = set(price_df[['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„']].apply(tuple, axis=1))
        common_keys = fs2_keys.intersection(price_keys)
        
        print(f"FS2 í‚¤ ê°œìˆ˜: {len(fs2_keys)}")
        print(f"ì£¼ê°€ ë°ì´í„° í‚¤ ê°œìˆ˜: {len(price_keys)}")
        print(f"ê³µí†µ í‚¤ ê°œìˆ˜: {len(common_keys)}")
        
        # FS2ì™€ ë³‘í•©
        if 'ê±°ë˜ì†Œì½”ë“œ' in price_df.columns and 'ê±°ë˜ì†Œì½”ë“œ' in df.columns:
            df = df.merge(price_df, on=['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„'], how='left')
            print(f"ì£¼ê°€ ë°ì´í„° ë³‘í•© í›„: {len(df)} í–‰")
            
            # ë³‘í•© ê²°ê³¼ í™•ì¸
            merged_price_data = df[['ì¢…ê°€', 'ê±°ë˜ëŸ‰', 'ìƒì¥ì£¼ì‹ìˆ˜']].notna().sum()
            print(f"ë³‘í•©ëœ ì£¼ê°€ ë°ì´í„° ê°œìˆ˜:")
            for col, count in merged_price_data.items():
                print(f"  {col}: {count}ê°œ ({count/len(df)*100:.2f}%)")
        else:
            print("âš ï¸ ê±°ë˜ì†Œì½”ë“œ ì»¬ëŸ¼ì´ ì—†ì–´ ì£¼ê°€ ë°ì´í„° ë³‘í•©ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # ì‹œê°€ì´ì•¡ ë°ì´í„° ì²˜ë¦¬ (ìš°ì„ ì£¼ í¬í•¨í•œ ì •í™•í•œ ì‹œê°€ì´ì•¡ ì‚¬ìš©)
    print("ì‹œê°€ì´ì•¡ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
    
    # ê¸°ì¡´ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì œê±° (ì‹œê°€ì´ì•¡.csvì˜ ì •í™•í•œ ê°’ ì‚¬ìš©ì„ ìœ„í•´)
    if 'ì‹œê°€ì´ì•¡' in df.columns:
        original_na_count = df['ì‹œê°€ì´ì•¡'].isna().sum()
        df = df.drop(columns=['ì‹œê°€ì´ì•¡'])
        print(f"âš ï¸ ê¸°ì¡´ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ì œê±° (ê²°ì¸¡ì¹˜ {original_na_count:,}ê°œ í¬í•¨)")
    
    # ì‹œê°€ì´ì•¡.csv íŒŒì¼ ë¡œë“œ (ìš°ì„ ì£¼ í¬í•¨í•œ ì •í™•í•œ ì‹œê°€ì´ì•¡)
    market_cap_path = project_root / "data" / "processed" / "ì‹œê°€ì´ì•¡.csv"
    if not market_cap_path.exists():
        market_cap_path = project_root / "ì‹œê°€ì´ì•¡.csv"
    
    market_cap_loaded = False
    if market_cap_path.exists():
        try:
            market_cap_df = pd.read_csv(market_cap_path, encoding='utf-8-sig')
            if 'íšŒê³„ë…„ë„' in market_cap_df.columns:
                market_cap_df = market_cap_df.rename(columns={'íšŒê³„ë…„ë„': 'ì—°ë„'})
            
            # ê±°ë˜ì†Œì½”ë“œ íƒ€ì… í†µì¼
            market_cap_df['ê±°ë˜ì†Œì½”ë“œ'] = market_cap_df['ê±°ë˜ì†Œì½”ë“œ'].astype(str)
            
            # ë°ì´í„° íƒ€ì… í†µì¼
            if 'ì—°ë„' in market_cap_df.columns:
                market_cap_df['ì—°ë„'] = pd.to_numeric(market_cap_df['ì—°ë„'], errors='coerce').astype('Int64')
            
            if 'ê±°ë˜ì†Œì½”ë“œ' in market_cap_df.columns and 'ê±°ë˜ì†Œì½”ë“œ' in df.columns:
                df = df.merge(market_cap_df[['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„', 'ì‹œê°€ì´ì•¡']], 
                             on=['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„'], how='left')
                market_cap_loaded = True
                print(f"âœ… ì‹œê°€ì´ì•¡.csv ë°ì´í„° ë³‘í•© ì™„ë£Œ: {len(df)} í–‰")
                
                # ë³‘í•© í›„ ì‹œê°€ì´ì•¡ í†µê³„
                total_count = len(df)
                valid_count = df['ì‹œê°€ì´ì•¡'].notna().sum()
                print(f"   ì‹œê°€ì´ì•¡ ë°ì´í„°: {valid_count:,}/{total_count:,} ({valid_count/total_count*100:.1f}%)")
                
        except Exception as e:
            print(f"âš ï¸ ì‹œê°€ì´ì•¡.csv ë¡œë”© ì‹¤íŒ¨: {e}")
    
    if not market_cap_loaded:
        print("âš ï¸ ì‹œê°€ì´ì•¡.csvë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        # ë¹ˆ ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ìƒì„±
        df['ì‹œê°€ì´ì•¡'] = np.nan
    
    # ì‹œê°€ì´ì•¡ ê²°ì¸¡ì¹˜ ë³´ì™„ (ì¢…ê°€ Ã— ìƒì¥ì£¼ì‹ìˆ˜ ë˜ëŠ” ë°œí–‰ì£¼ì‹ì´ìˆ˜)
    missing_cap = df['ì‹œê°€ì´ì•¡'].isna()
    missing_count = missing_cap.sum()
    
    if missing_count > 0:
        print(f"âš ï¸ ì‹œê°€ì´ì•¡ ê²°ì¸¡ì¹˜ {missing_count:,}ê°œ ë°œê²¬ - ë³´ê°„ ì‹œë„")
        
        # ìƒì¥ì£¼ì‹ìˆ˜ë¥¼ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ë°œí–‰ì£¼ì‹ì´ìˆ˜ ì‚¬ìš©
        share_col = None
        if 'ìƒì¥ì£¼ì‹ìˆ˜' in df.columns:
            share_col = 'ìƒì¥ì£¼ì‹ìˆ˜'
        elif 'ë°œí–‰ì£¼ì‹ì´ìˆ˜' in df.columns:
            share_col = 'ë°œí–‰ì£¼ì‹ì´ìˆ˜'
        
        if 'ì¢…ê°€' in df.columns and share_col:
            # ì¢…ê°€ì™€ ì£¼ì‹ìˆ˜ê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš°ë§Œ ê³„ì‚°
            calc_mask = missing_cap & df['ì¢…ê°€'].notna() & df[share_col].notna()
            df.loc[calc_mask, 'ì‹œê°€ì´ì•¡'] = df.loc[calc_mask, 'ì¢…ê°€'] * df.loc[calc_mask, share_col]
            filled_count = calc_mask.sum()
            print(f"âœ… ì¢…ê°€ Ã— {share_col}ë¡œ {filled_count:,}ê°œ ê°’ ë³´ê°„ ì™„ë£Œ")
            
            # ìµœì¢… ê²°ì¸¡ì¹˜ í™•ì¸
            final_missing = df['ì‹œê°€ì´ì•¡'].isna().sum()
            if final_missing > 0:
                print(f"âš ï¸ ìµœì¢… ì‹œê°€ì´ì•¡ ê²°ì¸¡ì¹˜: {final_missing:,}ê°œ")
        else:
            print(f"âŒ ì‹œê°€ì´ì•¡ ë³´ê°„ ë¶ˆê°€: ì¢…ê°€ ë˜ëŠ” ì£¼ì‹ìˆ˜ ë°ì´í„° ë¶€ì¡±")
    else:
        print("âœ… ì‹œê°€ì´ì•¡ ê²°ì¸¡ì¹˜ ì—†ìŒ")
    
    # ê±°ë˜ì†Œì½”ë“œ, ì—°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    df = df.sort_values(['ê±°ë˜ì†Œì½”ë“œ', 'ì—°ë„']).reset_index(drop=True)
    
    return df

def create_balance_sheet_averages(df):
    """
    ì ì ˆí•œ í”Œë¡œìš° ì»¨ë²¤ì…˜ì„ ìœ„í•œ ëŒ€ì°¨ëŒ€ì¡°í‘œ í•­ëª©ë“¤ì˜ í‰ê· ê°’ ìƒì„±
    """
    print("ëŒ€ì°¨ëŒ€ì¡°í‘œ í”Œë¡œìš° í‰ê· ê°’ ìƒì„± ì¤‘...")
    
    bs_cols = [
        'ì´ìì‚°','ìœ ë™ìì‚°','ìœ í˜•ìì‚°','ë¬´í˜•ìì‚°','ì¬ê³ ìì‚°','í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°',
        'ë¹„ìœ ë™ìì‚°','ì´ìë³¸','ë°œí–‰ì£¼ì‹ì´ìˆ˜','ì´ë¶€ì±„','ìœ ë™ë¶€ì±„','ë¹„ìœ ë™ë¶€ì±„',
        'ì¥ê¸°ì°¨ì…ê¸ˆ','ë‹¨ê¸°ì°¨ì…ê¸ˆ','ë§¤ì¶œì±„ê¶Œ','ë§¤ì…ì±„ë¬´','ì„ ìˆ˜ìˆ˜ìµ',
        'ê¸°íƒ€ìœ ë™ë¶€ì±„','ê¸°íƒ€ìœ ë™ìì‚°','(ê¸ˆìœµ)ë¦¬ìŠ¤ë¶€ì±„','ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ(ê¸ˆìœµê¸°ê´€ì˜ˆì¹˜ê¸ˆ)',
        'ìë³¸ê¸ˆ','ê¸°íƒ€í¬ê´„ì†ìµëˆ„ê³„ì•¡'
    ]
    
    # ëŒ€ì°¨ëŒ€ì¡°í‘œ í•­ëª©ë“¤ì— ëŒ€í•œ avg_ ì»¬ëŸ¼ ìƒì„±
    for col in bs_cols:
        if col in df.columns:
            df[f'avg_{col}'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')[col].transform(
                lambda x: (x + x.shift(1)) / 2
            )
    
    return df

def create_growth_features(df):
    """
    ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥  í”¼ì²˜ ìƒì„±
    """
    print("ì„±ì¥ë¥  í”¼ì²˜ ìƒì„± ì¤‘...")
    
    growth_cols = ['ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ì´ìì‚°', 'ì´ë¶€ì±„', 'ì˜ì—…í˜„ê¸ˆíë¦„']
    
    for col in growth_cols:
        if col in df.columns:
            df[f'{col}ì¦ê°€ìœ¨'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')[col].pct_change()
    
    return df

def create_liquidity_leverage_features(df):
    """
    ìœ ë™ì„± ë° ë ˆë²„ë¦¬ì§€ ë¹„ìœ¨ ìƒì„± (B/S vs B/S, ê¸°ë§ ì”ì•¡ ì‚¬ìš©)
    """
    print("ìœ ë™ì„± ë° ë ˆë²„ë¦¬ì§€ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # ìœ ë™ì„± ë¹„ìœ¨
    if 'ìœ ë™ìì‚°' in df.columns and 'ìœ ë™ë¶€ì±„' in df.columns:
        df['ìœ ë™ë¹„ìœ¨'] = safe_divide(df['ìœ ë™ìì‚°'], df['ìœ ë™ë¶€ì±„'], outlier_threshold=100)
        df['ë‹¹ì¢Œë¹„ìœ¨'] = safe_divide(
            df['ìœ ë™ìì‚°'] - df.get('ì¬ê³ ìì‚°', 0), 
            df['ìœ ë™ë¶€ì±„'], 
            outlier_threshold=100
        )
        df['ìš´ì „ìë³¸'] = df['ìœ ë™ìì‚°'] - df['ìœ ë™ë¶€ì±„']
    
    # ë ˆë²„ë¦¬ì§€ ë¹„ìœ¨
    if 'ì´ë¶€ì±„' in df.columns and 'ì´ìì‚°' in df.columns:
        df['ë¶€ì±„ìì‚°ë¹„ìœ¨'] = safe_divide(df['ì´ë¶€ì±„'], df['ì´ìì‚°'], outlier_threshold=10)
    
    if 'ì´ë¶€ì±„' in df.columns and 'ì´ìë³¸' in df.columns:
        df['ë¶€ì±„ìë³¸ë¹„ìœ¨'] = safe_divide(df['ì´ë¶€ì±„'], df['ì´ìë³¸'], outlier_threshold=50)
        df['ë¶€ì±„ì´ìë³¸ë¹„ìœ¨'] = safe_divide(
            df['ì´ë¶€ì±„'], 
            df['ì´ë¶€ì±„'] + df['ì´ìë³¸'], 
            outlier_threshold=1
        )
    
    if 'ì´ìë³¸' in df.columns and 'ì´ìì‚°' in df.columns:
        df['ìë³¸ë¹„ìœ¨'] = safe_divide(df['ì´ìë³¸'], df['ì´ìì‚°'], outlier_threshold=10)
    
    # ì´ìë¶€ë‹´ë¶€ì±„ ë¹„ìœ¨
    debt_cols = ['ë‹¨ê¸°ì°¨ì…ê¸ˆ', 'ì¥ê¸°ì°¨ì…ê¸ˆ']
    if all(col in df.columns for col in debt_cols) and 'ì´ìì‚°' in df.columns:
        df['ì´ìë¶€ë‹´ì°¨ì…ê¸ˆë¹„ìœ¨'] = safe_divide(
            df['ë‹¨ê¸°ì°¨ì…ê¸ˆ'] + df['ì¥ê¸°ì°¨ì…ê¸ˆ'], 
            df['ì´ìì‚°'], 
            outlier_threshold=10
        )
    
    if 'ì¥ê¸°ì°¨ì…ê¸ˆ' in df.columns and all(col in df.columns for col in ['ì´ë¶€ì±„', 'ì´ìë³¸']):
        df['ì¥ê¸°ì°¨ì…ê¸ˆìë³¸ë¹„ìœ¨'] = safe_divide(
            df['ì¥ê¸°ì°¨ì…ê¸ˆ'], 
            df['ì´ë¶€ì±„'] + df['ì´ìë³¸'], 
            outlier_threshold=5
        )
    
    # ì˜ì—…ìš´ì „ìë³¸ ë³€í˜•
    working_capital_cols = ['ë§¤ì¶œì±„ê¶Œ', 'ì¬ê³ ìì‚°', 'ê¸°íƒ€ìœ ë™ìì‚°', 'ë§¤ì…ì±„ë¬´', 'ì„ ìˆ˜ìˆ˜ìµ', 'ê¸°íƒ€ìœ ë™ë¶€ì±„']
    if all(col in df.columns for col in working_capital_cols):
        df['ì˜ì—…ìš´ì „ìë³¸'] = (df['ë§¤ì¶œì±„ê¶Œ'] + df['ì¬ê³ ìì‚°'] + df['ê¸°íƒ€ìœ ë™ìì‚°']) - \
                          (df['ë§¤ì…ì±„ë¬´'] + df['ì„ ìˆ˜ìˆ˜ìµ'] + df['ê¸°íƒ€ìœ ë™ë¶€ì±„'])
    
    # íˆ¬í•˜ìë³¸
    cash_cols = ['í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°', 'ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ(ê¸ˆìœµê¸°ê´€ì˜ˆì¹˜ê¸ˆ)']
    if all(col in df.columns for col in ['ì´ë¶€ì±„', 'ì´ìë³¸']) and any(col in df.columns for col in cash_cols):
        cash_sum = sum(df.get(col, 0) for col in cash_cols if col in df.columns)
        df['íˆ¬í•˜ìë³¸'] = df['ì´ë¶€ì±„'] + df['ì´ìë³¸'] - cash_sum
    
    # ê²½ì˜ìë³¸
    if all(col in df.columns for col in ['ìœ í˜•ìì‚°', 'ë¬´í˜•ìì‚°']) and 'ì˜ì—…ìš´ì „ìë³¸' in df.columns:
        df['ê²½ì˜ìë³¸'] = df['ìœ í˜•ìì‚°'] + df['ë¬´í˜•ìì‚°'] + df['ì˜ì—…ìš´ì „ìë³¸']
    
    return df

def create_additional_balance_sheet_averages(df):
    """
    í”¼ì²˜ ìƒì„± ê³¼ì •ì—ì„œ ìƒˆë¡œ ë§Œë“¤ì–´ì§„ ëŒ€ì°¨ëŒ€ì¡°í‘œ í•­ëª©ë“¤ì˜ í‰ê· ê°’ ìƒì„±
    """
    print("ì¶”ê°€ ëŒ€ì°¨ëŒ€ì¡°í‘œ í•­ëª© í‰ê· ê°’ ìƒì„± ì¤‘...")
    
    # ìƒˆë¡œ ìƒì„±ëœ BS í•­ëª©ë“¤ (í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê³¼ì •ì—ì„œ ìƒì„±)
    additional_bs_items = ['íˆ¬í•˜ìë³¸', 'ê²½ì˜ìë³¸', 'ìš´ì „ìë³¸', 'ì˜ì—…ìš´ì „ìë³¸']
    
    # ì¶”ê°€ BS í•­ëª©ë“¤ì— ëŒ€í•œ avg_ ì»¬ëŸ¼ ìƒì„±
    created_count = 0
    for col in additional_bs_items:
        if col in df.columns:
            avg_col_name = f'avg_{col}'
            if avg_col_name not in df.columns:  # ì¤‘ë³µ ìƒì„± ë°©ì§€
                df[avg_col_name] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')[col].transform(
                    lambda x: (x + x.shift(1)) / 2
                )
                created_count += 1
                print(f"  ìƒì„±ë¨: {avg_col_name}")
    
    if created_count == 0:
        print("  ìƒˆë¡œ ìƒì„±í•  í‰ê·  BS í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"  ì´ {created_count}ê°œ ì¶”ê°€ í‰ê·  BS í•­ëª© ìƒì„± ì™„ë£Œ")
    
    return df

def create_profitability_features(df):
    """
    ìˆ˜ìµì„± ë° í˜„ê¸ˆíë¦„ ë¹„ìœ¨ ìƒì„± (I/S ë˜ëŠ” C/F vs avg_B/S)
    """
    print("ìˆ˜ìµì„± í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # ROA, ROE
    if 'ë‹¹ê¸°ìˆœì´ìµ' in df.columns:
        if 'avg_ì´ìì‚°' in df.columns:
            df['ì´ìì‚°ìˆ˜ìµë¥ (ROA)'] = safe_divide(df['ë‹¹ê¸°ìˆœì´ìµ'], df['avg_ì´ìì‚°'], outlier_threshold=5)
        if 'avg_ì´ìë³¸' in df.columns:
            df['ìê¸°ìë³¸ìˆ˜ìµë¥ (ROE)'] = safe_divide(df['ë‹¹ê¸°ìˆœì´ìµ'], df['avg_ì´ìë³¸'], outlier_threshold=10)
    
    # ìì‚°íšŒì „ìœ¨
    if 'ë§¤ì¶œì•¡' in df.columns and 'avg_ì´ìì‚°' in df.columns:
        df['ì´ìì‚°íšŒì „ìœ¨'] = safe_divide(df['ë§¤ì¶œì•¡'], df['avg_ì´ìì‚°'], outlier_threshold=20)
    
    # ë¶€ì±„ì»¤ë²„ë¦¬ì§€ ë¹„ìœ¨
    if 'ì˜ì—…ì´ìµ' in df.columns:
        debt_avg_cols = ['avg_ë‹¨ê¸°ì°¨ì…ê¸ˆ', 'avg_ì¥ê¸°ì°¨ì…ê¸ˆ']
        if all(col in df.columns for col in debt_avg_cols):
            total_debt = df['avg_ë‹¨ê¸°ì°¨ì…ê¸ˆ'] + df['avg_ì¥ê¸°ì°¨ì…ê¸ˆ']
            df['ì˜ì—…ì´ìµëŒ€ì°¨ì…ê¸ˆë¹„ìœ¨'] = safe_divide(df['ì˜ì—…ì´ìµ'], total_debt, outlier_threshold=100)
    
    # EBITDA ì»¤ë²„ë¦¬ì§€
    ebitda_cols = ['ì˜ì—…ì´ìµ', 'ê°ê°€ìƒê°ë¹„', 'ë¬´í˜•ìì‚°ìƒê°ë¹„']
    if all(col in df.columns for col in ebitda_cols):
        ebitda = df['ì˜ì—…ì´ìµ'] + df['ê°ê°€ìƒê°ë¹„'] + df['ë¬´í˜•ìì‚°ìƒê°ë¹„']
        debt_avg_cols = ['avg_ë‹¨ê¸°ì°¨ì…ê¸ˆ', 'avg_ì¥ê¸°ì°¨ì…ê¸ˆ']
        if all(col in df.columns for col in debt_avg_cols):
            total_debt = df['avg_ë‹¨ê¸°ì°¨ì…ê¸ˆ'] + df['avg_ì¥ê¸°ì°¨ì…ê¸ˆ']
            df['EBITDAëŒ€ì°¨ì…ê¸ˆë¹„ìœ¨'] = safe_divide(ebitda, total_debt, outlier_threshold=100)
    
    # í˜„ê¸ˆíë¦„ ë¹„ìœ¨
    if 'ì˜ì—…í˜„ê¸ˆíë¦„' in df.columns and 'avg_ì´ë¶€ì±„' in df.columns:
        df['í˜„ê¸ˆíë¦„ëŒ€ë¶€ì±„ë¹„ìœ¨'] = safe_divide(df['ì˜ì—…í˜„ê¸ˆíë¦„'], df['avg_ì´ë¶€ì±„'], outlier_threshold=5)
    
    # ROIC
    if 'ì˜ì—…ì´ìµ' in df.columns and 'avg_íˆ¬í•˜ìë³¸' in df.columns:
        df['íˆ¬í•˜ìë³¸ìˆ˜ìµë¥ (ROIC)'] = safe_divide(df['ì˜ì—…ì´ìµ'], df['avg_íˆ¬í•˜ìë³¸'], outlier_threshold=5)
    
    return df

def create_leverage_metrics(df):
    """
    ì§€ì •ëœ ëŒ€ë¡œ DOLê³¼ DFL ë ˆë²„ë¦¬ì§€ ì§€í‘œë§Œ ìƒì„±
    """
    print("ë ˆë²„ë¦¬ì§€ ì§€í‘œ ìƒì„± ì¤‘ (DOLê³¼ DFLë§Œ)...")
    
    # DOL - ì˜ì—…ë ˆë²„ë¦¬ì§€
    if all(col in df.columns for col in ['ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ']):
        # ì„±ì¥ë¥ ì´ create_growth_featuresì—ì„œ ì´ë¯¸ ìƒì„±ë˜ì–´ì•¼ í•¨
        if 'ë§¤ì¶œì•¡ì¦ê°€ìœ¨' in df.columns and 'ì˜ì—…ì´ìµì¦ê°€ìœ¨' in df.columns:
            df['DOL'] = safe_divide(df['ì˜ì—…ì´ìµì¦ê°€ìœ¨'], df['ë§¤ì¶œì•¡ì¦ê°€ìœ¨'], outlier_threshold=50)
        else:
            # ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
            df['ë§¤ì¶œì•¡ì¦ê°€ìœ¨'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ë§¤ì¶œì•¡'].pct_change()
            df['ì˜ì—…ì´ìµì¦ê°€ìœ¨'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì˜ì—…ì´ìµ'].pct_change()
            df['DOL'] = safe_divide(df['ì˜ì—…ì´ìµì¦ê°€ìœ¨'], df['ë§¤ì¶œì•¡ì¦ê°€ìœ¨'], outlier_threshold=50)
    
    # DFL - ì¬ë¬´ë ˆë²„ë¦¬ì§€
    if all(col in df.columns for col in ['ì˜ì—…ì´ìµ', 'ì´ìë¹„ìš©']):
        denominator = df['ì˜ì—…ì´ìµ'] - df['ì´ìë¹„ìš©']
        df['DFL'] = safe_divide(df['ì˜ì—…ì´ìµ'], denominator, outlier_threshold=50)
    
    # ì„ íƒì‚¬í•­: ë¸íƒ€ í”¼ì²˜
    for metric in ['DFL']:
        if metric in df.columns:
            df[f'Î”{metric}'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')[metric].diff()
    
    return df

def create_market_features(df):
    """
    ì‹œì¥ ë°¸ë¥˜ì—ì´ì…˜ í”¼ì²˜ ìƒì„±
    """
    print("ì‹œì¥ ë°¸ë¥˜ì—ì´ì…˜ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # ì‹œê°€ì´ì•¡ í”¼ì²˜
    if 'ì‹œê°€ì´ì•¡' in df.columns:
        df['ë¡œê·¸ì‹œê°€ì´ì•¡'] = np.log1p(df['ì‹œê°€ì´ì•¡'])
        # df['ì‹œê°€ì´ì•¡ì¦ê°€ìœ¨'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì‹œê°€ì´ì•¡'].pct_change()
    
    # ì´ìì‚° ë¡œê·¸ ë³€í™˜
    if 'ì´ìì‚°' in df.columns:
        df['ë¡œê·¸ì´ìì‚°'] = np.log1p(df['ì´ìì‚°'])
    
    # ê¸°ì—…ê°€ì¹˜(Enterprise Value)
    cash_cols = ['í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚°', 'ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ(ê¸ˆìœµê¸°ê´€ì˜ˆì¹˜ê¸ˆ)']
    if 'ì‹œê°€ì´ì•¡' in df.columns and 'ì´ë¶€ì±„' in df.columns:
        cash_sum = sum(df.get(col, 0) for col in cash_cols if col in df.columns)
        df['EV'] = df['ì‹œê°€ì´ì•¡'] + df['ì´ë¶€ì±„'] - cash_sum
        
        # EV/EBITDA ë¹„ìœ¨
        ebitda_cols = ['ì˜ì—…ì´ìµ', 'ê°ê°€ìƒê°ë¹„', 'ë¬´í˜•ìì‚°ìƒê°ë¹„']
        if all(col in df.columns for col in ebitda_cols):
            ebitda = df['ì˜ì—…ì´ìµ'] + df['ê°ê°€ìƒê°ë¹„'] + df['ë¬´í˜•ìì‚°ìƒê°ë¹„']
            df['EV/EBITDA'] = safe_divide(df['EV'], ebitda, outlier_threshold=500)
    
    # ë°¸ë¥˜ì—ì´ì…˜ ë°°ìˆ˜
    if 'ì‹œê°€ì´ì•¡' in df.columns:
        if 'ì´ìë³¸' in df.columns:
            df['PBR'] = safe_divide(df['ì‹œê°€ì´ì•¡'], df['ì´ìë³¸'], outlier_threshold=100)
        
        if 'ë‹¹ê¸°ìˆœì´ìµ' in df.columns:
            df['PER'] = safe_divide(df['ì‹œê°€ì´ì•¡'], df['ë‹¹ê¸°ìˆœì´ìµ'], outlier_threshold=1000)
        
        if 'ë§¤ì¶œì•¡' in df.columns:
            df['PSR'] = safe_divide(df['ì‹œê°€ì´ì•¡'], df['ë§¤ì¶œì•¡'], outlier_threshold=100)
        
        if 'ì˜ì—…í˜„ê¸ˆíë¦„' in df.columns:
            df['PCR'] = safe_divide(df['ì‹œê°€ì´ì•¡'], df['ì˜ì—…í˜„ê¸ˆíë¦„'], outlier_threshold=1000)
    
    # ë°¸ë¥˜ì—ì´ì…˜ ë°°ìˆ˜ì˜ ë¸íƒ€ í”¼ì²˜
    # for multiple in ['PBR', 'PER', 'PSR', 'PCR']:
    #     if multiple in df.columns:
    #         df[f'Î”{multiple}'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')[multiple].diff()
    
    return df

def create_dividend_features(df):
    """
    ë°°ë‹¹ ë° ì„±ì¥ í”¼ì²˜ ìƒì„±
    """
    print("ë°°ë‹¹ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # ë°°ë‹¹ìˆ˜ìµë¥ 
    if all(col in df.columns for col in ['ì£¼ë‹¹ë°°ë‹¹ê¸ˆ', 'ì¢…ê°€']):
        df['ë°°ë‹¹ìˆ˜ìµë¥ '] = safe_divide(df['ì£¼ë‹¹ë°°ë‹¹ê¸ˆ'], df['ì¢…ê°€'], outlier_threshold=1)
    
    # PEG ë¹„ìœ¨
    # if all(col in df.columns for col in ['PER', 'ë‹¹ê¸°ìˆœì´ìµì¦ê°€ìœ¨']):
    #     # ì„±ì¥ë¥ ì„ ë°±ë¶„ìœ¨ë¡œ ë³€í™˜ í›„ ê³„ì‚°
    #     growth_rate_pct = df['ë‹¹ê¸°ìˆœì´ìµì¦ê°€ìœ¨'] * 100
    #     df['PEG'] = safe_divide(df['PER'], growth_rate_pct, outlier_threshold=10)
    
    return df

def create_momentum_features(df):
    """
    ëª¨ë©˜í…€, ë³€ë™ì„±, ìœ ë™ì„± í”¼ì²˜ ìƒì„±
    """
    print("ëª¨ë©˜í…€ ë° ìœ ë™ì„± í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # ì£¼ì˜: ì—°ê°„ ë°ì´í„°ì˜ ê²½ìš° ëª¨ë©˜í…€ ê³„ì‚°ì´ ì œí•œì ì„
    # ì¼ì¼/ì›”ê°„ ë°ì´í„°ì—ì„œ ë” ì˜ë¯¸ê°€ ìˆìŒ
    
    # if 'ì¢…ê°€' in df.columns:
    #     # ì—°ê°„ ìˆ˜ìµë¥  (ì—°ê°„ ë°ì´í„°ë¡œëŠ” ì œí•œì  í™œìš©)
    #     for period in [1, 2, 3]:  # 1, 2, 3ë…„ ìˆ˜ìµë¥ 
    #         df[f'{period}ë…„ìˆ˜ìµë¥ '] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì¢…ê°€'].pct_change(periods=period)
    
    # ì£¼ì‹ íšŒì „ìœ¨
    if all(col in df.columns for col in ['ê±°ë˜ëŸ‰', 'ìƒì¥ì£¼ì‹ìˆ˜']):
        df['ì£¼ì‹íšŒì „ìœ¨'] = safe_divide(df['ê±°ë˜ëŸ‰'], df['ìƒì¥ì£¼ì‹ìˆ˜'], outlier_threshold=10)
    
    return df

def create_delta_features(df):
    """
    ì£¼ìš” ë¹„ìœ¨ë“¤ì˜ ë¸íƒ€(ë³€í™”ëŸ‰) í”¼ì²˜ ìƒì„±
    """
    print("ë¸íƒ€ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # ì£¼ìš” ìˆ˜ìµì„± ì§€í‘œì˜ ì „ë…„ ëŒ€ë¹„ ë³€í™”ëŸ‰ (ëª…ì‹œì  ìƒì„±)
    profitability_ratios = {
        'ì´ìì‚°ìˆ˜ìµë¥ (ROA)': 'ROA_ë³€í™”ëŸ‰',
        'ìê¸°ìë³¸ìˆ˜ìµë¥ (ROE)': 'ROE_ë³€í™”ëŸ‰', 
        'íˆ¬í•˜ìë³¸ìˆ˜ìµë¥ (ROIC)': 'ROIC_ë³€í™”ëŸ‰'
    }
    
    for original_col, new_col in profitability_ratios.items():
        if original_col in df.columns:
            df[new_col] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')[original_col].diff()
            print(f"  ìƒì„±ë¨: {new_col}")
    
    # ë¸íƒ€ í”¼ì²˜ë¥¼ ìƒì„±í•  ì£¼ìš” ë¹„ìœ¨ë“¤
    delta_candidates = [
        'ìœ ë™ë¹„ìœ¨', 'ë‹¹ì¢Œë¹„ìœ¨', 'ë¶€ì±„ìì‚°ë¹„ìœ¨', 'ë¶€ì±„ìë³¸ë¹„ìœ¨', 'ìë³¸ë¹„ìœ¨',
        'ì´ìì‚°íšŒì „ìœ¨', 'EBITDAëŒ€ì°¨ì…ê¸ˆë¹„ìœ¨', 'í˜„ê¸ˆíë¦„ëŒ€ë¶€ì±„ë¹„ìœ¨',
        'ë°°ë‹¹ìˆ˜ìµë¥ '
    ]
    
    for ratio in delta_candidates:
        if ratio in df.columns:
            df[f'Î”{ratio}'] = df.groupby('ê±°ë˜ì†Œì½”ë“œ')[ratio].diff()
    
    return df

def clean_numerical_data(df):
    """
    ìˆ˜ì¹˜ ë°ì´í„° ì •ë¦¬ - ë¬´í•œê°’ì„ NaNìœ¼ë¡œ ì¹˜í™˜
    """
    print("ìˆ˜ì¹˜ ë°ì´í„° ì •ë¦¬ ì¤‘...")
    
    # infì™€ -infë¥¼ NaNìœ¼ë¡œ ì¹˜í™˜
    df = df.replace([np.inf, -np.inf], np.nan)
    
    print(f"ìµœì¢… ë°ì´í„°ì…‹ í¬ê¸°: {df.shape}")
    print(f"ì´ NaN ê°’ ê°œìˆ˜: {df.isna().sum().sum()}")
    
    return df

def remove_first_year_data(df):
    """
    ê° ê¸°ì—…ë³„ ì²«í•´ ë°ì´í„° ì‚­ì œ (ë¶€ë„ ê¸°ì—… ì œì™¸)
    - ë¶€ë„ ê¸°ì—…(default=1)ì˜ ë°ì´í„°ëŠ” ë³´ì¡´
    - ì •ìƒ ê¸°ì—…ì˜ ì²«í•´ ë°ì´í„°ë§Œ ì‚­ì œí•˜ì—¬ ì „ë…„ ëŒ€ë¹„ ë¹„êµ ê°€ëŠ¥í•œ ë°ì´í„°ë§Œ ìœ ì§€
    """
    print("ê° ê¸°ì—…ë³„ ì²«í•´ ë°ì´í„° ì‚­ì œ ì¤‘ (ë¶€ë„ ê¸°ì—… ì œì™¸)...")
    
    original_count = len(df)
    print(f"ì „ì²˜ë¦¬ ì „ ë°ì´í„°: {original_count:,}ê°œ")
    
    if 'default' in df.columns:
        # ì „ì²˜ë¦¬ ì „ ë¶€ë„ ê¸°ì—… í˜„í™©
        default_before = df[df['default'] == 1].shape[0]
        print(f"ë¶€ë„ ê¸°ì—… ë°ì´í„°: {default_before:,}ê°œ ({default_before/original_count*100:.2f}%)")
        
        # ë¶€ë„ ê¸°ì—…ì´ ì•„ë‹Œ ë°ì´í„°ì—ì„œë§Œ ì²«í•´ ì°¾ê¸°
        non_default_df = df[df['default'] != 1]
        first_year_by_code = non_default_df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì—°ë„'].min()
        print(f"ì²«í•´ ì‚­ì œ ëŒ€ìƒ ê¸°ì—… ìˆ˜ (ë¶€ë„ ê¸°ì—… ì œì™¸): {len(first_year_by_code):,}ê°œ")
        
        # ì²«í•´ ë°ì´í„° ì‹ë³„ (ë¶€ë„ ê¸°ì—…ì´ ì•„ë‹Œ ê²½ìš°ë§Œ)
        first_year_mask = df.apply(
            lambda row: (row['default'] != 1) and 
                       (row['ê±°ë˜ì†Œì½”ë“œ'] in first_year_by_code) and
                       (row['ì—°ë„'] == first_year_by_code.get(row['ê±°ë˜ì†Œì½”ë“œ'], float('inf'))), 
            axis=1
        )
        
        first_year_count = first_year_mask.sum()
        print(f"ê° ê¸°ì—…ë³„ ì²«í•´ ë°ì´í„° (ì‚­ì œ ëŒ€ìƒ): {first_year_count:,}ê°œ")
        
        # ì²«í•´ ë°ì´í„° ì‚­ì œ
        df_final = df[~first_year_mask].copy()
        
        # ê²°ê³¼ ìš”ì•½
        final_count = len(df_final)
        default_after = df_final[df_final['default'] == 1].shape[0]
        default_loss = default_before - default_after
        
        print(f"ì²«í•´ ë°ì´í„° ì‚­ì œ í›„: {final_count:,}ê°œ")
        print(f"ì „ì²´ ì‚­ì œìœ¨: {(original_count - final_count)/original_count*100:.2f}%")
        print(f"ë¶€ë„ ê¸°ì—… ë³´ì¡´: {default_after:,}ê°œ (ì†ì‹¤: {default_loss:,}ê°œ)")
        print(f"ë¶€ë„ìœ¨ ë³€í™”: {default_before/original_count*100:.3f}% â†’ {default_after/final_count*100:.3f}%")
        
    else:
        # default ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
        print("âš ï¸ default ì»¬ëŸ¼ì´ ì—†ì–´ ëª¨ë“  ê¸°ì—…ì˜ ì²«í•´ ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
        first_year_by_code = df.groupby('ê±°ë˜ì†Œì½”ë“œ')['ì—°ë„'].min()
        print(f"ë¶„ì„ ëŒ€ìƒ ê¸°ì—… ìˆ˜: {len(first_year_by_code):,}ê°œ")
        
        first_year_mask = df.apply(
            lambda row: row['ì—°ë„'] == first_year_by_code[row['ê±°ë˜ì†Œì½”ë“œ']], 
            axis=1
        )
        
        first_year_count = first_year_mask.sum()
        print(f"ê° ê¸°ì—…ë³„ ì²«í•´ ë°ì´í„° (ì‚­ì œ ëŒ€ìƒ): {first_year_count:,}ê°œ")
        
        # ì²«í•´ ë°ì´í„° ì‚­ì œ
        df_final = df[~first_year_mask].copy()
        final_count = len(df_final)
        
        print(f"ì²«í•´ ë°ì´í„° ì‚­ì œ í›„: {final_count:,}ê°œ")
        print(f"ì „ì²´ ì‚­ì œìœ¨: {(original_count - final_count)/original_count*100:.2f}%")
    
    # ê¸°ì—…ë³„ ë°ì´í„° ê°œìˆ˜ ë¶„í¬ í™•ì¸
    company_data_counts = df_final['ê±°ë˜ì†Œì½”ë“œ'].value_counts()
    print(f"\nê¸°ì—…ë³„ í‰ê·  ì—°ë„ ìˆ˜: {company_data_counts.mean():.1f}ë…„")
    print(f"ê¸°ì—…ë³„ ì—°ë„ ìˆ˜ ë²”ìœ„: {company_data_counts.min()}~{company_data_counts.max()}ë…„")
    
    return df_final

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("=" * 60)
    print("ë¶€ë„ì˜ˆì¸¡ì„ ìœ„í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
    df = load_and_merge_data()
    
    # 2. ëŒ€ì°¨ëŒ€ì¡°í‘œ í‰ê· ê°’ ìƒì„±
    df = create_balance_sheet_averages(df)
    
    # 3. ëª¨ë“  í”¼ì²˜ ì¹´í…Œê³ ë¦¬ ìƒì„±
    df = create_growth_features(df)
    df = create_liquidity_leverage_features(df)
    
    # 3-1. ìƒˆë¡œ ìƒì„±ëœ BS í•­ëª©ë“¤ì˜ í‰ê· ê°’ ìƒì„±
    df = create_additional_balance_sheet_averages(df)
    
    df = create_profitability_features(df)
    df = create_leverage_metrics(df)  # DOLê³¼ DFLë§Œ
    df = create_market_features(df)
    df = create_momentum_features(df)
    df = create_dividend_features(df)
    df = create_delta_features(df)
    
    # 4. ìˆ˜ì¹˜ ë°ì´í„° ì •ë¦¬
    df = clean_numerical_data(df)
    
    # 5. ê° ê¸°ì—…ë³„ ì²«í•´ ë°ì´í„° ì‚­ì œ (ë¶€ë„ ê¸°ì—… ì œì™¸)
    df = remove_first_year_data(df)
    
    # 6. í”¼ì²˜ í’ˆì§ˆ ê²€ì¦
    validation_report = validate_features(df)
    
    # 7. ì¶œë ¥ ì €ì¥
    current_dir = Path(__file__).parent
    project_root = current_dir.parent.parent  # src/data_processing -> src -> project_root
    output_path = project_root / "data" / "processed" / "FS2_features.csv"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    df.to_csv(output_path, index=False, encoding='utf-8')
    
    print("=" * 60)
    print("í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë° ì „ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ì¶œë ¥ ì €ì¥ ìœ„ì¹˜: {output_path}")
    print(f"ìµœì¢… ë°ì´í„°ì…‹: {df.shape[0]} í–‰ Ã— {df.shape[1]} ì—´")
    print("ğŸ’¡ ê° ê¸°ì—…ì˜ ì²«í•´ ë°ì´í„°ê°€ ì‚­ì œë˜ì–´ ì „ë…„ ëŒ€ë¹„ ë¹„êµ ê°€ëŠ¥í•œ ë°ì´í„°ë§Œ í¬í•¨")
    print("=" * 60)
    
    # í”¼ì²˜ ìš”ì•½ í‘œì‹œ
    print("\ní”¼ì²˜ ìš”ì•½:")
    print(f"ì›ë³¸ ì»¬ëŸ¼: {len([col for col in df.columns if not any(prefix in col for prefix in ['avg_', 'Î”', 'ì¦ê°€ìœ¨', 'ë¹„ìœ¨', 'ROA', 'ROE', 'PBR', 'PER', 'PSR', 'PCR', 'DOL', 'DFL', 'EV', 'ë¡œê·¸', 'ë³€í™”ëŸ‰'])])}")
    print(f"ì„±ì¥ë¥  í”¼ì²˜: {len([col for col in df.columns if 'ì¦ê°€ìœ¨' in col])}")
    print(f"ë¹„ìœ¨ í”¼ì²˜: {len([col for col in df.columns if 'ë¹„ìœ¨' in col])}")
    print(f"ì‹œì¥ í”¼ì²˜: {len([col for col in df.columns if any(prefix in col for prefix in ['PBR', 'PER', 'PSR', 'PCR', 'EV', 'ì‹œê°€ì´ì•¡'])])}")
    print(f"ë¸íƒ€ í”¼ì²˜: {len([col for col in df.columns if 'Î”' in col])}")
    print(f"ë³€í™”ëŸ‰ í”¼ì²˜: {len([col for col in df.columns if 'ë³€í™”ëŸ‰' in col])}")
    print(f"ë¡œê·¸ ë³€í™˜ í”¼ì²˜: {len([col for col in df.columns if 'ë¡œê·¸' in col])}")
    print(f"í‰ê·  B/S í”¼ì²˜: {len([col for col in df.columns if 'avg_' in col])}")
    print(f"  - ê¸°ë³¸ BS í‰ê· : {len([col for col in df.columns if 'avg_' in col and not any(item in col for item in ['íˆ¬í•˜ìë³¸', 'ê²½ì˜ìë³¸', 'ìš´ì „ìë³¸'])])}")
    print(f"  - ì¶”ê°€ BS í‰ê· : {len([col for col in df.columns if 'avg_' in col and any(item in col for item in ['íˆ¬í•˜ìë³¸', 'ê²½ì˜ìë³¸', 'ìš´ì „ìë³¸'])])}")
    print(f"\nğŸ’¡ ì „ë…„ ëŒ€ë¹„ í”¼ì²˜ë“¤ì€ ê° ê¸°ì—… ì²«í•´ ì‚­ì œë¡œ ì¸í•´ ì •í™•í•˜ê²Œ ê³„ì‚°ë¨")
    print(f"ğŸ’¡ ìƒˆë¡œ ìƒì„±ëœ BS í•­ëª©ë“¤(íˆ¬í•˜ìë³¸, ê²½ì˜ìë³¸ ë“±)ì˜ í‰ê· ê°’ë„ ìƒì„±ë¨")
    
    # ê²€ì¦ ë¦¬í¬íŠ¸ ìš”ì•½
    print("\në°ì´í„° í’ˆì§ˆ ìš”ì•½:")
    total_issues = (
        len(validation_report['negative_assets']) +
        len(validation_report['extreme_ratios']) +
        len(validation_report['high_missing_rate']) +
        len(validation_report['suspicious_values'])
    )
    print(f"ì´ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ: {total_issues}ê°œ")
    print(f"ë¬´í•œê°’/NaN ì²˜ë¦¬ ì™„ë£Œ: {df.isna().sum().sum()}ê°œ NaN ê°’ ì¡´ì¬")

if __name__ == "__main__":
    main()