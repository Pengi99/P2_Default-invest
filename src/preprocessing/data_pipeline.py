"""
ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
==============================

ê¸°ëŠ¥:
1. ë°ì´í„° ë¡œë“œ ë° 5:3:2 ë¶„í• 
2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (50% ì´ìƒ ê²°ì¸¡ í–‰ ì‚­ì œ + median ëŒ€ì²´)
3. ìœˆì €ë¼ì´ì§• (ì–‘ ì˜† 0.05%)
4. ë¼ì†Œ íšŒê·€ í”¼ì²˜ ì„ íƒ

Configë¥¼ í†µí•œ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì§€ì›
"""

import pandas as pd
import numpy as np
import yaml
import pickle
import logging
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional
import warnings
warnings.filterwarnings('ignore')

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LassoCV, Lasso
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.metrics import mean_squared_error, r2_score
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns


class DataPreprocessingPipeline:
    """
    ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤
    
    Config íŒŒì¼ì„ í†µí•´ ëª¨ë“  ì„¤ì •ì„ ê´€ë¦¬í•˜ë©°,
    ë°ì´í„° ë¡œë“œë¶€í„° í”¼ì²˜ ì„ íƒê¹Œì§€ ì „ì²´ ê³¼ì •ì„ ìˆ˜í–‰ (ìŠ¤ì¼€ì¼ë§ ì œì™¸)
    """
    
    def __init__(self, config_path: str):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            config_path: config YAML íŒŒì¼ ê²½ë¡œ
        """
        self.config_path = config_path
        self.config = self._load_config()
        self.logger = self._setup_logging()
        
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.project_root = Path(__file__).parent.parent.parent
        
        # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        self.results = {
            'experiment_info': {},
            'data_info': {},
            'preprocessing_steps': {},
            'model_performance': {},
            'selected_features': []
        }
        
        # í”¼ì²˜ ì„ íƒ ëª¨ë¸ ì €ì¥ìš©
        self.feature_selector = None
        
        self.logger.info("ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤ (ìŠ¤ì¼€ì¼ë§ ì œì™¸).")
    
    def _load_config(self) -> Dict:
        """Config íŒŒì¼ ë¡œë“œ"""
        with open(self.config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    
    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger('DataPipeline')
        logger.setLevel(getattr(logging, self.config['logging']['level']))
        
        # í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        if self.config['logging']['save_to_file']:
            log_dir = Path(self.config['logging']['log_file']).parent
            log_dir.mkdir(parents=True, exist_ok=True)
            
            file_handler = logging.FileHandler(self.config['logging']['log_file'])
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)
        
        return logger
    
    def load_data(self) -> pd.DataFrame:
        """ë°ì´í„° ë¡œë“œ"""
        self.logger.info("ë°ì´í„° ë¡œë“œ ì‹œì‘")
        
        data_path = self.project_root / self.config['data']['input_path']
        df = pd.read_csv(data_path, dtype={'ê±°ë˜ì†Œì½”ë“œ': str})
        
        self.logger.info(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
        
        # ê¸°ë³¸ ì •ë³´ ì €ì¥
        self.results['data_info'] = {
            'original_shape': df.shape,
            'columns': list(df.columns),
            'target_distribution': df[self.config['feature_engineering']['target_column']].value_counts().to_dict(),
            'missing_data_summary': df.isnull().sum().to_dict()
        }
        
        return df
    
    def split_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """ë°ì´í„°ë¥¼ 5:3:2ë¡œ ë¶„í• """
        self.logger.info("ë°ì´í„° ë¶„í•  ì‹œì‘ (5:3:2)")
        
        target_col = self.config['feature_engineering']['target_column']
        
        # ë¨¼ì € trainê³¼ tempë¡œ ë¶„í•  (5:5)
        if self.config['data_split']['stratify']:
            train_df, temp_df = train_test_split(
                df, 
                test_size=0.5,  # 50%ë¥¼ tempë¡œ
                random_state=self.config['data_split']['random_state'],
                stratify=df[target_col]
            )
        else:
            train_df, temp_df = train_test_split(
                df,
                test_size=0.5,
                random_state=self.config['data_split']['random_state']
            )
        
        # tempë¥¼ valê³¼ testë¡œ ë¶„í•  (3:2)
        val_ratio = self.config['data_split']['val_ratio']
        test_ratio = self.config['data_split']['test_ratio']
        val_size = val_ratio / (val_ratio + test_ratio)  # temp ë‚´ì—ì„œì˜ val ë¹„ìœ¨
        
        if self.config['data_split']['stratify']:
            val_df, test_df = train_test_split(
                temp_df,
                test_size=(1-val_size),
                random_state=self.config['data_split']['random_state'],
                stratify=temp_df[target_col]
            )
        else:
            val_df, test_df = train_test_split(
                temp_df,
                test_size=(1-val_size),
                random_state=self.config['data_split']['random_state']
            )
        
        self.logger.info(f"Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}")
        
        # ë¶„í•  ì •ë³´ ì €ì¥
        self.results['preprocessing_steps']['data_split'] = {
            'train_shape': train_df.shape,
            'val_shape': val_df.shape,
            'test_shape': test_df.shape,
            'train_target_dist': train_df[target_col].value_counts().to_dict(),
            'val_target_dist': val_df[target_col].value_counts().to_dict(),
            'test_target_dist': test_df[target_col].value_counts().to_dict()
        }
        
        return train_df, val_df, test_df
    
    def handle_missing_data(self, train_df: pd.DataFrame, val_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
        self.logger.info("ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘")
        
        # í”¼ì²˜ ì»¬ëŸ¼ë“¤ë§Œ ì¶”ì¶œ
        exclude_cols = self.config['feature_engineering']['exclude_columns'] + [self.config['feature_engineering']['target_column']]
        feature_cols = [col for col in train_df.columns if col not in exclude_cols]
        
        original_train_shape = train_df.shape
        original_val_shape = val_df.shape
        original_test_shape = test_df.shape
        
        # 1. 50% ì´ìƒ ê²°ì¸¡ì¹˜ì¸ í–‰ ì‚­ì œ
        threshold = self.config['missing_data']['row_missing_threshold']
        
        # ê° í–‰ì˜ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ ê³„ì‚°
        train_missing_rate = train_df[feature_cols].isnull().sum(axis=1) / len(feature_cols)
        val_missing_rate = val_df[feature_cols].isnull().sum(axis=1) / len(feature_cols)
        test_missing_rate = test_df[feature_cols].isnull().sum(axis=1) / len(feature_cols)
        
        # ì„ê³„ê°’ ì´í•˜ì¸ í–‰ë§Œ ìœ ì§€
        train_df = train_df[train_missing_rate <= threshold].copy()
        val_df = val_df[val_missing_rate <= threshold].copy()
        test_df = test_df[test_missing_rate <= threshold].copy()
        
        self.logger.info(f"í–‰ ì‚­ì œ í›„ - Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}")
        
        # 2. ê²°ì¸¡ê°’ ëŒ€ì²´
        imputation_method = self.config['missing_data']['imputation_method']
        
        if imputation_method == "median":
            imputer = SimpleImputer(strategy='median')
        elif imputation_method == "mean":
            imputer = SimpleImputer(strategy='mean')
        elif imputation_method == "mode":
            imputer = SimpleImputer(strategy='most_frequent')
        elif imputation_method == "knn":
            imputer = KNNImputer(n_neighbors=5)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ê²°ì¸¡ê°’ ëŒ€ì²´ ë°©ë²•: {imputation_method}")
        
        # Train ë°ì´í„°ë¡œ imputer í•™ìŠµ
        imputer.fit(train_df[feature_cols])
        
        # ëª¨ë“  ë°ì´í„°ì…‹ì— ì ìš©
        train_df[feature_cols] = imputer.transform(train_df[feature_cols])
        val_df[feature_cols] = imputer.transform(val_df[feature_cols])
        test_df[feature_cols] = imputer.transform(test_df[feature_cols])
        
        self.logger.info(f"ê²°ì¸¡ê°’ ëŒ€ì²´ ì™„ë£Œ ({imputation_method})")
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì •ë³´ ì €ì¥
        self.results['preprocessing_steps']['missing_data'] = {
            'method': imputation_method,
            'threshold': threshold,
            'before_shape': {
                'train': original_train_shape,
                'val': original_val_shape,
                'test': original_test_shape
            },
            'after_shape': {
                'train': train_df.shape,
                'val': val_df.shape,
                'test': test_df.shape
            },
            'rows_removed': {
                'train': original_train_shape[0] - train_df.shape[0],
                'val': original_val_shape[0] - val_df.shape[0],
                'test': original_test_shape[0] - test_df.shape[0]
            }
        }
        
        return train_df, val_df, test_df
    
    def apply_winsorization(self, train_df: pd.DataFrame, val_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """ìœˆì €ë¼ì´ì§• ì ìš©"""
        if not self.config['outlier_treatment']['enabled']:
            self.logger.info("ìœˆì €ë¼ì´ì§•ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return train_df, val_df, test_df
        
        self.logger.info("ìœˆì €ë¼ì´ì§• ì ìš© ì‹œì‘")
        
        # í”¼ì²˜ ì»¬ëŸ¼ë“¤ë§Œ ì¶”ì¶œ
        exclude_cols = self.config['feature_engineering']['exclude_columns'] + [self.config['feature_engineering']['target_column']]
        feature_cols = [col for col in train_df.columns if col not in exclude_cols]
        
        lower_pct = self.config['outlier_treatment']['winsorization']['lower_percentile']
        upper_pct = self.config['outlier_treatment']['winsorization']['upper_percentile']
        
        # Train ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„ê³„ê°’ ê³„ì‚°
        winsor_limits = {}
        for col in feature_cols:
            lower_limit = train_df[col].quantile(lower_pct)
            upper_limit = train_df[col].quantile(upper_pct)
            winsor_limits[col] = (lower_limit, upper_limit)
        
        # ìœˆì €ë¼ì´ì§• ì ìš©
        for df_name, df in [('train', train_df), ('val', val_df), ('test', test_df)]:
            for col in feature_cols:
                lower_limit, upper_limit = winsor_limits[col]
                df[col] = np.clip(df[col], lower_limit, upper_limit)
        
        self.logger.info(f"ìœˆì €ë¼ì´ì§• ì™„ë£Œ (í•˜ìœ„ {lower_pct*100}%, ìƒìœ„ {upper_pct*100}%)")
        
        # ìœˆì €ë¼ì´ì§• ì •ë³´ ì €ì¥
        self.results['preprocessing_steps']['winsorization'] = {
            'enabled': True,
            'lower_percentile': lower_pct,
            'upper_percentile': upper_pct,
            'limits': {col: limits for col, limits in winsor_limits.items()}
        }
        
        return train_df, val_df, test_df
    
    def select_features_with_lasso(self, train_df: pd.DataFrame, val_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """ë¼ì†Œ íšŒê·€ë¥¼ ì´ìš©í•œ í”¼ì²˜ ì„ íƒ"""
        if not self.config['feature_selection']['enabled']:
            self.logger.info("í”¼ì²˜ ì„ íƒì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return train_df, val_df, test_df
        
        self.logger.info("ë¼ì†Œ íšŒê·€ í”¼ì²˜ ì„ íƒ ì‹œì‘")
        
        # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
        exclude_cols = self.config['feature_engineering']['exclude_columns'] + [self.config['feature_engineering']['target_column']]
        feature_cols = [col for col in train_df.columns if col not in exclude_cols]
        target_col = self.config['feature_engineering']['target_column']
        
        X_train = train_df[feature_cols]
        y_train = train_df[target_col]
        X_val = val_df[feature_cols]
        y_val = val_df[target_col]
        X_test = test_df[feature_cols]
        y_test = test_df[target_col]
        
        # ë¼ì†Œ íšŒê·€ ì„¤ì •
        lasso_config = self.config['feature_selection']['lasso']
        alphas = lasso_config['alpha_range']
        cv_folds = lasso_config['cv_folds']
        max_iter = lasso_config['max_iter']
        random_state = lasso_config['random_state']
        
        # LassoCVë¡œ ìµœì  alpha ì°¾ê¸°
        lasso_cv = LassoCV(
            alphas=alphas,
            cv=cv_folds,
            max_iter=max_iter,
            random_state=random_state,
            n_jobs=self.config['performance'].get('n_jobs', 1)
        )
        
        lasso_cv.fit(X_train, y_train)
        
        # 1se rule ì ìš©í• ì§€ ê²°ì •
        if lasso_config['alpha_selection'] == "1se":
            # 1-standard-error rule
            mean_scores = lasso_cv.mse_path_.mean(axis=1)
            std_scores = lasso_cv.mse_path_.std(axis=1)
            
            best_idx = np.argmin(mean_scores)
            best_score = mean_scores[best_idx]
            best_std = std_scores[best_idx]
            
            # 1se ì„ê³„ê°’ ì´í•˜ì¸ alpha ì¤‘ ê°€ì¥ í° ê°’ ì„ íƒ
            threshold = best_score + best_std
            valid_indices = np.where(mean_scores <= threshold)[0]
            selected_alpha_idx = valid_indices[0]  # ê°€ì¥ í° alpha (ì²« ë²ˆì§¸ ì¸ë±ìŠ¤)
            selected_alpha = alphas[selected_alpha_idx]
        else:
            selected_alpha = lasso_cv.alpha_
        
        # ì„ íƒëœ alphaë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ
        lasso = Lasso(alpha=selected_alpha, max_iter=max_iter, random_state=random_state)
        lasso.fit(X_train, y_train)
        
        # ì„ íƒëœ í”¼ì²˜ë“¤ (ê³„ìˆ˜ê°€ 0ì´ ì•„ë‹Œ í”¼ì²˜ë“¤)
        selected_features = [feature_cols[i] for i in range(len(feature_cols)) if lasso.coef_[i] != 0]
        
        self.logger.info(f"ì„ íƒëœ í”¼ì²˜ ìˆ˜: {len(selected_features)} / {len(feature_cols)}")
        
        # í”¼ì²˜ ì„ íƒ ì ìš©
        all_selected_cols = selected_features + [target_col] + self.config['feature_engineering']['exclude_columns']
        all_selected_cols = [col for col in all_selected_cols if col in train_df.columns]
        
        train_selected = train_df[all_selected_cols]
        val_selected = val_df[all_selected_cols]
        test_selected = test_df[all_selected_cols]
        
        # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
        train_pred = lasso.predict(X_train[selected_features])
        val_pred = lasso.predict(X_val[selected_features])
        test_pred = lasso.predict(X_test[selected_features])
        
        # ê²°ê³¼ ì €ì¥
        self.feature_selector = lasso
        self.results['selected_features'] = selected_features
        
        self.results['preprocessing_steps']['feature_selection'] = {
            'method': 'lasso',
            'selected_alpha': selected_alpha,
            'original_features': len(feature_cols),
            'selected_features': len(selected_features),
            'feature_names': selected_features
        }
        
        self.results['model_performance'] = {
            'train_mse': mean_squared_error(y_train, train_pred),
            'val_mse': mean_squared_error(y_val, val_pred),
            'test_mse': mean_squared_error(y_test, test_pred),
            'train_r2': r2_score(y_train, train_pred),
            'val_r2': r2_score(y_val, val_pred),
            'test_r2': r2_score(y_test, test_pred)
        }
        
        return train_selected, val_selected, test_selected
    
    def save_results(self, train_df: pd.DataFrame, val_df: pd.DataFrame, test_df: pd.DataFrame):
        """ê²°ê³¼ ì €ì¥"""
        self.logger.info("ê²°ê³¼ ì €ì¥ ì‹œì‘")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        output_dir = self.project_root / self.config['data']['output_dir']
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ì„œë¸Œë””ë ‰í† ë¦¬ ìƒì„± ì—¬ë¶€ í™•ì¸
        create_subdirectory = self.config['experiment'].get('create_subdirectory', True)
        
        if create_subdirectory:
            # ì‹¤í—˜ ì´ë¦„ ìƒì„±
            experiment_name = self.config['experiment']['name']
            if experiment_name is None:
                experiment_name = f"preprocessing_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            experiment_dir = output_dir / experiment_name
            experiment_dir.mkdir(parents=True, exist_ok=True)
        else:
            # data/finalì— ì§ì ‘ ì €ì¥
            experiment_dir = output_dir
        
        # 1. ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        if self.config['output']['save_processed_data']:
            self._save_processed_data(train_df, val_df, test_df, experiment_dir)
        
        # 2. í”¼ì²˜ ì„ íƒ ëª¨ë¸ ì €ì¥
        if self.config['output']['save_feature_selector'] and self.feature_selector is not None:
            with open(experiment_dir / "feature_selector.pkl", 'wb') as f:
                pickle.dump(self.feature_selector, f)
        
        # 3. ì‹¤í—˜ ê²°ê³¼ ì €ì¥
        experiment_name = "preprocessing" if not create_subdirectory else self.config['experiment']['name']
        self.results['experiment_info'] = {
            'name': experiment_name,
            'config_path': str(self.config_path),
            'timestamp': datetime.now().isoformat(),
            'version': self.config['experiment']['version'],
            'description': self.config['experiment']['description']
        }
        
        # ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ì €ì¥ (ì„œë¸Œë””ë ‰í† ë¦¬ ìƒì„± ì‹œì—ë§Œ)
        if create_subdirectory:
            import json
            with open(experiment_dir / "experiment_results.json", 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2, default=str)
        
        # 4. Config íŒŒì¼ ë³µì‚¬ (ì„œë¸Œë””ë ‰í† ë¦¬ ìƒì„± ì‹œì—ë§Œ)
        if self.config['output']['save_config_log'] and create_subdirectory:
            import shutil
            shutil.copy2(self.config_path, experiment_dir / "config.yaml")
        
        self.logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {experiment_dir}")
        
        return experiment_dir
    
    def _save_processed_data(self, train_df: pd.DataFrame, val_df: pd.DataFrame, test_df: pd.DataFrame, experiment_dir: Path):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        file_naming = self.config['output']['file_naming']
        separate_features_target = file_naming.get('separate_features_target', False)
        prefix = file_naming.get('prefix', "")
        
        # í”¼ì²˜ì™€ íƒ€ê²Ÿ ì»¬ëŸ¼ ë¶„ë¦¬
        exclude_cols = self.config['feature_engineering']['exclude_columns'] + [self.config['feature_engineering']['target_column']]
        feature_cols = [col for col in train_df.columns if col not in exclude_cols]
        target_col = self.config['feature_engineering']['target_column']
        
        datasets = {
            'train': train_df,
            'val': val_df,
            'test': test_df
        }
        
        for split_name, df in datasets.items():
            if separate_features_target:
                # X, y ë¶„ë¦¬ ì €ì¥
                feature_filename = prefix + file_naming['feature_format'].format(split=split_name)
                target_filename = prefix + file_naming['target_format'].format(split=split_name)
                
                # X ì €ì¥ (í”¼ì²˜ë§Œ)
                X = df[feature_cols]
                X.to_csv(experiment_dir / feature_filename, index=False)
                
                # y ì €ì¥ (íƒ€ê²Ÿë§Œ)
                y = df[target_col]
                y.to_csv(experiment_dir / target_filename, index=False)
                
                self.logger.info(f"ì €ì¥ ì™„ë£Œ: {feature_filename}, {target_filename}")
            else:
                # í†µí•© íŒŒì¼ë¡œ ì €ì¥
                combined_filename = prefix + file_naming['combined_format'].format(split=split_name)
                df.to_csv(experiment_dir / combined_filename, index=False)
                
                self.logger.info(f"ì €ì¥ ì™„ë£Œ: {combined_filename}")
    
    def generate_report(self, experiment_dir: Path):
        """ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.config['output']['generate_report']:
            return
        
        self.logger.info("ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        report_content = self._create_report_content()
        
        formats = self.config['output']['report_format']
        
        if 'txt' in formats:
            with open(experiment_dir / "preprocessing_report.txt", 'w', encoding='utf-8') as f:
                f.write(report_content)
        
        if 'html' in formats:
            html_content = self._convert_to_html(report_content)
            with open(experiment_dir / "preprocessing_report.html", 'w', encoding='utf-8') as f:
                f.write(html_content)
        
        self.logger.info("ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
    
    def _create_report_content(self) -> str:
        """ë¦¬í¬íŠ¸ ë‚´ìš© ìƒì„±"""
        
        # í”¼ì²˜ ì„ íƒ ì •ë³´
        feature_selection_enabled = 'feature_selection' in self.results['preprocessing_steps']
        
        report = f"""
ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ ë¦¬í¬íŠ¸ (ìŠ¤ì¼€ì¼ë§ ì œì™¸)
=========================================================

ì‹¤í—˜ ì •ë³´
--------
- ì‹¤í—˜ëª…: {self.results['experiment_info']['name']}
- ì‹¤í–‰ ì‹œê°„: {self.results['experiment_info']['timestamp']}
- ë²„ì „: {self.results['experiment_info']['version']}
- ì„¤ëª…: {self.results['experiment_info']['description']}

ì›ë³¸ ë°ì´í„° ì •ë³´
--------------
- ë°ì´í„° í¬ê¸°: {self.results['data_info']['original_shape']}
- íƒ€ê²Ÿ ë¶„í¬: {self.results['data_info']['target_distribution']}

ì „ì²˜ë¦¬ ë‹¨ê³„ë³„ ê²°ê³¼
----------------

1. ë°ì´í„° ë¶„í•  (5:3:2)
   - Train: {self.results['preprocessing_steps']['data_split']['train_shape']}
   - Validation: {self.results['preprocessing_steps']['data_split']['val_shape']}
   - Test: {self.results['preprocessing_steps']['data_split']['test_shape']}

2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
   - ë°©ë²•: {self.results['preprocessing_steps']['missing_data']['method']}
   - ì„ê³„ê°’: {self.results['preprocessing_steps']['missing_data']['threshold']}
   - ì œê±°ëœ í–‰ìˆ˜: {self.results['preprocessing_steps']['missing_data']['rows_removed']}

3. ìœˆì €ë¼ì´ì§•
   - ì ìš© ì—¬ë¶€: {self.results['preprocessing_steps']['winsorization']['enabled']}
   - í•˜ìœ„ ì„ê³„ê°’: {self.results['preprocessing_steps']['winsorization']['lower_percentile']}
   - ìƒìœ„ ì„ê³„ê°’: {self.results['preprocessing_steps']['winsorization']['upper_percentile']}
"""

        # í”¼ì²˜ ì„ íƒ ì •ë³´ (í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
        if feature_selection_enabled:
            report += f"""
4. í”¼ì²˜ ì„ íƒ (ë¼ì†Œ íšŒê·€)
   - ì›ë³¸ í”¼ì²˜ ìˆ˜: {self.results['preprocessing_steps']['feature_selection']['original_features']}
   - ì„ íƒëœ í”¼ì²˜ ìˆ˜: {self.results['preprocessing_steps']['feature_selection']['selected_features']}
   - ì„ íƒëœ Alpha: {self.results['preprocessing_steps']['feature_selection']['selected_alpha']}

ëª¨ë¸ ì„±ëŠ¥
--------
- Train MSE: {self.results['model_performance']['train_mse']:.6f}
- Validation MSE: {self.results['model_performance']['val_mse']:.6f}
- Test MSE: {self.results['model_performance']['test_mse']:.6f}
- Train RÂ²: {self.results['model_performance']['train_r2']:.6f}
- Validation RÂ²: {self.results['model_performance']['val_r2']:.6f}
- Test RÂ²: {self.results['model_performance']['test_r2']:.6f}

ì„ íƒëœ í”¼ì²˜ ëª©ë¡
--------------
{chr(10).join(f"- {feature}" for feature in self.results['selected_features'])}
"""
        else:
            report += f"""
4. í”¼ì²˜ ì„ íƒ
   - ìƒíƒœ: ë¹„í™œì„±í™”ë¨
   - ëª¨ë“  í”¼ì²˜ê°€ ìœ ì§€ë¨
"""

        return report
    
    def _convert_to_html(self, text_content: str) -> str:
        """í…ìŠ¤íŠ¸ë¥¼ HTMLë¡œ ë³€í™˜"""
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>ë°ì´í„° ì „ì²˜ë¦¬ ë¦¬í¬íŠ¸</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        h1 {{ color: #333; }}
        h2 {{ color: #666; border-bottom: 1px solid #ccc; }}
        pre {{ background-color: #f5f5f5; padding: 10px; }}
    </style>
</head>
<body>
    <pre>{text_content}</pre>
</body>
</html>
"""
        return html_content
    
    def run_pipeline(self) -> str:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        self.logger.info("=== ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===")
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            df = self.load_data()
            
            # 2. ë°ì´í„° ë¶„í• 
            train_df, val_df, test_df = self.split_data(df)
            
            # 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            train_df, val_df, test_df = self.handle_missing_data(train_df, val_df, test_df)
            
            # 4. ìœˆì €ë¼ì´ì§•
            train_df, val_df, test_df = self.apply_winsorization(train_df, val_df, test_df)
            
            # 5. í”¼ì²˜ ì„ íƒ
            train_df, val_df, test_df = self.select_features_with_lasso(train_df, val_df, test_df)
            
            # 6. ê²°ê³¼ ì €ì¥
            experiment_dir = self.save_results(train_df, val_df, test_df)
            
            # 7. ë¦¬í¬íŠ¸ ìƒì„±
            self.generate_report(experiment_dir)
            
            self.logger.info("=== ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ===")
            
            return str(experiment_dir)
            
        except Exception as e:
            self.logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸')
    parser.add_argument('--config', '-c', type=str, 
                       default='config/preprocessing_config.yaml',
                       help='Config íŒŒì¼ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = DataPreprocessingPipeline(args.config)
    experiment_dir = pipeline.run_pipeline()
    
    print(f"\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ! (ìŠ¤ì¼€ì¼ë§ ì œì™¸)")
    print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {experiment_dir}")
    
    # í”¼ì²˜ ì„ íƒì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ê´€ë ¨ ì •ë³´ ì¶œë ¥
    if pipeline.results['selected_features']:
        print(f"ğŸ“Š ì„ íƒëœ í”¼ì²˜ ìˆ˜: {len(pipeline.results['selected_features'])}")
        print(f"ğŸ¯ ê²€ì¦ RÂ²: {pipeline.results['model_performance']['val_r2']:.4f}")
    else:
        print(f"ğŸ“Š í”¼ì²˜ ì„ íƒ: ë¹„í™œì„±í™”ë¨ (ëª¨ë“  í”¼ì²˜ ìœ ì§€)")
        print(f"ğŸ¯ ë°ì´í„° ì²˜ë¦¬: ì™„ë£Œ")


if __name__ == "__main__":
    main()