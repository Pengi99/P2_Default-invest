"""
ÏïôÏÉÅÎ∏î ÌååÏù¥ÌîÑÎùºÏù∏
===============================

Í∏∞Îä•:
1. Í∞úÎ≥Ñ Î™®Îç∏Îì§Ïùò ÏòàÏ∏° Í≤∞Ìï©
2. Í∞ÄÏ§ëÏπò ÏûêÎèô Í≥ÑÏÇ∞
3. ÏïôÏÉÅÎ∏î ÏÑ±Îä• ÌèâÍ∞Ä
4. Threshold ÏµúÏ†ÅÌôî

Îã§ÏñëÌïú ÏïôÏÉÅÎ∏î Î∞©Î≤ï ÏßÄÏõê:
- Simple Average
- Weighted Average  
- Stacking (Meta-learner)
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional
from sklearn.metrics import (
    roc_auc_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, balanced_accuracy_score,
    average_precision_score, precision_recall_curve
)
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold
import matplotlib.pyplot as plt
import seaborn as sns


class EnsemblePipeline:
    """
    ÏïôÏÉÅÎ∏î ÌååÏù¥ÌîÑÎùºÏù∏ ÌÅ¥ÎûòÏä§
    
    Ïó¨Îü¨ Í∞úÎ≥Ñ Î™®Îç∏Ïùò ÏòàÏ∏°ÏùÑ Í≤∞Ìï©ÌïòÏó¨ Îçî Í∞ïÎ†•Ìïú ÏòàÏ∏° Î™®Îç∏ÏùÑ ÏÉùÏÑ±
    """
    
    def __init__(self, config: Dict, models: Dict):
        """
        ÏïôÏÉÅÎ∏î ÌååÏù¥ÌîÑÎùºÏù∏ Ï¥àÍ∏∞Ìôî
        
        Args:
            config: ÏÑ§Ï†ï ÎîïÏÖîÎÑàÎ¶¨
            models: Í∞úÎ≥Ñ Î™®Îç∏Îì§Ïùò ÎîïÏÖîÎÑàÎ¶¨ {model_key: model_object}
        """
        self.config = config
        self.models = models
        self.ensemble_config = config.get('ensemble', {})
        
        # ÏïôÏÉÅÎ∏î Î∞©Î≤ï
        self.method = self.ensemble_config.get('method', 'weighted_average')
        self.auto_weight = self.ensemble_config.get('auto_weight', True)
        
        # Í∞ÄÏ§ëÏπò Ï†ÄÏû•
        self.weights = {}
        self.meta_learner = None
        
        print(f"üé≠ ÏïôÏÉÅÎ∏î ÌååÏù¥ÌîÑÎùºÏù∏ Ï¥àÍ∏∞Ìôî")
        print(f"üìä Î∞©Î≤ï: {self.method}")
        print(f"üîÑ ÏûêÎèô Í∞ÄÏ§ëÏπò: {self.auto_weight}")
        print(f"ü§ñ Ìè¨Ìï® Î™®Îç∏ Ïàò: {len(models)}")
    
    def calculate_weights(self, X_val: pd.DataFrame, y_val: pd.Series) -> Dict[str, float]:
        """
        Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞òÏúºÎ°ú Í∞Å Î™®Îç∏Ïùò Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞
        
        Args:
            X_val: Í≤ÄÏ¶ù ÌäπÏÑ± Îç∞Ïù¥ÌÑ∞
            y_val: Í≤ÄÏ¶ù ÌÉÄÍ≤ü Îç∞Ïù¥ÌÑ∞
            
        Returns:
            Dict[str, float]: Î™®Îç∏Î≥Ñ Í∞ÄÏ§ëÏπò
        """
        if not self.auto_weight:
            # ÎèôÏùº Í∞ÄÏ§ëÏπò
            equal_weight = 1.0 / len(self.models)
            return {model_key: equal_weight for model_key in self.models.keys()}
        
        print("üîç Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞ Ï§ë...")
        
        model_scores = {}
        
        for model_key, model in self.models.items():
            try:
                # Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞Î°ú ÏòàÏ∏°
                y_pred_proba = model.predict_proba(X_val)[:, 1]
                
                # AUC Ïä§ÏΩîÏñ¥ Í≥ÑÏÇ∞
                auc_score = roc_auc_score(y_val, y_pred_proba)
                model_scores[model_key] = auc_score
                
                print(f"  üìä {model_key}: AUC = {auc_score:.4f}")
                
            except Exception as e:
                print(f"  ‚ö†Ô∏è {model_key} ÌèâÍ∞Ä Ïã§Ìå®: {e}")
                model_scores[model_key] = 0.5  # Í∏∞Î≥∏Í∞í
        
        # ÏÑ±Îä• Í∏∞Î∞ò Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞ (ÏÜåÌîÑÌä∏Îß•Ïä§)
        scores = np.array(list(model_scores.values()))
        
        # ÏÑ±Îä•Ïù¥ 0.5 Ïù¥ÌïòÏù∏ Î™®Îç∏ÏùÄ Ï†úÏô∏ÌïòÍ±∞ÎÇò ÎÇÆÏùÄ Í∞ÄÏ§ëÏπò Î∂ÄÏó¨
        scores = np.maximum(scores, 0.5)  # ÏµúÏÜåÍ∞í Î≥¥Ïû•
        
        # ÏÜåÌîÑÌä∏Îß•Ïä§Î°ú Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞
        exp_scores = np.exp((scores - np.max(scores)) * 10)  # Ïò®ÎèÑ ÌååÎùºÎØ∏ÌÑ∞ 10
        weights_array = exp_scores / np.sum(exp_scores)
        
        weights = dict(zip(model_scores.keys(), weights_array))
        
        print("‚úÖ ÏµúÏ¢Ö Í∞ÄÏ§ëÏπò:")
        for model_key, weight in weights.items():
            print(f"  üéØ {model_key}: {weight:.4f}")
        
        return weights
    
    def ensemble_predict_proba(self, X: pd.DataFrame, X_val: Optional[pd.DataFrame] = None, 
                              y_val: Optional[pd.Series] = None) -> np.ndarray:
        """
        ÏïôÏÉÅÎ∏î ÏòàÏ∏° ÌôïÎ•† Í≥ÑÏÇ∞
        
        Args:
            X: ÏòàÏ∏°Ìï† ÌäπÏÑ± Îç∞Ïù¥ÌÑ∞
            X_val: Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞Ïö© Í≤ÄÏ¶ù ÌäπÏÑ± Îç∞Ïù¥ÌÑ∞ (ÏÑ†ÌÉùÏÇ¨Ìï≠)
            y_val: Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞Ïö© Í≤ÄÏ¶ù ÌÉÄÍ≤ü Îç∞Ïù¥ÌÑ∞ (ÏÑ†ÌÉùÏÇ¨Ìï≠)
            
        Returns:
            np.ndarray: ÏïôÏÉÅÎ∏î ÏòàÏ∏° ÌôïÎ•†
        """
        # Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞ (ÏïÑÏßÅ Í≥ÑÏÇ∞ÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞)
        if not self.weights and X_val is not None and y_val is not None:
            self.weights = self.calculate_weights(X_val, y_val)
        elif not self.weights:
            # ÎèôÏùº Í∞ÄÏ§ëÏπò ÏÇ¨Ïö©
            equal_weight = 1.0 / len(self.models)
            self.weights = {model_key: equal_weight for model_key in self.models.keys()}
        
        if self.method == 'simple_average':
            return self._simple_average_predict(X)
        elif self.method == 'weighted_average':
            return self._weighted_average_predict(X)
        elif self.method == 'stacking':
            return self._stacking_predict(X, X_val, y_val)
        else:
            raise ValueError(f"ÏßÄÏõêÌïòÏßÄ ÏïäÎäî ÏïôÏÉÅÎ∏î Î∞©Î≤ï: {self.method}")
    
    def _simple_average_predict(self, X: pd.DataFrame) -> np.ndarray:
        """Îã®Ïàú ÌèâÍ∑† ÏïôÏÉÅÎ∏î"""
        predictions = []
        
        for model_key, model in self.models.items():
            y_pred_proba = model.predict_proba(X)[:, 1]
            predictions.append(y_pred_proba)
        
        return np.mean(predictions, axis=0)
    
    def _weighted_average_predict(self, X: pd.DataFrame) -> np.ndarray:
        """Í∞ÄÏ§ë ÌèâÍ∑† ÏïôÏÉÅÎ∏î"""
        predictions = []
        weights = []
        
        for model_key, model in self.models.items():
            y_pred_proba = model.predict_proba(X)[:, 1]
            predictions.append(y_pred_proba)
            weights.append(self.weights.get(model_key, 1.0 / len(self.models)))
        
        predictions = np.array(predictions)
        weights = np.array(weights)
        
        # Í∞ÄÏ§ë ÌèâÍ∑† Í≥ÑÏÇ∞
        weighted_pred = np.average(predictions, axis=0, weights=weights)
        
        return weighted_pred
    
    def _stacking_predict(self, X: pd.DataFrame, X_val: Optional[pd.DataFrame] = None, 
                         y_val: Optional[pd.Series] = None) -> np.ndarray:
        """Ïä§ÌÉúÌÇπ ÏïôÏÉÅÎ∏î (Î©îÌÉÄ Îü¨ÎÑà ÏÇ¨Ïö©)"""
        # Î©îÌÉÄ Îü¨ÎÑàÍ∞Ä ÏóÜÍ≥† Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäî Í≤ΩÏö∞ ÌõàÎ†®
        if self.meta_learner is None and X_val is not None and y_val is not None:
            self._train_meta_learner(X_val, y_val)
        
        # Í∞úÎ≥Ñ Î™®Îç∏Îì§Ïùò ÏòàÏ∏°ÏùÑ Î©îÌÉÄ ÌäπÏÑ±ÏúºÎ°ú ÏÇ¨Ïö©
        meta_features = []
        for model_key, model in self.models.items():
            y_pred_proba = model.predict_proba(X)[:, 1]
            meta_features.append(y_pred_proba)
        
        meta_features = np.column_stack(meta_features)
        
        if self.meta_learner is not None:
            return self.meta_learner.predict_proba(meta_features)[:, 1]
        else:
            # Î©îÌÉÄ Îü¨ÎÑàÍ∞Ä ÏóÜÏúºÎ©¥ Îã®Ïàú ÌèâÍ∑† ÏÇ¨Ïö©
            return np.mean(meta_features, axis=1)
    
    def _train_meta_learner(self, X_val: pd.DataFrame, y_val: pd.Series):
        """Î©îÌÉÄ Îü¨ÎÑà ÌõàÎ†® (Ïä§ÌÉúÌÇπÏö©)"""
        print("üîÑ Î©îÌÉÄ Îü¨ÎÑà ÌõàÎ†® Ï§ë...")
        
        # Í∞úÎ≥Ñ Î™®Îç∏Îì§Ïùò Í≤ÄÏ¶ù ÏòàÏ∏°ÏùÑ Î©îÌÉÄ ÌäπÏÑ±ÏúºÎ°ú ÏÇ¨Ïö©
        meta_features = []
        for model_key, model in self.models.items():
            y_pred_proba = model.predict_proba(X_val)[:, 1]
            meta_features.append(y_pred_proba)
        
        meta_features = np.column_stack(meta_features)
        
        # Î°úÏßÄÏä§Ìã± ÌöåÍ∑ÄÎ•º Î©îÌÉÄ Îü¨ÎÑàÎ°ú ÏÇ¨Ïö©
        self.meta_learner = LogisticRegression(
            random_state=self.config.get('random_state', 42),
            max_iter=1000
        )
        self.meta_learner.fit(meta_features, y_val)
        
        print("‚úÖ Î©îÌÉÄ Îü¨ÎÑà ÌõàÎ†® ÏôÑÎ£å")
    
    def find_optimal_threshold(self, X_val: pd.DataFrame, y_val: pd.Series, 
                              metric: str = 'f1') -> Tuple[float, Dict]:
        """
        ÏïôÏÉÅÎ∏îÏùò ÏµúÏ†Å threshold Ï∞æÍ∏∞
        
        Args:
            X_val: Í≤ÄÏ¶ù ÌäπÏÑ± Îç∞Ïù¥ÌÑ∞
            y_val: Í≤ÄÏ¶ù ÌÉÄÍ≤ü Îç∞Ïù¥ÌÑ∞
            metric: ÏµúÏ†ÅÌôîÌï† Î©îÌä∏Î¶≠
            
        Returns:
            Tuple[float, Dict]: (ÏµúÏ†Å threshold, threshold Î∂ÑÏÑù Í≤∞Í≥º)
        """
        print(f"üéØ ÏïôÏÉÅÎ∏î ÏµúÏ†Å Threshold ÌÉêÏÉâ ({metric.upper()} Í∏∞Ï§Ä)")
        
        # ÏïôÏÉÅÎ∏î ÏòàÏ∏°
        y_pred_proba = self.ensemble_predict_proba(X_val, X_val, y_val)
        
        # Îã§ÏñëÌïú thresholdÏóêÏÑúÏùò ÏÑ±Îä• Í≥ÑÏÇ∞
        thresholds = np.arange(0.05, 0.5, 0.05)
        threshold_results = []
        
        for threshold in thresholds:
            y_pred = (y_pred_proba >= threshold).astype(int)
            
            if len(np.unique(y_pred)) == 1:
                continue
            
            try:
                metrics = {
                    'threshold': threshold,
                    'precision': precision_score(y_val, y_pred, zero_division=0),
                    'recall': recall_score(y_val, y_pred, zero_division=0),
                    'f1': f1_score(y_val, y_pred, zero_division=0),
                    'balanced_accuracy': balanced_accuracy_score(y_val, y_pred)
                }
                threshold_results.append(metrics)
            except:
                continue
        
        if not threshold_results:
            print("‚ö†Ô∏è ÏµúÏ†Å threshold Ï∞æÍ∏∞ Ïã§Ìå®, Í∏∞Î≥∏Í∞í 0.5 ÏÇ¨Ïö©")
            return 0.5, {}
        
        # Í≤∞Í≥ºÎ•º DataFrameÏúºÎ°ú Î≥ÄÌôò
        threshold_df = pd.DataFrame(threshold_results)
        
        # ÏµúÏ†Å threshold Ï∞æÍ∏∞
        best_idx = threshold_df[metric].idxmax()
        optimal_threshold = threshold_df.loc[best_idx, 'threshold']
        optimal_value = threshold_df.loc[best_idx, metric]
        
        print(f"‚úÖ ÏµúÏ†Å Threshold: {optimal_threshold:.3f} ({metric.upper()}: {optimal_value:.4f})")
        
        # Precision-Recall Í≥°ÏÑ† Îç∞Ïù¥ÌÑ∞
        precision_vals, recall_vals, pr_thresholds = precision_recall_curve(y_val, y_pred_proba)
        
        threshold_analysis = {
            'all_thresholds': threshold_results,
            'optimal_threshold': optimal_threshold,
            'optimal_metric': metric,
            'optimal_value': optimal_value,
            'pr_curve': {
                'precision': precision_vals.tolist(),
                'recall': recall_vals.tolist(),
                'thresholds': pr_thresholds.tolist()
            }
        }
        
        return optimal_threshold, threshold_analysis
    
    def evaluate_ensemble(self, X_test: pd.DataFrame, y_test: pd.Series, 
                         threshold: float = 0.5) -> Dict[str, float]:
        """
        ÏïôÏÉÅÎ∏î Î™®Îç∏ ÌèâÍ∞Ä
        
        Args:
            X_test: ÌÖåÏä§Ìä∏ ÌäπÏÑ± Îç∞Ïù¥ÌÑ∞
            y_test: ÌÖåÏä§Ìä∏ ÌÉÄÍ≤ü Îç∞Ïù¥ÌÑ∞
            threshold: Î∂ÑÎ•ò threshold
            
        Returns:
            Dict[str, float]: ÏÑ±Îä• Î©îÌä∏Î¶≠Îì§
        """
        print(f"üìä ÏïôÏÉÅÎ∏î Î™®Îç∏ ÌèâÍ∞Ä (Threshold: {threshold:.3f})")
        
        # ÏòàÏ∏°
        y_pred_proba = self.ensemble_predict_proba(X_test)
        y_pred = (y_pred_proba >= threshold).astype(int)
        
        # ÏÑ±Îä• Î©îÌä∏Î¶≠ Í≥ÑÏÇ∞
        metrics = {
            'auc': roc_auc_score(y_test, y_pred_proba),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1': f1_score(y_test, y_pred, zero_division=0),
            'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),
            'average_precision': average_precision_score(y_test, y_pred_proba)
        }
        
        print("üìà ÏïôÏÉÅÎ∏î ÏÑ±Îä•:")
        for metric_name, value in metrics.items():
            print(f"  {metric_name.upper()}: {value:.4f}")
        
        return metrics
    
    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:
        """
        ÏãúÍ∞ÅÌôîÏö© predict_proba Î©îÏÑúÎìú
        
        Args:
            X: ÏòàÏ∏°Ìï† ÌäπÏÑ± Îç∞Ïù¥ÌÑ∞
            
        Returns:
            np.ndarray: ÏïôÏÉÅÎ∏î ÏòàÏ∏° ÌôïÎ•† (ÏãúÍ∞ÅÌôî Ìò∏ÌôòÏùÑ ÏúÑÌï¥ ÌôïÎ•†Í∞íÎßå Î∞òÌôò)
        """
        return self.ensemble_predict_proba(X)

    def create_ensemble_report(self, output_dir):
        """ÏïôÏÉÅÎ∏î ÏãúÍ∞ÅÌôî Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±"""
        print("üìä ÏïôÏÉÅÎ∏î Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ± Ï§ë...")
        
        # Í∞ÄÏ§ëÏπò ÏãúÍ∞ÅÌôî
        if self.weights:
            fig, ax = plt.subplots(1, 1, figsize=(10, 6))
            
            models = list(self.weights.keys())
            weights = list(self.weights.values())
            
            # Î™®Îç∏Î™Ö Í∞ÑÏÜåÌôî
            model_names = [model.split('_')[0] for model in models]
            
            bars = ax.bar(model_names, weights, color=['blue', 'red', 'green', 'orange', 'purple'][:len(models)])
            
            # Í∞í ÌëúÏãú
            for bar, weight in zip(bars, weights):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                       f'{weight:.3f}', ha='center', va='bottom', fontweight='bold')
            
            ax.set_title('ÏïôÏÉÅÎ∏î Î™®Îç∏ Í∞ÄÏ§ëÏπò', fontsize=14, fontweight='bold')
            ax.set_ylabel('Í∞ÄÏ§ëÏπò')
            ax.set_xlabel('Î™®Îç∏')
            ax.grid(True, alpha=0.3)
            ax.set_ylim(0, max(weights) * 1.2)
            
            plt.tight_layout()
            plt.savefig(output_dir / 'ensemble_weights.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"  ‚úÖ ÏïôÏÉÅÎ∏î Í∞ÄÏ§ëÏπò ÏãúÍ∞ÅÌôî Ï†ÄÏû•: ensemble_weights.png")
        
        print("‚úÖ ÏïôÏÉÅÎ∏î Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ± ÏôÑÎ£å")