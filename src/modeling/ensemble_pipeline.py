"""
ì•™ìƒë¸” íŒŒì´í”„ë¼ì¸
===============================

ê¸°ëŠ¥:
1. ê°œë³„ ëª¨ë¸ë“¤ì˜ ì˜ˆì¸¡ ê²°í•©
2. ê°€ì¤‘ì¹˜ ìë™ ê³„ì‚°
3. ì•™ìƒë¸” ì„±ëŠ¥ í‰ê°€
4. Threshold ìµœì í™”

ë‹¤ì–‘í•œ ì•™ìƒë¸” ë°©ë²• ì§€ì›:
- Simple Average
- Weighted Average  
- Stacking (Meta-learner)
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional
from sklearn.metrics import (
    roc_auc_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, balanced_accuracy_score,
    average_precision_score, precision_recall_curve
)
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold
import matplotlib.pyplot as plt
import seaborn as sns


class EnsemblePipeline:
    """
    ì•™ìƒë¸” íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤
    
    ì—¬ëŸ¬ ê°œë³„ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ê²°í•©í•˜ì—¬ ë” ê°•ë ¥í•œ ì˜ˆì¸¡ ëª¨ë¸ì„ ìƒì„±
    """
    
    def __init__(self, config: Dict, models: Dict):
        """
        ì•™ìƒë¸” íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
            models: ê°œë³„ ëª¨ë¸ë“¤ì˜ ë”•ì…”ë„ˆë¦¬ {model_key: model_object}
        """
        self.config = config
        self.models = models
        self.ensemble_config = config.get('ensemble', {})
        
        # ì•™ìƒë¸” ë°©ë²•
        self.method = self.ensemble_config.get('method', 'weighted_average')
        self.auto_weight = self.ensemble_config.get('auto_weight', True)
        
        # ê°€ì¤‘ì¹˜ ì €ì¥
        self.weights = {}
        self.meta_learner = None
        
        print(f"ğŸ­ ì•™ìƒë¸” íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”")
        print(f"ğŸ“Š ë°©ë²•: {self.method}")
        print(f"ğŸ”„ ìë™ ê°€ì¤‘ì¹˜: {self.auto_weight}")
        print(f"ğŸ¤– í¬í•¨ ëª¨ë¸ ìˆ˜: {len(models)}")
    
    def calculate_weights(self, X_val: pd.DataFrame, y_val: pd.Series) -> Dict[str, float]:
        """
        ê²€ì¦ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ê° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
        
        Args:
            X_val: ê²€ì¦ íŠ¹ì„± ë°ì´í„°
            y_val: ê²€ì¦ íƒ€ê²Ÿ ë°ì´í„°
            
        Returns:
            Dict[str, float]: ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜
        """
        if not self.auto_weight:
            # ë™ì¼ ê°€ì¤‘ì¹˜
            equal_weight = 1.0 / len(self.models)
            return {model_key: equal_weight for model_key in self.models.keys()}
        
        print("ğŸ” ê²€ì¦ ë°ì´í„° ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...")
        
        model_scores = {}
        
        for model_key, model in self.models.items():
            try:
                # ê²€ì¦ ë°ì´í„°ë¡œ ì˜ˆì¸¡
                y_pred_proba = model.predict_proba(X_val)[:, 1]
                
                # AUC ìŠ¤ì½”ì–´ ê³„ì‚°
                auc_score = roc_auc_score(y_val, y_pred_proba)
                model_scores[model_key] = auc_score
                
                print(f"  ğŸ“Š {model_key}: AUC = {auc_score:.4f}")
                
            except Exception as e:
                print(f"  âš ï¸ {model_key} í‰ê°€ ì‹¤íŒ¨: {e}")
                model_scores[model_key] = 0.5  # ê¸°ë³¸ê°’
        
        # ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚° (ì†Œí”„íŠ¸ë§¥ìŠ¤)
        scores = np.array(list(model_scores.values()))
        
        # ì„±ëŠ¥ì´ 0.5 ì´í•˜ì¸ ëª¨ë¸ì€ ì œì™¸í•˜ê±°ë‚˜ ë‚®ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
        scores = np.maximum(scores, 0.5)  # ìµœì†Œê°’ ë³´ì¥
        
        # ì†Œí”„íŠ¸ë§¥ìŠ¤ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°
        exp_scores = np.exp((scores - np.max(scores)) * 10)  # ì˜¨ë„ íŒŒë¼ë¯¸í„° 10
        weights_array = exp_scores / np.sum(exp_scores)
        
        weights = dict(zip(model_scores.keys(), weights_array))
        
        print("âœ… ìµœì¢… ê°€ì¤‘ì¹˜:")
        for model_key, weight in weights.items():
            print(f"  ğŸ¯ {model_key}: {weight:.4f}")
        
        return weights
    
    def ensemble_predict_proba(self, X: pd.DataFrame, X_val: Optional[pd.DataFrame] = None, 
                              y_val: Optional[pd.Series] = None) -> np.ndarray:
        """
        ì•™ìƒë¸” ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°
        
        Args:
            X: ì˜ˆì¸¡í•  íŠ¹ì„± ë°ì´í„°
            X_val: ê°€ì¤‘ì¹˜ ê³„ì‚°ìš© ê²€ì¦ íŠ¹ì„± ë°ì´í„° (ì„ íƒì‚¬í•­)
            y_val: ê°€ì¤‘ì¹˜ ê³„ì‚°ìš© ê²€ì¦ íƒ€ê²Ÿ ë°ì´í„° (ì„ íƒì‚¬í•­)
            
        Returns:
            np.ndarray: ì•™ìƒë¸” ì˜ˆì¸¡ í™•ë¥ 
        """
        # ê°€ì¤‘ì¹˜ ê³„ì‚° (ì•„ì§ ê³„ì‚°ë˜ì§€ ì•Šì€ ê²½ìš°)
        if not self.weights and X_val is not None and y_val is not None:
            self.weights = self.calculate_weights(X_val, y_val)
        elif not self.weights:
            # ë™ì¼ ê°€ì¤‘ì¹˜ ì‚¬ìš©
            equal_weight = 1.0 / len(self.models)
            self.weights = {model_key: equal_weight for model_key in self.models.keys()}
        
        if self.method == 'simple_average':
            return self._simple_average_predict(X)
        elif self.method == 'weighted_average':
            return self._weighted_average_predict(X)
        elif self.method == 'stacking':
            return self._stacking_predict(X, X_val, y_val)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•™ìƒë¸” ë°©ë²•: {self.method}")
    
    def _simple_average_predict(self, X: pd.DataFrame) -> np.ndarray:
        """ë‹¨ìˆœ í‰ê·  ì•™ìƒë¸”"""
        predictions = []
        
        for model_key, model in self.models.items():
            y_pred_proba = model.predict_proba(X)[:, 1]
            predictions.append(y_pred_proba)
        
        return np.mean(predictions, axis=0)
    
    def _weighted_average_predict(self, X: pd.DataFrame) -> np.ndarray:
        """ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”"""
        predictions = []
        weights = []
        
        for model_key, model in self.models.items():
            y_pred_proba = model.predict_proba(X)[:, 1]
            predictions.append(y_pred_proba)
            weights.append(self.weights.get(model_key, 1.0 / len(self.models)))
        
        predictions = np.array(predictions)
        weights = np.array(weights)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weighted_pred = np.average(predictions, axis=0, weights=weights)
        
        return weighted_pred
    
    def _stacking_predict(self, X: pd.DataFrame, X_val: Optional[pd.DataFrame] = None, 
                         y_val: Optional[pd.Series] = None) -> np.ndarray:
        """ìŠ¤íƒœí‚¹ ì•™ìƒë¸” (ë©”íƒ€ ëŸ¬ë„ˆ ì‚¬ìš©)"""
        # ë©”íƒ€ ëŸ¬ë„ˆê°€ ì—†ê³  ê²€ì¦ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° í›ˆë ¨
        if self.meta_learner is None and X_val is not None and y_val is not None:
            self._train_meta_learner(X_val, y_val)
        
        # ê°œë³„ ëª¨ë¸ë“¤ì˜ ì˜ˆì¸¡ì„ ë©”íƒ€ íŠ¹ì„±ìœ¼ë¡œ ì‚¬ìš©
        meta_features = []
        for model_key, model in self.models.items():
            y_pred_proba = model.predict_proba(X)[:, 1]
            meta_features.append(y_pred_proba)
        
        meta_features = np.column_stack(meta_features)
        
        if self.meta_learner is not None:
            return self.meta_learner.predict_proba(meta_features)[:, 1]
        else:
            # ë©”íƒ€ ëŸ¬ë„ˆê°€ ì—†ìœ¼ë©´ ë‹¨ìˆœ í‰ê·  ì‚¬ìš©
            return np.mean(meta_features, axis=1)
    
    def _train_meta_learner(self, X_val: pd.DataFrame, y_val: pd.Series):
        """ë©”íƒ€ ëŸ¬ë„ˆ í›ˆë ¨ (ìŠ¤íƒœí‚¹ìš©)"""
        print("ğŸ”„ ë©”íƒ€ ëŸ¬ë„ˆ í›ˆë ¨ ì¤‘...")
        
        # ê°œë³„ ëª¨ë¸ë“¤ì˜ ê²€ì¦ ì˜ˆì¸¡ì„ ë©”íƒ€ íŠ¹ì„±ìœ¼ë¡œ ì‚¬ìš©
        meta_features = []
        for model_key, model in self.models.items():
            y_pred_proba = model.predict_proba(X_val)[:, 1]
            meta_features.append(y_pred_proba)
        
        meta_features = np.column_stack(meta_features)
        
        # ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ë©”íƒ€ ëŸ¬ë„ˆë¡œ ì‚¬ìš©
        self.meta_learner = LogisticRegression(
            random_state=self.config.get('random_state', 42),
            max_iter=1000
        )
        self.meta_learner.fit(meta_features, y_val)
        
        print("âœ… ë©”íƒ€ ëŸ¬ë„ˆ í›ˆë ¨ ì™„ë£Œ")
    
    def find_optimal_threshold(self, X_val: pd.DataFrame, y_val: pd.Series, 
                              metric: str = 'f1') -> Tuple[float, Dict]:
        """
        ì•™ìƒë¸”ì˜ ìµœì  threshold ì°¾ê¸°
        
        Args:
            X_val: ê²€ì¦ íŠ¹ì„± ë°ì´í„°
            y_val: ê²€ì¦ íƒ€ê²Ÿ ë°ì´í„°
            metric: ìµœì í™”í•  ë©”íŠ¸ë¦­
            
        Returns:
            Tuple[float, Dict]: (ìµœì  threshold, threshold ë¶„ì„ ê²°ê³¼)
        """
        print(f"ğŸ¯ ì•™ìƒë¸” ìµœì  Threshold íƒìƒ‰ ({metric.upper()} ê¸°ì¤€)")
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        y_pred_proba = self.ensemble_predict_proba(X_val, X_val, y_val)
        
        # ë‹¤ì–‘í•œ thresholdì—ì„œì˜ ì„±ëŠ¥ ê³„ì‚°
        thresholds = np.arange(0.05, 0.5, 0.05)
        threshold_results = []
        
        for threshold in thresholds:
            y_pred = (y_pred_proba >= threshold).astype(int)
            
            if len(np.unique(y_pred)) == 1:
                continue
            
            try:
                metrics = {
                    'threshold': threshold,
                    'precision': precision_score(y_val, y_pred, zero_division=0),
                    'recall': recall_score(y_val, y_pred, zero_division=0),
                    'f1': f1_score(y_val, y_pred, zero_division=0),
                    'balanced_accuracy': balanced_accuracy_score(y_val, y_pred)
                }
                threshold_results.append(metrics)
            except:
                continue
        
        if not threshold_results:
            print("âš ï¸ ìµœì  threshold ì°¾ê¸° ì‹¤íŒ¨, ê¸°ë³¸ê°’ 0.5 ì‚¬ìš©")
            return 0.5, {}
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        threshold_df = pd.DataFrame(threshold_results)
        
        # ìµœì  threshold ì°¾ê¸°
        best_idx = threshold_df[metric].idxmax()
        optimal_threshold = threshold_df.loc[best_idx, 'threshold']
        optimal_value = threshold_df.loc[best_idx, metric]
        
        print(f"âœ… ìµœì  Threshold: {optimal_threshold:.3f} ({metric.upper()}: {optimal_value:.4f})")
        
        # Precision-Recall ê³¡ì„  ë°ì´í„°
        precision_vals, recall_vals, pr_thresholds = precision_recall_curve(y_val, y_pred_proba)
        
        threshold_analysis = {
            'all_thresholds': threshold_results,
            'optimal_threshold': optimal_threshold,
            'optimal_metric': metric,
            'optimal_value': optimal_value,
            'pr_curve': {
                'precision': precision_vals.tolist(),
                'recall': recall_vals.tolist(),
                'thresholds': pr_thresholds.tolist()
            }
        }
        
        return optimal_threshold, threshold_analysis
    
    def evaluate_ensemble(self, X_test: pd.DataFrame, y_test: pd.Series, 
                         threshold: float = 0.5) -> Dict[str, float]:
        """
        ì•™ìƒë¸” ëª¨ë¸ í‰ê°€
        
        Args:
            X_test: í…ŒìŠ¤íŠ¸ íŠ¹ì„± ë°ì´í„°
            y_test: í…ŒìŠ¤íŠ¸ íƒ€ê²Ÿ ë°ì´í„°
            threshold: ë¶„ë¥˜ threshold
            
        Returns:
            Dict[str, float]: ì„±ëŠ¥ ë©”íŠ¸ë¦­ë“¤
        """
        print(f"ğŸ“Š ì•™ìƒë¸” ëª¨ë¸ í‰ê°€ (Threshold: {threshold:.3f})")
        
        # ì˜ˆì¸¡
        y_pred_proba = self.ensemble_predict_proba(X_test)
        y_pred = (y_pred_proba >= threshold).astype(int)
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = {
            'auc': roc_auc_score(y_test, y_pred_proba),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1': f1_score(y_test, y_pred, zero_division=0),
            'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),
            'average_precision': average_precision_score(y_test, y_pred_proba)
        }
        
        print("ğŸ“ˆ ì•™ìƒë¸” ì„±ëŠ¥:")
        for metric_name, value in metrics.items():
            print(f"  {metric_name.upper()}: {value:.4f}")
        
        return metrics
    
    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:
        """
        ì‹œê°í™”ìš© predict_proba ë©”ì„œë“œ
        
        Args:
            X: ì˜ˆì¸¡í•  íŠ¹ì„± ë°ì´í„°
            
        Returns:
            np.ndarray: ì•™ìƒë¸” ì˜ˆì¸¡ í™•ë¥  (ì‹œê°í™” í˜¸í™˜ì„ ìœ„í•´ í™•ë¥ ê°’ë§Œ ë°˜í™˜)
        """
        return self.ensemble_predict_proba(X)

    def create_ensemble_report(self, output_dir):
        """ì•™ìƒë¸” ì‹œê°í™” ë¦¬í¬íŠ¸ ìƒì„±"""
        print("ğŸ“Š ì•™ìƒë¸” ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        # ê°€ì¤‘ì¹˜ ì‹œê°í™”
        if self.weights:
            fig, ax = plt.subplots(1, 1, figsize=(10, 6))
            
            models = list(self.weights.keys())
            weights = list(self.weights.values())
            
            # ëª¨ë¸ëª… ê°„ì†Œí™”
            model_names = [model.split('_')[0] for model in models]
            
            bars = ax.bar(model_names, weights, color=['blue', 'red', 'green', 'orange', 'purple'][:len(models)])
            
            # ê°’ í‘œì‹œ
            for bar, weight in zip(bars, weights):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                       f'{weight:.3f}', ha='center', va='bottom', fontweight='bold')
            
            ax.set_title('ì•™ìƒë¸” ëª¨ë¸ ê°€ì¤‘ì¹˜', fontsize=14, fontweight='bold')
            ax.set_ylabel('ê°€ì¤‘ì¹˜')
            ax.set_xlabel('ëª¨ë¸')
            ax.grid(True, alpha=0.3)
            ax.set_ylim(0, max(weights) * 1.2)
            
            plt.tight_layout()
            plt.savefig(output_dir / 'ensemble_weights.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"  âœ… ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì‹œê°í™” ì €ì¥: ensemble_weights.png")
        
        print("âœ… ì•™ìƒë¸” ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")