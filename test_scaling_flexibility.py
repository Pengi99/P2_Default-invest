"""
ìŠ¤ì¼€ì¼ë§ ìœ ì—°ì„± í…ŒìŠ¤íŠ¸
===================

ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ì´ ìˆì–´ë„ íŒŒì´í”„ë¼ì¸ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
"""

import pandas as pd
import numpy as np
import yaml
import sys
import os
import logging
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append('.')
sys.path.append('..')

from modeling_pipeline import ModelingPipeline

def create_test_data():
    """ì‹¤ì œ ì»¬ëŸ¼ ì¤‘ ì¼ë¶€ë§Œ í¬í•¨ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±"""
    test_columns = [
        # Standard ê·¸ë£¹ ì¤‘ ì¼ë¶€
        'ì´ìì‚°', 'ì´ë¶€ì±„', 'ë§¤ì¶œì•¡', 'ìë³¸ê¸ˆ',
        # Robust ê·¸ë£¹ ì¤‘ ì¼ë¶€  
        'ë§¤ì¶œì•¡ì¦ê°€ìœ¨', 'ë¶€ì±„ë¹„ìœ¨', 'ì´ìë³´ìƒë°°ìœ¨',
        # MinMax ê·¸ë£¹ ì¤‘ ì¼ë¶€
        'ë§¤ì¶œì•¡ì´ì´ìµë¥ ', 'ìœ ë™ë¹„ìœ¨', 'ì´ìì‚°ìˆ˜ìµë¥ ',
        # ìŠ¤ì¼€ì¼ë§ ì„¤ì •ì— ì—†ëŠ” ì»¬ëŸ¼ë“¤
        'ê¸°íƒ€ë³€ìˆ˜1', 'ê¸°íƒ€ë³€ìˆ˜2', 'ìƒˆë¡œìš´ë³€ìˆ˜'
    ]
    
    np.random.seed(42)
    n_samples = 200
    
    data = {}
    for col in test_columns:
        if 'ë¹„ìœ¨' in col or 'ë¥ ' in col:
            # ë¹„ìœ¨ ë³€ìˆ˜ëŠ” 0-100 ë²”ìœ„
            data[col] = np.random.uniform(0, 100, n_samples)
        elif 'ì¦ê°€ìœ¨' in col:
            # ì¦ê°€ìœ¨ì€ -50 ~ 50 ë²”ìœ„
            data[col] = np.random.normal(0, 20, n_samples)
        else:
            # ì ˆëŒ“ê°’ ë³€ìˆ˜ëŠ” í° ìˆ«ì
            data[col] = np.random.lognormal(10, 2, n_samples)
    
    df = pd.DataFrame(data)
    
    # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ë¶€ì‹¤ ì—¬ë¶€)
    y = np.random.choice([0, 1], n_samples, p=[0.95, 0.05])
    
    return df, pd.Series(y)

def create_test_config():
    """í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ config ìƒì„±"""
    # ê¸°ë³¸ config ë¡œë“œ
    with open('../../config/modeling_config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ê°„ì†Œí™”
    config['experiment']['name'] = "scaling_flexibility_test"
    config['feature_selection']['enabled'] = False
    config['ensemble']['enabled'] = False
    
    # ëª¨ë¸ trial ìˆ˜ ê°ì†Œ
    for model_name in config['models']:
        if 'n_trials' in config['models'][model_name]:
            config['models'][model_name]['n_trials'] = 5
    
    # ì¼ë¶€ ëª¨ë¸ë§Œ í™œì„±í™”
    for model_name in config['models']:
        config['models'][model_name]['enabled'] = False
    config['models']['logistic_regression']['enabled'] = True
    
    # ìƒ˜í”Œë§ ê°„ì†Œí™”
    for data_type in config['sampling']['data_types']:
        config['sampling']['data_types'][data_type]['enabled'] = False
    config['sampling']['data_types']['normal']['enabled'] = True
    
    return config

def run_test():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§ª ìŠ¤ì¼€ì¼ë§ ìœ ì—°ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    X, y = create_test_data()
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {X.shape}")
    print(f"ì»¬ëŸ¼: {list(X.columns)}")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥
    os.makedirs('../../data/final', exist_ok=True)
    
    # ê°„ë‹¨í•œ train/val/test ë¶„í• 
    n = len(X)
    train_idx = int(n * 0.6)
    val_idx = int(n * 0.8)
    
    X_train, X_val, X_test = X[:train_idx], X[val_idx:train_idx], X[val_idx:]
    y_train, y_val, y_test = y[:train_idx], y[val_idx:train_idx], y[val_idx:]
    
    # íŒŒì¼ ì €ì¥
    X_train.to_csv('../../data/final/X_train.csv', index=False)
    X_val.to_csv('../../data/final/X_val.csv', index=False) 
    X_test.to_csv('../../data/final/X_test.csv', index=False)
    y_train.to_csv('../../data/final/y_train.csv', index=False)
    y_val.to_csv('../../data/final/y_val.csv', index=False)
    y_test.to_csv('../../data/final/y_test.csv', index=False)
    
    print("âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
    
    # Config ìƒì„±
    config = create_test_config()
    config_path = 'test_scaling_config.yaml'
    
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print("âœ… í…ŒìŠ¤íŠ¸ Config ìƒì„± ì™„ë£Œ")
    
    try:
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        print("\nğŸš€ ModelingPipeline ì‹œì‘...")
        pipeline = ModelingPipeline(config_path)
        
        # ë°ì´í„° ë¡œë“œ
        pipeline.load_data()
        print("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        
        # ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸
        data_type = 'normal'
        X_train_scaled, X_val_scaled, X_test_scaled, scalers = pipeline.apply_scaling(
            pipeline.data[data_type]['X_train'].copy(),
            pipeline.data[data_type]['X_val'].copy(),
            pipeline.data[data_type]['X_test'].copy(),
            data_type
        )
        
        print("\nğŸ‰ ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"âœ… ì ìš©ëœ ìŠ¤ì¼€ì¼ëŸ¬: {len(scalers)}ê°œ")
        
        for scaler_name, scaler_info in scalers.items():
            applied_cols = len(scaler_info['columns'])
            missing_cols = len(scaler_info['missing_columns'])
            print(f"  - {scaler_name}: {applied_cols}ê°œ ì ìš©, {missing_cols}ê°œ ëˆ„ë½")
        
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # ì •ë¦¬
        if os.path.exists(config_path):
            os.remove(config_path)
        print("ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")

if __name__ == "__main__":
    success = run_test()
    if success:
        print("\nğŸŠ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì„±ê³µ! ìŠ¤ì¼€ì¼ë§ ìœ ì—°ì„±ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!") 